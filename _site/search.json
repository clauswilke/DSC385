[
  {
    "objectID": "worksheets/working-with-models.html",
    "href": "worksheets/working-with-models.html",
    "title": "Working with models",
    "section": "",
    "text": "In this worksheet, we will discuss how to efficiently fit statistical models (such as linear regressions) to subsets of data and then use for plotting.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data. We will be working with data on individual penguins in Antarctica."
  },
  {
    "objectID": "worksheets/working-with-models.html#introduction",
    "href": "worksheets/working-with-models.html#introduction",
    "title": "Working with models",
    "section": "",
    "text": "In this worksheet, we will discuss how to efficiently fit statistical models (such as linear regressions) to subsets of data and then use for plotting.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data. We will be working with data on individual penguins in Antarctica."
  },
  {
    "objectID": "worksheets/working-with-models.html#inserting-data-into-text-output",
    "href": "worksheets/working-with-models.html#inserting-data-into-text-output",
    "title": "Working with models",
    "section": "Inserting data into text output",
    "text": "Inserting data into text output\nThere are several utility functions we need to understand before we can fit models, process them with broom, and ultimately plot. These include nesting and unnesting of data tables, using map() to apply a function to all the values in a data column, and using glue() to generate generate text. We have discussed nesting/unnesting and map() in the lecture on functional programming, and you may want to review this material if it is unclear to you. Here, we will discuss how to insert data into text output.\nThe glue() function allows you to place variables into a text string. This is frequently useful when we want to process multiple subsets of a larger data table and generate output for each subset.\nFor example:\n\n\n\n\n\n\n\n\nThis also works for vectorized input.\n\n\n\n\n\n\n\n\nTry this for yourself. Create variables holding your first and last name and then print out your complete name using glue().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nfirst_name &lt;- \"Claus\"\nlast_name &lt;- \"Wilke\"\n\nglue(\"My name is ___.\")\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nfirst_name &lt;- \"Claus\"\nlast_name &lt;- \"Wilke\"\n\nglue(\"My name is {first_name} {last_name}.\")"
  },
  {
    "objectID": "worksheets/working-with-models.html#cleaning-up-models-with-broom",
    "href": "worksheets/working-with-models.html#cleaning-up-models-with-broom",
    "title": "Working with models",
    "section": "Cleaning up models with broom",
    "text": "Cleaning up models with broom\nR has powerful functions to fit statistical models to data, such as lm() to fit linear regression models. However, many of these functions have been written for interactive use and don’t work well in an automated data processing pipeline. For example, consider the following code to perform a linear regression analysis on the penguins dataset (ignoring for a moment that there are multiple species):\n\n\n\n\n\n\n\n\nThe fit object stores information about the linear regression, and summary(fit) shows us this information in a nice, human-readable form. But what if we want the relevant information in a data table? This is where the broom package comes in. The glance() function extracts model-level summary data from a fitted object, and the tidy() function extracts information about individual regression coefficients.\n\n\n\n\n\n\n\n\nTry this yourself. Fit a model of bill length versus bill depth (formula: bill_length_mm ~ bill_depth_mm), look at the model fit with summary(), and then look at the model fit via glance() and tidy().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\n# fit linear model\nfit &lt;- lm(bill_length_mm ~ bill_depth_mm, data = penguins)\n\n# inspect model fit with summary()\nsummary(___)\n\n# inspect model fit with glance() and tidy()\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\n# fit linear model\nfit &lt;- lm(bill_length_mm ~ bill_depth_mm, data = penguins)\n\n# inspect model fit with summary()\nsummary(fit)\n\n# inspect model fit with glance() and tidy()\nglance(___)\ntidy(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# fit linear model\nfit &lt;- lm(bill_length_mm ~ bill_depth_mm, data = penguins)\n\n# inspect model fit with summary()\nsummary(fit)\n\n# inspect model fit with glance() and tidy()\nglance(fit)\ntidy(fit)\n\n\n\n\nThe real power of glance() and tidy() becomes apparent in a more complex data analysis pipeline, when we fit a model to subsets of data via map() and then combine the results from the individual fits into one large table.\n\n\n\n\n\n\n\n\nNow run this code yourself one line at a time and make sure you understand at each step what is happening. Review the materials from the class on functional programming if anything is unclear. Note: The individual stages of the calculation are provided as hints, so you can just click through the hints one-by-one and run each piece.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\npenguins |&gt;\n  nest(data = -species) |&gt;     # nest the data table by species\n  mutate(\n    # use map() to fit a model to each nested data table\n    fit = map(data, ~lm(bill_length_mm ~ body_mass_g, data = .x))\n  )\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\npenguins |&gt;\n  nest(data = -species) |&gt;     # nest the data table by species\n  mutate(\n    # use map() to fit a model to each nested data table\n    fit = map(data, ~lm(bill_length_mm ~ body_mass_g, data = .x)),\n    # use map to apply glance() to each model fit\n    glance_out = map(fit, glance)\n  )\n\n\n\n\n\n\n\n\n\n\n\nHint 3\n\n\n\n\n\npenguins |&gt;\n  nest(data = -species) |&gt;     # nest the data table by species\n  mutate(\n    # use map() to fit a model to each nested data table\n    fit = map(data, ~lm(bill_length_mm ~ body_mass_g, data = .x)),\n    # use map to apply glance() to each model fit\n    glance_out = map(fit, glance)\n  ) |&gt;\n  unnest(cols = glance_out)     # unnest output from glance\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  nest(data = -species) |&gt;     # nest the data table by species\n  mutate(\n    # use map() to fit a model to each nested data table\n    fit = map(data, ~lm(bill_length_mm ~ body_mass_g, data = .x)),\n    # use map to apply glance() to each model fit\n    glance_out = map(fit, glance)\n  ) |&gt;\n  unnest(cols = glance_out) |&gt; # unnest output from glance\n  select(-data, -fit)           # remove columns data and fit"
  },
  {
    "objectID": "worksheets/working-with-models.html#plotting-model-fits",
    "href": "worksheets/working-with-models.html#plotting-model-fits",
    "title": "Working with models",
    "section": "Plotting model fits",
    "text": "Plotting model fits\nFinally, we use the results from the model fit to plot a p value on each facet of a regression plot. The plot we’ll be working with is the following:\n\n\n\n\n\n\n\n\nWe can generate the fitted models as in the previous section. We will store them in the penguins_fits:\n\n\n\n\n\n\n\n\nNow, do the following. First, use mutate(), glue(), and select() to convert this table into one that has four columns, species, body_mass_g, bill_length_mm, and label. The species column holds the penguin species. The next two columns will hold the coordinates of the text label. For example, the values body_mass_g = 5500 and bill_length_mm = 32 will work. The last column will hold labels, generated with glue(), of the form “p = 7.48e-06”. You can use signif(p.value, 3) to round p values to three significant digits.\nOnce you have this table, use geom_text() to add the labels to the above plot.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\n# first do the data table manipulation\nlabels_data &lt;- penguins_fits |&gt;\n  mutate(\n    body_mass_g = ___,\n    bill_length_mm = ___,\n    label = ___\n  )\nlabels_data\n\n# then plot\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\n# first do the data table manipulation\nlabels_data &lt;- penguins_fits |&gt;\n  mutate(\n    body_mass_g = 5500,\n    bill_length_mm = 32,\n    label = glue(\"p = {signif(p.value, 3)}\")\n  ) |&gt;\n  select(___)\nlabels_data\n\n# then plot\n\n\n\n\n\n\n\n\n\n\n\nHint 3\n\n\n\n\n\n# first do the data table manipulation\nlabels_data &lt;- penguins_fits |&gt;\n  mutate(\n    body_mass_g = 5500,\n    bill_length_mm = 32,\n    label = glue(\"p = {signif(p.value, 3)}\")\n  ) |&gt;\n  select(species, body_mass_g, bill_length_mm, label)\nlabels_data\n  \n# then plot\n\n\n\n\n\n\n\n\n\n\n\nHint 4\n\n\n\n\n\n# first do the data table manipulation\nlabels_data &lt;- penguins_fits |&gt;\n  mutate(\n    body_mass_g = 5500,\n    bill_length_mm = 32,\n    label = glue(\"p = {signif(p.value, 3)}\")\n  ) |&gt;\n  select(species, body_mass_g, bill_length_mm, label)\n  \n# then plot\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_point(na.rm = TRUE) +\n  geom_smooth(method = \"lm\", formula = y ~ x, na.rm = TRUE) +\n  facet_wrap(vars(species)) +\n  geom_text(___)\n\n\n\n\n\n\n\n\n\n\n\nHint 5\n\n\n\n\n\n# first do the data table manipulation\nlabels_data &lt;- penguins_fits |&gt;\n  mutate(\n    body_mass_g = 5500,\n    bill_length_mm = 32,\n    label = glue(\"p = {signif(p.value, 3)}\")\n  ) |&gt;\n  select(species, body_mass_g, bill_length_mm, label)\n  \n# then plot\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_point(na.rm = TRUE) +\n  geom_smooth(method = \"lm\", formula = y ~ x, na.rm = TRUE) +\n  facet_wrap(vars(species)) +\n  geom_text(\n    data = labels_data,\n    aes(___)\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# first do the data table manipulation\nlabels_data &lt;- penguins_fits |&gt;\n  mutate(\n    body_mass_g = 5500,\n    bill_length_mm = 32,\n    label = glue(\"p = {signif(p.value, 3)}\")\n  ) |&gt;\n  select(species, body_mass_g, bill_length_mm, label)\n  \n# then plot\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_point(na.rm = TRUE) +\n  geom_smooth(method = \"lm\", formula = y ~ x, na.rm = TRUE) +\n  facet_wrap(vars(species)) +\n  geom_text(\n    data = labels_data,\n    aes(label = label)\n  )\n\n\n\n\nOnce you have successfully made the plot, you can try a few more things:\n\nPlace the labels for the different facets in different locations within each facet.\nUse hjust and vjust in geom_text() to fine-tune where labels are placed.\nMake labels that contain the R2 value in addition to the p value."
  },
  {
    "objectID": "worksheets/visualizing-trends.html",
    "href": "worksheets/visualizing-trends.html",
    "title": "Visualizing trends",
    "section": "",
    "text": "In this worksheet, we will discuss how to fit linear regressions (straight lines) and smooth curves to the observations in a dataset.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with three datasets, blue_jays, biorxiv_growth, and cars93. The blue_jays dataset contains various measurements taken on blue jay birds.\n\n\n\n\n\n\n\n\nThe biorxiv_growth dataset contains the number of article submissions per month to the bioRxiv preprint server. Each row corresponds to one month, and the column date_dec shows the date in decimal form. (For example, Feb. 1 2014 is 2014.085, and March 1 2014 is 2014.162. This representation allows us to treat dates as numerical values.)\n\n\n\n\n\n\n\n\nThe cars93 dataset contains information about various passenger cars that were on the market in 1993."
  },
  {
    "objectID": "worksheets/visualizing-trends.html#introduction",
    "href": "worksheets/visualizing-trends.html#introduction",
    "title": "Visualizing trends",
    "section": "",
    "text": "In this worksheet, we will discuss how to fit linear regressions (straight lines) and smooth curves to the observations in a dataset.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with three datasets, blue_jays, biorxiv_growth, and cars93. The blue_jays dataset contains various measurements taken on blue jay birds.\n\n\n\n\n\n\n\n\nThe biorxiv_growth dataset contains the number of article submissions per month to the bioRxiv preprint server. Each row corresponds to one month, and the column date_dec shows the date in decimal form. (For example, Feb. 1 2014 is 2014.085, and March 1 2014 is 2014.162. This representation allows us to treat dates as numerical values.)\n\n\n\n\n\n\n\n\nThe cars93 dataset contains information about various passenger cars that were on the market in 1993."
  },
  {
    "objectID": "worksheets/visualizing-trends.html#fitting-linear-trend-lines",
    "href": "worksheets/visualizing-trends.html#fitting-linear-trend-lines",
    "title": "Visualizing trends",
    "section": "Fitting linear trend lines",
    "text": "Fitting linear trend lines\nWe start with simple linear regression lines. These can be generated with geom_smooth(method = \"lm\"). Try this on the blue_jays dataset. Make a scatter plot of head length (head_length_mm) versus body mass (body_mass_g) and add a regression line.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(blue_jays, aes(body_mass_g, head_length_mm)) +\n  geom_point() +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(blue_jays, aes(body_mass_g, head_length_mm)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\nYou can turn off the confidence band by setting se = FALSE. Try this out. And also change the color of the regression line to black.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(blue_jays, aes(body_mass_g, head_length_mm)) +\n  geom_point() +\n  geom_smooth(\n    method = \"lm\",\n    se = ___,\n    color = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(blue_jays, aes(body_mass_g, head_length_mm)) +\n  geom_point() +\n  geom_smooth(\n    method = \"lm\",\n    se = FALSE,\n    color = \"black\"\n  )\n\n\n\n\nNow color the points by the birds’ sex and generate two separate regression lines, one for each sex.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(blue_jays, aes(body_mass_g, head_length_mm, color = ___)) +\n  geom_point() +\n  geom_smooth(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(blue_jays, aes(body_mass_g, head_length_mm, color = sex)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nNow do the same but instead of coloring by sex you facet by sex.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(blue_jays, aes(body_mass_g, head_length_mm)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(blue_jays, aes(body_mass_g, head_length_mm)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~sex)"
  },
  {
    "objectID": "worksheets/visualizing-trends.html#linear-trend-lines-in-log-transformed-data",
    "href": "worksheets/visualizing-trends.html#linear-trend-lines-in-log-transformed-data",
    "title": "Visualizing trends",
    "section": "Linear trend lines in log-transformed data",
    "text": "Linear trend lines in log-transformed data\nThe blue jay example displayed a nice linear relationship between the variable on the x axis (body mass) and the variable on the y axis (head length). Linear relationships arise in many contexts, but they are not the only type of relationship we encounter in practice. Another commonly encountered relationship is exponential growth, where some quantity increases at a constant rate over time.\nAs an example of exponential growth, we will examine the biorxiv_growth dataset. This dataset contains the number of monthly article submissions to the bioRxiv preprint server from November 2013 to March 2018. A preprint server is a website to which scientists submit their research articles before they are formally published. The bioRxiv server started operation in late 2013, and it experienced rapid growth in subsequent years.\nFirst, make a simple scatter plot of monthly submissions (column count) versus time (column date_dec).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(biorxiv_growth, aes(date_dec, count)) +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(biorxiv_growth, aes(date_dec, count)) +\n  geom_point()\n\n\n\n\nNow add a linear regression line. You should see that this does not look correct at all for this dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(biorxiv_growth, aes(date_dec, count)) +\n  geom_point() +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(biorxiv_growth, aes(date_dec, count)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\nWe could try to fit an exponential curve to the data points, but such fits tend to be not very accurate. Instead, it is usually better to fit a straight line in log space. To do so, you need to plot the count data on a log scale. Remember that you can make an axis logarithmic by adding scale_x_log10() or scale_y_log10() to the plot, depending on which axis you want to transform.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(biorxiv_growth, aes(date_dec, count)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(biorxiv_growth, aes(date_dec, count)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  scale_y_log10()\n\n\n\n\nNow you can see how closely the points follow the exponential growth pattern. Exponential growth creates a strict linear relationship in log-space.\n\nCreating a legend for the regression line\nWhenever we are creating a plot with data points and a regression line, we may want to add a legend that annotates both of these visual elements, as demonstrated in the following plot.\n\n\n\n\n\n\n\n\nHow can we coax ggplot to produce such a legend? We are used to mapping a variable to color or fill and ggplot creates a legend for this mapping, but here the situation is different. We’re not mapping a particular variable in the data, we’re using two separate geoms.\nThe solution is that we need to set up a placeholder mapping, such as aes(color = \"original data\"). A mapping defined with aes() doesn’t always have to refer to a data column in the original data, it can also refer to a constant value provided with the mapping. So, if we give each geom its own mapping, with a different string (e.g., \"original data\" and \"regression line\"), we will get a legend for the aesthetic that we used in the mapping. Try this out with the color aesthetic.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(biorxiv_growth, aes(date_dec, count)) +\n  geom_point(aes(color = ___)) +\n  geom_smooth(aes(color = ___), method = \"lm\") +\n  scale_y_log10()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(biorxiv_growth, aes(date_dec, count)) +\n  geom_point(aes(color = \"original data\")) +\n  geom_smooth(aes(color = \"regression line\"), method = \"lm\") +\n  scale_y_log10()"
  },
  {
    "objectID": "worksheets/visualizing-trends.html#smoothing-lines",
    "href": "worksheets/visualizing-trends.html#smoothing-lines",
    "title": "Visualizing trends",
    "section": "Smoothing lines",
    "text": "Smoothing lines\nWhen you use geom_smooth() without any method argument, it will create a nonlinear smoothing line that provides a reasonable representation of the x-y relationship in the data. This is a good choice when a simple linear regression is not appropriate.\n[Technically, geom_smooth() fits a LOESS estimator (locally estimated scatterplot smoothing) when there are fewer than 1000 observations and a GAM estimator (generalized additive model) when there are more observations. The LOESS estimator tends to produce slightly better visual results but is slow for large datasets.]\nTo try this out, make a scatter plot of fuel tank capacity (Fuel.tank.capacity) versus car price (Price) in the cars93 dataset and add a smoothing line. Fuel tank capacity does not continue to increase the more expensive a car gets, therefore a linear regression is not appripriate in this context.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(cars93, aes(Price, Fuel.tank.capacity)) +\n  ___ + \n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(cars93, aes(Price, Fuel.tank.capacity)) +\n  geom_point() + \n  geom_smooth()\n\n\n\n\nYou can adjust the smoothness of the fitted curve with the span argument. Try span values between 0.2 and 1.5.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(cars93, aes(Price, Fuel.tank.capacity)) +\n  geom_point() + \n  geom_smooth(\n    span = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(cars93, aes(Price, Fuel.tank.capacity)) +\n  geom_point() + \n  geom_smooth(\n    span = 0.2\n  )\n\nggplot(cars93, aes(Price, Fuel.tank.capacity)) +\n  geom_point() + \n  geom_smooth(\n    span = 1.5\n  )\n\n\n\n\nYou can also explicitly force a GAM estimator by setting method = \"gam\". However, in this case you need to also provide a formula that specifies the particular smoothing functions you want to use. For example, formula = y ~ s(x, k = 3) creates thin-plate regression splines with three knots. Try this out. Also try different values of k.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(cars93, aes(Price, Fuel.tank.capacity)) +\n  geom_point() + \n  geom_smooth(\n    method = ___,\n    formula = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(cars93, aes(Price, Fuel.tank.capacity)) +\n  geom_point() + \n  geom_smooth(\n    method = \"gam\",\n    formula = y ~ s(x, k = 3)\n  )\n\n\n\n\nThere are many available options for the formula describing the desired GAM estimator. These options are fully described in the mgcv reference documentation."
  },
  {
    "objectID": "worksheets/visualizing-distributions-2.html",
    "href": "worksheets/visualizing-distributions-2.html",
    "title": "Visualizing distributions 2",
    "section": "",
    "text": "In this worksheet, we will discuss how to display many distributions at once, using boxplots, violin plots, strip charts, sina plots, and ridgeline plots.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nThe dataset we will be working with contains information about the mean temperature for every day of the year 2016 in Lincoln, NE:"
  },
  {
    "objectID": "worksheets/visualizing-distributions-2.html#introduction",
    "href": "worksheets/visualizing-distributions-2.html#introduction",
    "title": "Visualizing distributions 2",
    "section": "",
    "text": "In this worksheet, we will discuss how to display many distributions at once, using boxplots, violin plots, strip charts, sina plots, and ridgeline plots.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nThe dataset we will be working with contains information about the mean temperature for every day of the year 2016 in Lincoln, NE:"
  },
  {
    "objectID": "worksheets/visualizing-distributions-2.html#boxplots-and-violins",
    "href": "worksheets/visualizing-distributions-2.html#boxplots-and-violins",
    "title": "Visualizing distributions 2",
    "section": "Boxplots and violins",
    "text": "Boxplots and violins\nWe start by drawing the distributions of mean temperatures for each month of the year (columns month and mean_temp in the dataset lincoln_temps), using boxplots. We can do this in ggplot with the geom geom_boxplot(). Try this for yourself.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(lincoln_temps, aes(x = ___, y = ___)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_boxplot()\n\n\n\n\nNext, do the same but now using violins (geom_violin()) instead of boxplots.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_violin()\n\n\n\n\nCustomize the violins by trying some of the following:\n\nChange the fill or outline color.\nSwap the x and y mappings.\nChange the bandwidth (parameter bw) or kernel (parameter kernel). These parameters work just like in geom_density() as discussed in the previous worksheet.\nSet trim = FALSE. What does this do?"
  },
  {
    "objectID": "worksheets/visualizing-distributions-2.html#strip-charts-and-jittering",
    "href": "worksheets/visualizing-distributions-2.html#strip-charts-and-jittering",
    "title": "Visualizing distributions 2",
    "section": "Strip charts and jittering",
    "text": "Strip charts and jittering\nBoth boxplots and violin plots have the disadvantage that they don’t show the individual data points. We can show individual data points by using geom_point(). Such a plot is called a strip chart.\nMake a strip chart for the Lincoln temperature data set. Hint: Use size = 0.75 to reduce the size of the individual points.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_point(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_point(size = 0.75)\n\n\n\n\nFrequently when we make strip charts we want to apply some jitter to separate points away from each other. We can do so by setting the argument position = position_jitter() in geom_point().\nWhen using position_jitter() we will normally have to specify how much jittering we want in the horizontal and vertical direction, by setting the width and height arguments: position_jitter(width = 0.15, height = 0). Both width and height are specified in units representing the resolution of the data points, and indicate jittering in either direction. So, if data points are 1 unit apart, then width = 0.15 means the jittering covers 0.3 units or 30% of the spacing of the data points.\nTry this for yourself, by making a strip chart with jittering.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_point(\n    size = 0.75,\n    position = position_jitter(___)\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_point(\n    size = 0.75,\n    position = position_jitter(width = 0.15, height = 0)\n  )\n\n\n\n\nThe function position_jitter() applies random jittering to the data points, which means the plot looks different each time you make it. (Verify this.) We can force a specific, fixed arrangement of jittering by setting the seed parameter. This parameter takes an arbitrary integer value, e.g. seed = 1234. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_point(\n    size = 0.75,\n    position = position_jitter(width = 0.15, height = 0, seed = ___)\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_point(\n    size = 0.75,\n    position = position_jitter(width = 0.15, height = 0, seed = 1234)\n  )\n\n\n\n\nFinally, try to figure out what the parameter height does, by setting it to a value other than 0, or by removing it entirely."
  },
  {
    "objectID": "worksheets/visualizing-distributions-2.html#sina-plots",
    "href": "worksheets/visualizing-distributions-2.html#sina-plots",
    "title": "Visualizing distributions 2",
    "section": "Sina plots",
    "text": "Sina plots\nWe can create a combination of strip charts and violin plots by making sina plots, which jitter points into the shape of a violin. We can do this with geom_sina() from the ggforce package. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_sina(size = 0.75)\n\n\n\n\nIt often makes sense to draw a sina plot on top of a violin plot. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_violin() +\n  geom_sina(size = 0.75)\n\n\n\n\nFinally, customize the violins by removing the outline and changing the fill color.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(lincoln_temps, aes(x = month, y = mean_temp)) +\n  geom_violin(color = NA, fill = \"cornsilk\") +  # `NA` means no color\n  geom_sina(size = 0.75)"
  },
  {
    "objectID": "worksheets/visualizing-distributions-2.html#ridgeline-plots",
    "href": "worksheets/visualizing-distributions-2.html#ridgeline-plots",
    "title": "Visualizing distributions 2",
    "section": "Ridgeline plots",
    "text": "Ridgeline plots\nAs the last alternative for visualizing multiple distributions at once, we will make ridgeline plots. These are multiple density plots staggered vertically. In ridgeline plots, we normally map the grouping variable (e.g. here, the month) to the y axis and the dependent variable (e.g. here, the mean temperature) to the x axis.\nWe can create ridgeline plots using geom_density_ridges() from the ggridges package. Try this out. Use the column month_long instead of month for the name of the month to get a slightly nicer plot. Hint: If you get an error about a missing y aesthetic you need to swap your x and y mappings.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(lincoln_temps, aes(x = mean_temp, y = month_long)) +\n  geom_density_ridges()\n\n\n\n\nWhat happens when you use month instead of month_long? Can you explain why?\nIt is often a good idea to prune the ridgelines once they are close to zero. You can do this with the parameter rel_min_height, which takes a numeric value relative to the maximum height of any ridgeline anywhere in the plot. So, rel_min_height = 0.01 would prune all lines that are less than 1% of the maximum height in the plot.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(lincoln_temps, aes(x = mean_temp, y = month_long)) +\n  geom_density_ridges(rel_min_height = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(lincoln_temps, aes(x = mean_temp, y = month_long)) +\n  geom_density_ridges(rel_min_height = 0.01)"
  },
  {
    "objectID": "worksheets/visualizing-amounts.html",
    "href": "worksheets/visualizing-amounts.html",
    "title": "Visualizing amounts",
    "section": "",
    "text": "In this worksheet, we will discuss a core concept of ggplot, the mapping of data values onto aesthetics.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with two datasets. First, box-office gross results for Dec. 22-24, 2017:\n\n\n\n\n\n\n\n\nSecond, data on individual penguins in Antarctica. Note that missing values have been removed:\npenguins2"
  },
  {
    "objectID": "worksheets/visualizing-amounts.html#introduction",
    "href": "worksheets/visualizing-amounts.html#introduction",
    "title": "Visualizing amounts",
    "section": "",
    "text": "In this worksheet, we will discuss a core concept of ggplot, the mapping of data values onto aesthetics.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with two datasets. First, box-office gross results for Dec. 22-24, 2017:\n\n\n\n\n\n\n\n\nSecond, data on individual penguins in Antarctica. Note that missing values have been removed:\npenguins2"
  },
  {
    "objectID": "worksheets/visualizing-amounts.html#drawing-numerical-values-as-bars",
    "href": "worksheets/visualizing-amounts.html#drawing-numerical-values-as-bars",
    "title": "Visualizing amounts",
    "section": "Drawing numerical values as bars",
    "text": "Drawing numerical values as bars\nFor the boxoffice dataset, we want to draw the amount (Weekend gross, in million USD) for each movie as a bar. Somewhat confusingly, the ggplot geom that does this is called geom_col(). (There is also a geom_bar(), but it works differently. We’ll get to that later in this tutorial.) Make a bar plot of amount versus title. This means amount goes on the y axis and title on the x axis.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(boxoffice, aes(x = ___, y = ___)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(boxoffice, aes(x = title, y = amount)) +\n  geom_col()\n\n\n\n\nNow flip which column you map onto x and which onto y.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(boxoffice, aes(x = amount, y = title)) +\n  geom_col()\n\n\n\n\nThe x-axis label should specify that the amount is in million USD, and the y axis doesn’t need the word “title”. Use xlab() and ylab() to make these changes to the plot.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(boxoffice, aes(x = amount, y = title)) +\n  geom_col() +\n  xlab(___) +\n  ylab(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(boxoffice, aes(x = amount, y = title)) +\n  geom_col() +\n  xlab(\"weekend gross (million USD)\") +\n  ylab(NULL) # NULL means nothing, don't show a y label"
  },
  {
    "objectID": "worksheets/visualizing-amounts.html#getting-bars-into-the-right-order",
    "href": "worksheets/visualizing-amounts.html#getting-bars-into-the-right-order",
    "title": "Visualizing amounts",
    "section": "Getting bars into the right order",
    "text": "Getting bars into the right order\nWhenever we are making bar plots, we need to think about the correct order of the bars. By default, ggplot uses alphabetic ordering, but that is rarely appropriate. If there is no inherent ordering (such as, for example, a temporal progression), then it is usually best to order by the magnitude of the values, i.e., sort the bars by length.\nWe can do this with the fct_reorder() function, which takes two arguments: The categorical variable we want to re-order, and the values by which we want to order. Here, the categorical variable is the column title and the values are in the column amount. We can apply the fct_reorder() function right inside the aes() statement.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(boxoffice, aes(x = amount, y = fct_reorder(___, ___))) +\n  geom_col() +\n  xlab(\"weekend gross (million USD)\") +\n  ylab(NULL)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(boxoffice, aes(x = amount, y = fct_reorder(title, amount))) +\n  geom_col() +\n  xlab(\"weekend gross (million USD)\") +\n  ylab(NULL)\n\n\n\n\nTry the following additional experiments in the above code:\n\nWhat happens when you run the above code without the ylab(NULL) statement?\nCan you make the bars blue?\nCan you color the bars by amount or by title?"
  },
  {
    "objectID": "worksheets/visualizing-amounts.html#drawing-bars-based-on-a-count",
    "href": "worksheets/visualizing-amounts.html#drawing-bars-based-on-a-count",
    "title": "Visualizing amounts",
    "section": "Drawing bars based on a count",
    "text": "Drawing bars based on a count\nThe boxoffice dataset contains individual values, the dollar amounts, that we wanted to visualize with bars. Often, however, we encounter a slightly different scenario: A dataset doesn’t contain the numeric amounts directly, but instead contains observations we want to count. This is the case in the penguins2 dataset (see above).\nIt contains one row per penguin. If we want to make a bar plot of the number of penguins of each species (Adelie, Chinstrap, Gentoo), we cannot use geom_col() as before, because the dataset doesn’t have a column that contains these counts.\nThe solution here is to use geom_bar(), which performs a count and then displays the result of that count. Because geom_bar() counts automatically, you only have to provide it with a single aesthetic, which specifies the data column in which you are counting.\nTry this out. Make a bar plot of the number of penguins per species. Map the penguin species onto the x axis.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins2, aes(x = ___)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins2, aes(x = species)) +\n  geom_bar()\n\n\n\n\nTry the following additional modifications in the above code:\n\nMap penguin species onto the y axis.\nRemove the axis label that says “species”.\nChange the order of the bars manually, using fct_relevel() (see slides)."
  },
  {
    "objectID": "worksheets/visualizing-amounts.html#counting-subgroups",
    "href": "worksheets/visualizing-amounts.html#counting-subgroups",
    "title": "Visualizing amounts",
    "section": "Counting subgroups",
    "text": "Counting subgroups\ngeom_bar() automatically counts how many cases there are in each unique combination of different categorical aesthetics. In the previous example, we had only one categorical aesthetic, species. But we can add a second one, for example sex. Then geom_bar() counts the number of cases in each unique combination of species and sex and draws separate bars for each. Try this out by mapping the sex column onto the fill aesthetic.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins2, aes(x = species, fill = sex)) +\n  geom_bar()\n\n\n\n\nBy default, the bars for different fill values but identical x values will be drawn on top of one-another. But there are other possibilities, which are controled by the position argument to geom_bar(). For example, try to set the position to \"dodge\".\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins2, aes(x = species, fill = sex)) +\n  geom_bar(position = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins2, aes(x = species, fill = sex)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\nIn the above code, also try positions \"stack\" and \"fill\"."
  },
  {
    "objectID": "worksheets/overplotting.html",
    "href": "worksheets/overplotting.html",
    "title": "Dealing with overplotting",
    "section": "",
    "text": "In this worksheet, we will discuss how to make 2D density plots and histograms, to effectively visualize scatter plots in which many points lie on top of one another.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data. We will be working with data on individual penguins in Antarctica.\npenguins"
  },
  {
    "objectID": "worksheets/overplotting.html#introduction",
    "href": "worksheets/overplotting.html#introduction",
    "title": "Dealing with overplotting",
    "section": "",
    "text": "In this worksheet, we will discuss how to make 2D density plots and histograms, to effectively visualize scatter plots in which many points lie on top of one another.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data. We will be working with data on individual penguins in Antarctica.\npenguins"
  },
  {
    "objectID": "worksheets/overplotting.html#d-density-plots",
    "href": "worksheets/overplotting.html#d-density-plots",
    "title": "Dealing with overplotting",
    "section": "2D density plots",
    "text": "2D density plots\n2D density plots are a replacement for and alternative to scatter plots. They visualize the density of points in the 2D plane, and they are particularly useful when the point density is very high, so that many points lie on top of one another. We will demonstrate 2D density plots for the penguins dataset, specifically for a scatter plot of bill length versus body mass.\n\n\n\n\n\n\n\n\nTo create a 2D density plot, we simply add geom_density_2d(). Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  ___ +\n  geom_point(na.rm = TRUE) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_density_2d(na.rm = TRUE) + \n  geom_point(na.rm = TRUE) +\n  theme_bw()\n\n\n\n\nYou can change the number of contour lines shown by providing the bins argument to geom_density_2d(). For example, try bins = 5.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_density_2d(na.rm = TRUE, bins = ___) + \n  geom_point(na.rm = TRUE) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_density_2d(na.rm = TRUE, bins = 5) + \n  geom_point(na.rm = TRUE) +\n  theme_bw()\n\n\n\n\nAlso try other values for bins.\nThe plots we have made so far did not consider different penguin species, but we know from earlier worksheets that there are three penguins species with quite different values for body mass and bill length. Modify the above plot so that both points and contour lines are colored by species.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm, color = species)) +\n  geom_density_2d(na.rm = TRUE, bins = 5) + \n  geom_point(na.rm = TRUE) +\n  theme_bw()\n\n\n\n\nAlso try faceting by species.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm, color = species)) +\n  geom_density_2d(na.rm = TRUE, bins = 5) + \n  geom_point(na.rm = TRUE) +\n  theme_bw() +\n  facet_wrap(~species)\n\n\n\n\nFinally, you can use geom_density_2d_filled() to draw filled contour bands instead of contour lines. Try this out.\nHints:\n\nYou cannot map penguin species to color when drawing contour bands.\nIt helps to set alpha transparency for contour bands, e.g. alpha = 0.5.\nYou may want to make the point size smaller so you can see the contour bands underneath the points.\n\nNote: This example may not work in the live web environment.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_density_2d_filled(___) + \n  geom_point(na.rm = TRUE, size = ___) +\n  theme_bw() +\n  facet_wrap(~species)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_density_2d_filled(na.rm = TRUE, bins = 5, alpha = 0.5) + \n  geom_point(na.rm = TRUE, size = 0.2) +\n  theme_bw() +\n  facet_wrap(~species)"
  },
  {
    "objectID": "worksheets/overplotting.html#d-histograms",
    "href": "worksheets/overplotting.html#d-histograms",
    "title": "Dealing with overplotting",
    "section": "2D histograms",
    "text": "2D histograms\n2D histograms are very similar to 2D density plots. They are generated by simply subdividing the 2D plane into regularly shaped regions (rectangles or hexagons), counting how many data points fall into each region, and then coloring each region by its count.\nTo make rectangular 2D hexagons, you can use geom_bin2d(). Try this out.\nHint: Set bins = 5 to get a reasonable number of bins for this dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_bin2d(___) + \n  geom_point(na.rm = TRUE, size = 0.2) +\n  theme_bw() +\n  facet_wrap(~species)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_bin2d(na.rm = TRUE, bins = 5) + \n  geom_point(na.rm = TRUE, size = 0.2) +\n  theme_bw() +\n  facet_wrap(~species)\n\n\n\n\nIt helps to make the bins partially transparent (i.e., set alpha = 0.5). Also use a different sequential color scale.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_bin2d(na.rm = TRUE, bins = 5, ___) + \n  geom_point(na.rm = TRUE, size = 0.2) +\n  theme_bw() +\n  facet_wrap(~species) +\n  scale_fill____\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_bin2d(na.rm = TRUE, bins = 5, alpha = 0.5) + \n  geom_point(na.rm = TRUE, size = 0.2) +\n  theme_bw() +\n  facet_wrap(~species) +\n  scale_fill_viridis_c()\n\n\n\n\nYou can control bins in a more fine-grained manner by setting the binwidth argument. It takes a vector of two numbers, where the first is the width of the bins (in data units) and the second is the height (also in data units). Make bins that are 10000 units wide and 5 units tall.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_bin2d(\n    na.rm = TRUE,\n    binwidth = ___,\n    alpha = 0.5\n  ) + \n  geom_point(na.rm = TRUE, size = 0.2) +\n  theme_bw() +\n  facet_wrap(~species) +\n  scale_fill_viridis_c()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_bin2d(\n    na.rm = TRUE,\n    binwidth = c(10000, 5),\n    alpha = 0.5\n  ) + \n  geom_point(na.rm = TRUE, size = 0.2) +\n  theme_bw() +\n  facet_wrap(~species) +\n  scale_fill_viridis_c()\n\n\n\n\nAlso try making bins that are 30 units tall and 2500 units wide.\nInstead of rectangular bins, you can also make hexbins, with geom_hex(). It mostly works the same as geom_bin2d(). Try it out.\nHint: You will need to set the argument bins to an appropriate value for the hexbins to look good.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_hex(\n    ___\n  ) + \n  geom_point(na.rm = TRUE, size = 0.2) +\n  theme_bw() +\n  facet_wrap(~species) +\n  scale_fill_viridis_c()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_hex(\n    na.rm = TRUE,\n    bins = 5,\n    alpha = 0.5\n  ) + \n  geom_point(na.rm = TRUE, size = 0.2) +\n  theme_bw() +\n  facet_wrap(~species) +\n  scale_fill_viridis_c()\n\n\n\n\nJust as was the case with geom_bin2d(), you can provide an argument binwidth consisting of two values, one controling the width and the other the height. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_hex(\n    na.rm = TRUE,\n    binwidth = ___\n    alpha = 0.5\n  ) + \n  geom_point(na.rm = TRUE, size = 0.2) +\n  theme_bw() +\n  facet_wrap(~species) +\n  scale_fill_viridis_c()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm)) +\n  geom_hex(\n    na.rm = TRUE,\n    binwidth = c(1000, 5),\n    alpha = 0.5\n  ) + \n  geom_point(na.rm = TRUE, size = 0.2) +\n  theme_bw() +\n  facet_wrap(~species) +\n  scale_fill_viridis_c()"
  },
  {
    "objectID": "worksheets/know-your-data-1.html",
    "href": "worksheets/know-your-data-1.html",
    "title": "Getting to know your data 1",
    "section": "",
    "text": "In this worksheet, we will discuss how to perform basic inspection of a dataset and simple data-cleaning tasks.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the dataset NCbirths, which contains data about 1450 births in the state of North Carolina in 2001.\nNCbirths"
  },
  {
    "objectID": "worksheets/know-your-data-1.html#introduction",
    "href": "worksheets/know-your-data-1.html#introduction",
    "title": "Getting to know your data 1",
    "section": "",
    "text": "In this worksheet, we will discuss how to perform basic inspection of a dataset and simple data-cleaning tasks.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the dataset NCbirths, which contains data about 1450 births in the state of North Carolina in 2001.\nNCbirths"
  },
  {
    "objectID": "worksheets/know-your-data-1.html#basic-inspection-of-the-data",
    "href": "worksheets/know-your-data-1.html#basic-inspection-of-the-data",
    "title": "Getting to know your data 1",
    "section": "Basic inspection of the data",
    "text": "Basic inspection of the data\nWhen first working with a new dataset, you should always start by just looking at the data. The simplest way to do this is to just enter the name of the dataset in the R command line and run, which causes the data to be printed. You can also use head(...) to only see the first six rows or glimpse(...) to get a list of all columns with their type and first few values.\nTry this yourself. Write code that displays the entire NCbirths dataset, the first six rows, or a list of all columns.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nNCbirths\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nhead(NCbirths)\nglimpse(NCbirths)\nNCbirths\n\n\n\n\nIt is often useful to get a list of all names of the columns in a data frame. You can obtain this with names(...). Try this yourself.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nnames(NCbirths)\n\n\n\n\nTo inspect individual columns, you can extract them either with pull() like so: data |&gt; pull(column) or with the $ operator like so: data$column. The second option is shorter but the first option integrates better into longer analysis pipelines. Try both options on the NCbirths dataset, for example for the Smoke column.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# option using pull()\nNCbirths |&gt;\n  pull(Smoke)\n\n# option using $ operator\nNCbirths$Smoke\n\n\n\n\nFinally, to see all distinct values in a column, you can apply the function unique() to it. Try this with the Smoke column.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nNCbirths |&gt;\n  pull(Smoke) |&gt;\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNCbirths |&gt;\n  pull(Smoke) |&gt;\n  unique()"
  },
  {
    "objectID": "worksheets/know-your-data-1.html#recoding-of-data-values",
    "href": "worksheets/know-your-data-1.html#recoding-of-data-values",
    "title": "Getting to know your data 1",
    "section": "Recoding of data values",
    "text": "Recoding of data values\nWe frequently want to recode data values such that they are more humanly readable. For example, we might want to write smoker/non-smoker instead of 1/0. We can do this with if_else(), which takes three arguments: a logical condition, the data value if the logical condition is true, and the data value if the logical condition is false. Try this out on the Smoke column, creating a new column Smoke_recoded that is human-readable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nNCbirths |&gt;\n  mutate(\n    Smoke_recoded = if_else(___, ___, ___)\n  ) |&gt;\n  select(Smoke, Smoke_recoded) |&gt;\n  unique()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNCbirths |&gt;\n  mutate(\n    Smoke_recoded = if_else(Smoke == 0, \"non-smoker\", \"smoker\")\n  ) |&gt;\n  select(Smoke, Smoke_recoded) |&gt;\n  unique()\n\n\n\n\nWhen you want to recode a variable with more than two categories, you could nest if_else() commands, but usually it is simpler to use case_when(). With case_when(), you provide a list of conditions and corresponding data values as formulas of the form condition ~ data value. For example, the recoding exercise for the Smoke column could be written with case_when() as follows:\n\n\n\n\n\n\n\n\nWhen using case_when(), it is usually a good idea to provide an explicit fallback that is used when none of the earlier conditions match. The logical conditions are evaluated in order, so you want to list the most specific conditions first and the least specific conditions last. The fallback condition is simply TRUE. It applies always if no previous condition applied.\nNow use case_when() to recode the Plural column into singlet/twins/triplets.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nNCbirths |&gt;\n  mutate(\n    Plural_recoded = case_when(\n      Plural == 1 ~ \"singlet\",\n      ___,\n      ___,\n      ___\n    )\n  ) |&gt;\n  select(Plural, Plural_recoded) |&gt;\n  unique()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNCbirths |&gt;\n  mutate(\n    Plural_recoded = case_when(\n      Plural == 1 ~ \"singlet\",\n      Plural == 2 ~ \"twins\",\n      Plural == 3 ~ \"triplets\",\n      TRUE ~ NA\n    )\n  ) |&gt;\n  select(Plural, Plural_recoded) |&gt;\n  unique()"
  },
  {
    "objectID": "worksheets/know-your-data-1.html#summaries-of-data-columns",
    "href": "worksheets/know-your-data-1.html#summaries-of-data-columns",
    "title": "Getting to know your data 1",
    "section": "Summaries of data columns",
    "text": "Summaries of data columns\nWhen exploring a new dataset, it is usually a good idea to look at summaries of the data values in each column, to get a quick sense of the range of data values, to see whether there are any unexpected outliers, etc. There are two useful functions for this purpose, summary() for numerical data and table() for categorical data.\nFirst try this for numerical data. Perform summaries for the data columns MomAge, Weeks, and BirthWeightGm.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nsummary(NCbirths$MomAge)\n___\n___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nsummary(NCbirths$MomAge)\nsummary(NCbirths$Weeks)\nsummary(NCbirths$BirthWeightGm)\n\n\n\n\nNow try this for categorical data. Perform summaries for the data columns Plural, Smoke, and RaceMom.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntable(NCbirths$Plural)\n___\n___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntable(NCbirths$Plural)\ntable(NCbirths$Smoke)\ntable(NCbirths$RaceMom)\n\n\n\n\nDo you understand what the output means? If not, look it up in the R documentation for the table() function.\nOne quirk of the table() function is that by default it omits any NA values. However, it is important to know whether there are any NA values in a data column or not. We can get table() to tabulate NAs as well by providing it with the argument useNA = \"ifany\". Repeat the previous exercise with this modification and see which of the three columns Plural, Smoke, or RaceMom contain any NAs.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntable(NCbirths$Plural, useNA = \"ifany\")\n___\n___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntable(NCbirths$Plural, useNA = \"ifany\")\ntable(NCbirths$Smoke, useNA = \"ifany\")\ntable(NCbirths$RaceMom, useNA = \"ifany\")"
  },
  {
    "objectID": "worksheets/intro-to-Quarto.html",
    "href": "worksheets/intro-to-Quarto.html",
    "title": "Introduction to Quarto",
    "section": "",
    "text": "All assignments in this class will be done via Quarto documents. Quarto documents are documents that combine text, code, and output, including figures. They are a great way to produce self-contained and documented statistical analyses. Quarto has support for a variety of popular programming languages for data analysis, including R and python.\nTo get familiar with Quarto, please download this Quarto template worksheet, complete it, and render into a PDF. You will use this same workflow in all homeworks and projects throughout the semester."
  },
  {
    "objectID": "worksheets/hierarchical-clustering.html",
    "href": "worksheets/hierarchical-clustering.html",
    "title": "Hierarchical clustering",
    "section": "",
    "text": "In this worksheet, we will discuss how to perform hierarchical clustering.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data. It’s a downsampled and slightly modified version of the penguins dataset from the package palmerpenguins."
  },
  {
    "objectID": "worksheets/hierarchical-clustering.html#introduction",
    "href": "worksheets/hierarchical-clustering.html#introduction",
    "title": "Hierarchical clustering",
    "section": "",
    "text": "In this worksheet, we will discuss how to perform hierarchical clustering.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data. It’s a downsampled and slightly modified version of the penguins dataset from the package palmerpenguins."
  },
  {
    "objectID": "worksheets/hierarchical-clustering.html#calculating-a-distance-matrix",
    "href": "worksheets/hierarchical-clustering.html#calculating-a-distance-matrix",
    "title": "Hierarchical clustering",
    "section": "Calculating a distance matrix",
    "text": "Calculating a distance matrix\nMany hierarchical clustering algorithms start with calculating a distance matrix. This is done with the built-in R function dist(). Before calculating distances, though, you should first scale the data to zero mean and unit variance, just like we have done previously for PCA and other multivariate techniques. As a reminder, you scale a dataset with the function scale().\nTry this out on the penguins_sampled dataset. Scale the data and then calculate the distance matrix.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins_sampled |&gt;\n  scale() |&gt;\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins_sampled |&gt;\n  scale() |&gt;\n  dist()\n\n\n\n\nBy default, the dist() function calculates Euclidean distances. But other options exist, which can be selected via the method argument to the dist() function. Commonly used options include \"maximum\", \"manhattan\", or \"minkowski\". Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins_sampled |&gt;\n  scale() |&gt;\n  dist(method = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins_sampled |&gt;\n  scale() |&gt;\n  dist(method = \"maximum\")\n\n# also try \"manhattan\" and \"minkowski\"\n\n\n\n\nWhen using the Minkowski distance, you should also set the parameter p. The Minkowski distance is a generalization of both the Euclidean and the Manhattan distance, and the parameter p interpolates between these distance types.\nVerify that the Minkowski distance is identical to the Euclidean distance for p = 2 and identical to the Manhattan distance for p = 1. The simplest way to do this is to calculate the two distance matrices and then subtract them from each other and check that the values are 0.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n# calculate distances\nd_eucl &lt;- penguins_sampled |&gt;\n  scale() |&gt;\n  dist(method = \"euclidean\")\n\nd_mink &lt;- penguins_sampled |&gt;\n  scale() |&gt;\n  dist(method = \"minkowski\", p = 2)\n\n# then subtract to check for equality\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# calculate distances\nd_eucl &lt;- penguins_sampled |&gt;\n  scale() |&gt;\n  dist(method = \"euclidean\")\n\nd_mink &lt;- penguins_sampled |&gt;\n  scale() |&gt;\n  dist(method = \"minkowski\", p = 2)\n\n# then subtract to check for equality\nd_eucl - d_mink"
  },
  {
    "objectID": "worksheets/hierarchical-clustering.html#performing-hierarchical-clustering",
    "href": "worksheets/hierarchical-clustering.html#performing-hierarchical-clustering",
    "title": "Hierarchical clustering",
    "section": "Performing hierarchical clustering",
    "text": "Performing hierarchical clustering\nTo perform hierarchical clustering, you simply run the function hclust() on a distance matrix previously computed with dist(). You can then visualize the result with ggdendrogram() from the ggdendro package. Try this out. (Hint: Write one consecutive sequence of pipe commands.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins_sampled |&gt;\n  scale() |&gt;\n  dist() |&gt;\n  hclust() |&gt;\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins_sampled |&gt;\n  scale() |&gt;\n  dist() |&gt;\n  hclust() |&gt;\n  ggdendrogram()\n\n\n\n\nIn the ggdendrogram() function, you can set rotate = TRUE to arrange the leaves of the dendrogram vertically instead of horizontally. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins_sampled |&gt;\n  scale() |&gt;\n  dist() |&gt;\n  hclust() |&gt;\n  ggdendrogram(rotate = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins_sampled |&gt;\n  scale() |&gt;\n  dist() |&gt;\n  hclust() |&gt;\n  ggdendrogram(rotate = TRUE)\n\n\n\n\nYou can run different clustering algorithms by changing the method argument of hclust(). method = \"average\" uses UPGMA, method = \"ward.D2\" uses Ward’s minimum variance method, and method = \"complete\" uses the complete linkage method. Modify the example above to try these different methods."
  },
  {
    "objectID": "worksheets/hierarchical-clustering.html#assigning-observations-to-clusters",
    "href": "worksheets/hierarchical-clustering.html#assigning-observations-to-clusters",
    "title": "Hierarchical clustering",
    "section": "Assigning observations to clusters",
    "text": "Assigning observations to clusters\nIn hierarchical clustering, if we want to assign each observation to a cluster, we need to cut the dendrogram into disjoint parts. There are two ways in which we can do this. First, we can cut such that we obtain a specific number of clusters. Second, we can cut at a set height and see how many clusters we obtain.\nWe can cut a dendrogram with the function cutree(), which takes as input the output from hclust() and either an argument k to determine how many clusters we want or an argument h to determine at which height we want to cut the tree. Let’s try the first approach first. Cut the penguin dendrogram such that there are three clusters. Then check whether the three clusters correspond to the three species.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins_sampled |&gt;\n  scale() |&gt;\n  dist() |&gt;\n  hclust() |&gt;\n  cutree(k = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins_sampled |&gt;\n  scale() |&gt;\n  dist() |&gt;\n  hclust() |&gt;\n  cutree(k = 3)\n\n\n\n\nNext, by trial-and-error, find a cut height at which you obtain exactly three clusters.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins_sampled |&gt;\n  scale() |&gt;\n  dist() |&gt;\n  hclust() |&gt;\n  cutree(h = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins_sampled |&gt;\n  scale() |&gt;\n  dist() |&gt;\n  hclust() |&gt;\n  cutree(h = 2.9)\n\n\n\n\nCould you have used the function ggdendrogram() to arrive at a good guess for the value of h?\nFinally, try different distance methods and see whether the clusters continue to match species identity when you cut into k = 3 clusters. Can you find a distance metric for which the clusters do not match the species?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# for Manhattan distance, Adelie and Chinstrap are mixed together\npenguins_sampled |&gt;\n  scale() |&gt;\n  dist(method = \"manhattan\") |&gt;\n  hclust() |&gt;\n  cutree(k = 3)"
  },
  {
    "objectID": "worksheets/geospatial-data.html",
    "href": "worksheets/geospatial-data.html",
    "title": "Visualizing geospatial data",
    "section": "",
    "text": "In this worksheet, we will discuss we will discuss how to visualize geospatial data.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the datasets texas_income and texas_counties. The dataset texas_income contains the median income of all counties in Texas, as well as the shape information about each county (stored in the geometry column). The column FIPS contains a five-digit id code that uniquely represents each county.\n\n\n\n\n\n\n\n\nThe dataset texas_counties holds information about how many people lived in Texas counties in 2010, as well as the size of each county (column area). The column popratio is the ratio of the number of inhabitants to the median across all counties. The column FIPS contains a five-digit id code that uniquely represents each county."
  },
  {
    "objectID": "worksheets/geospatial-data.html#introduction",
    "href": "worksheets/geospatial-data.html#introduction",
    "title": "Visualizing geospatial data",
    "section": "",
    "text": "In this worksheet, we will discuss we will discuss how to visualize geospatial data.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the datasets texas_income and texas_counties. The dataset texas_income contains the median income of all counties in Texas, as well as the shape information about each county (stored in the geometry column). The column FIPS contains a five-digit id code that uniquely represents each county.\n\n\n\n\n\n\n\n\nThe dataset texas_counties holds information about how many people lived in Texas counties in 2010, as well as the size of each county (column area). The column popratio is the ratio of the number of inhabitants to the median across all counties. The column FIPS contains a five-digit id code that uniquely represents each county."
  },
  {
    "objectID": "worksheets/geospatial-data.html#wrangling-data",
    "href": "worksheets/geospatial-data.html#wrangling-data",
    "title": "Visualizing geospatial data",
    "section": "Wrangling data",
    "text": "Wrangling data\nBefore we perform any visualizations, we will first gain some experience manipulating data tables containing geospatial information. This does not require us to learn any new concepts, as data tables with geospatial information (i.e., containing a geometry column) can be manipulated just like those without.\nLet’s try this out. Take the texas_income table and filter out the rows for the counties “Travis” and “Harris”.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntexas_income |&gt;\n  filter(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntexas_income |&gt;\n  filter(county %in% c(\"Travis\", \"Harris\"))\n\n\n\n\nNow join the texas_income table with the texas_counties table and then find the five largest counties.\nHint: Use the function left_join() to join the tables, and use the functions arrange() and slice() to find the five largest counties.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntexas_income |&gt;\n  left_join(___) |&gt;\n  ___\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntexas_income |&gt;\n  left_join(texas_counties) |&gt;\n  arrange(___) |&gt;\n  slice(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntexas_income |&gt;\n  left_join(texas_counties) |&gt;\n  arrange(desc(area)) |&gt;\n  slice(1:5)"
  },
  {
    "objectID": "worksheets/geospatial-data.html#visualizing-simple-features",
    "href": "worksheets/geospatial-data.html#visualizing-simple-features",
    "title": "Visualizing geospatial data",
    "section": "Visualizing simple features",
    "text": "Visualizing simple features\nWe can visualize datasets containing simple features with the function geom_sf(). This geom is very simple to use, as it automatically finds the geometry column and draws it in the appropriate coordinate system. All we need to think about is whether we want to apply a color mapping, e.g. to make a choropleth.\nTry this out by making a plot of the counties in Texas, without applying any kind of aesthetic mapping. Remember, the dataset texas_income contains the required geometry information.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(texas_income) +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(texas_income) +\n  geom_sf()\n\n\n\n\nNow map the data column median_income to the fill color. Also choose an appropriate color scale from the colorspace package.\nHint: You can see the available color palettes here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(texas_income) +\n  geom_sf(aes(fill = ___)) +\n  scale_fill_continuous_sequential(palette = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(texas_income) +\n  geom_sf(aes(fill = median_income)) +\n  scale_fill_continuous_sequential(palette = \"Lajolla\")\n\n\n\n\nFinally, make a plot that highlights the 10 smallest counties in Texas. This will require you to join texas_income and texas_counties first.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntexas_income |&gt;\n  left_join(texas_counties) |&gt;\n  mutate(\n    smallest = rank(area) &lt;= 5\n  )\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntexas_income |&gt;\n  left_join(texas_counties) |&gt;\n  mutate(\n    smallest = rank(area) &lt;= 5\n  ) |&gt;\n  ggplot() +\n  geom_sf(aes(fill = ___))\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntexas_income |&gt;\n  left_join(texas_counties) |&gt;\n  mutate(\n    smallest = rank(area) &lt;= 5\n  ) |&gt;\n  ggplot() +\n  geom_sf(aes(fill = smallest))\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntexas_income |&gt;\n  left_join(texas_counties) |&gt;\n  mutate(\n    smallest = rank(area) &lt;= 5\n  ) |&gt;\n  ggplot() +\n  geom_sf(aes(fill = smallest), size = 0.2) +\n  scale_fill_manual(\n    values = c(\n      `TRUE` = \"#D55E00\",\n      `FALSE` = \"#E8EEF9\"\n    )\n  )"
  },
  {
    "objectID": "worksheets/geospatial-data.html#changing-the-projection",
    "href": "worksheets/geospatial-data.html#changing-the-projection",
    "title": "Visualizing geospatial data",
    "section": "Changing the projection",
    "text": "Changing the projection\nOne major benefit of the sf framework is that different map projections are built in and supported out-of-the-box. We can refer to projections by their EPSG codes, and these codes can be looked up on websites such as https://spatialreference.org/ or https://epsg.io/.\nWe can set the coordinate system via coord_sf(), which takes an argument crs that specifies the Coordinate Reference System (CRS). For example, coord_sf(crs = 3083) will select a Texas Centric Albers Equal Area projection (https://spatialreference.org/ref/epsg/3083/). Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(texas_income) +\n  geom_sf() +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(texas_income) +\n  geom_sf() +\n  coord_sf(crs = 3083)\n\n\n\n\nHere are a few other coordinate systems to try out, to see how different projections affect how the map looks.\n\nEPSG:32139: Texas Centric Lambert Conformal Conic; notice the subtle changes compared to 3083.\nEPSG:3857: Web Mercator, used e.g. by Google Maps; not a good projection in practice.\nEPSG:3338: Alaska Albers equal area; not appropriate for Texas, but shows more extreme changes in the plot"
  },
  {
    "objectID": "worksheets/figure-design.html",
    "href": "worksheets/figure-design.html",
    "title": "Figure design",
    "section": "",
    "text": "In this worksheet, we will discuss how to change and customize plot appearance through themes.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nWe will be working with the dataset penguins, which contains data on individual penguins on Antarctica.\npenguins"
  },
  {
    "objectID": "worksheets/figure-design.html#introduction",
    "href": "worksheets/figure-design.html#introduction",
    "title": "Figure design",
    "section": "",
    "text": "In this worksheet, we will discuss how to change and customize plot appearance through themes.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nWe will be working with the dataset penguins, which contains data on individual penguins on Antarctica.\npenguins"
  },
  {
    "objectID": "worksheets/figure-design.html#ready-made-themes",
    "href": "worksheets/figure-design.html#ready-made-themes",
    "title": "Figure design",
    "section": "Ready-made themes",
    "text": "Ready-made themes\nLet’s start with this simple plot with no specific styling.\n\n\n\n\n\n\n\n\nThe default ggplot theme is theme_gray(). Verify that adding this theme to the plot makes no difference in the output. Then change the overall font size by providing the theme function with a numeric font size argument, e.g. theme_gray(16).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_gray()\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_gray(16)\n\n\n\n\nThe ggplot2 package has many built-in themes, including theme_minimal(), theme_bw(), theme_void(), theme_dark(). Try these different themes on the above plot. Also try again changing the font size. You can see all themes provided by ggplot2 here: https://ggplot2.tidyverse.org/reference/ggtheme.html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_bw(12)\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_minimal(14)\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_void()\n\n\n\n\nMany other packages also provide themes. For example, the cowplot package provides themes theme_half_open(), theme_minimal_grid(), theme_minimal_hgrid(), and theme_minimal_vgrid(). You can see all cowplot themes here: https://wilkelab.org/cowplot/articles/themes.html Try these out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_half_open()\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_minimal_grid()\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_minimal_hgrid()\n\n\n\n\nCompare the visual appearance of theme_minimal() from ggplot2 to theme_minimal_grid() from cowplot. What similarities and differences to you notice? Which do you prefer? (There is no correct answer here, just be aware of the differences and of your preferences.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_minimal()\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_minimal_grid()"
  },
  {
    "objectID": "worksheets/figure-design.html#modifying-theme-elements",
    "href": "worksheets/figure-design.html#modifying-theme-elements",
    "title": "Figure design",
    "section": "Modifying theme elements",
    "text": "Modifying theme elements\nYou can modify theme elements by adding a theme() call to the plot. Inside the theme() call you specify which theme element you want to modify (e.g., axis.title, axis.text.x, panel.background, etc) and what changes you want to make. For example, to make axis titles blue, you would write:\ntheme(\n  axis.title = element_text(color = \"blue\")\n)\nThere are many theme settings, and for each one you need to know what type of an element it is (for example, element_text(), element_line(), element_rect() for text, lines, or rectangles, respectively). A complete description of the available options is available at the ggplot2 website: https://ggplot2.tidyverse.org/reference/theme.html\nHere, we will only try a few simple things. For example, see if you can make the legend title blue and the legend text red.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme(\n    legend.title = ___,\n    legend.text = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme(\n    legend.title = element_text(color = \"blue\"),\n    legend.text = element_text(color = \"red\")\n  )\n\n\n\n\nNow color the area behind the legend in \"aliceblue\". Hint: The theme element you need to change is called legend.background. There is also an element legend.box.background but it is only visible if legend.background is not shown, and in the default ggplot2 themes that is not the case.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme(\n    legend.background = element_rect(___)\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme(\n    legend.background = element_rect(fill = \"aliceblue\")\n  )\n\n\n\n\nAnother commonly used feature in themes are margins. Many parts of the plot theme can understand customized margins, which control how much spacing there is between different parts of a plot. Margins are typically specified with the function margin(), which takes four numbers specifying the margins in points, in the order top, right, bottom, left. So, margin(10, 5, 5, 10) would specify a top margin of 10pt, a right margin of 5pt, a bottom margin of 5pt, and a left margin of 10pt.\nTry this out by setting the legend margin (element legend.margin) such that there is no top and no bottom margin but 10pt left and right margin.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme(\n    legend.background = element_rect(fill = \"aliceblue\"),\n    legend.margin = margin(___)\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme(\n    legend.background = element_rect(fill = \"aliceblue\"),\n    legend.margin = margin(0, 10, 0, 10)\n  )\n\n\n\n\nThere are many other things you can do. Try at least some of the following:\n\nChange the horizontal or vertical justification of text with hjust and vjust.\nChange the font family with family.1\nChange the panel grid. For example, create only horizontal lines, or only vertical lines.\nChange the overall margin of the plot with plot.margin.\nMove the position of the legend with legend.position and legend.justification.\nTurn off some elements by setting them to element_blank().\n\n1 Getting fonts to work well can be tricky in R. Which specific fonts work depends on the graphics device and the operating system. The following fonts work on the edupod class server: \"Palatino\", \"Times\", \"Helvetica\", \"Courier\", \"ITC Bookman\", \"ITC Avant Garde Gothic\", \"ITC Zapf Chancery\"."
  },
  {
    "objectID": "worksheets/figure-design.html#writing-your-own-theme",
    "href": "worksheets/figure-design.html#writing-your-own-theme",
    "title": "Figure design",
    "section": "Writing your own theme",
    "text": "Writing your own theme\nYou can write a theme by taking an existing theme and making some modifications, like so:\n\n\n\n\n\n\n\n\nNow try this out on the penguins scatter plot.\nHint: When using this theme, do you have to add theme_colorful or theme_colorful() to the plot? Do you understand which option is correct and why? If you are unsure, try both and see what happens.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(flipper_length_mm, body_mass_g, color = species)) +\n  geom_point(na.rm = TRUE) +\n  theme_colorful\n\n\n\n\nNow write your own theme and then add it to the penguins plot."
  },
  {
    "objectID": "worksheets/dimension-reduction-1.html",
    "href": "worksheets/dimension-reduction-1.html",
    "title": "Dimension reduction 1",
    "section": "",
    "text": "In this worksheet, we will discuss how to perform principal components analysis (PCA).\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the dataset blue_jays. It contains various measurements taken on blue jay birds."
  },
  {
    "objectID": "worksheets/dimension-reduction-1.html#introduction",
    "href": "worksheets/dimension-reduction-1.html#introduction",
    "title": "Dimension reduction 1",
    "section": "",
    "text": "In this worksheet, we will discuss how to perform principal components analysis (PCA).\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the dataset blue_jays. It contains various measurements taken on blue jay birds."
  },
  {
    "objectID": "worksheets/dimension-reduction-1.html#performing-a-pca",
    "href": "worksheets/dimension-reduction-1.html#performing-a-pca",
    "title": "Dimension reduction 1",
    "section": "Performing a PCA",
    "text": "Performing a PCA\nWe can perform a PCA with the function prcomp(). However, we first need to prepare the data. PCA can only take numeric columns, and it is best to scale all variables to zero mean and unit variance.\nWe can select all numeric columns in a dataset with select(where(is.numeric)) and we can scale an entire dataset consisting of only numeric columns with scale(). Try this on the blue_jays dataset. Modify the dataset so it is entirely numeric and properly scaled.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nblue_jays |&gt;\n  select(where(is.numeric)) |&gt;\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nblue_jays |&gt;\n  select(where(is.numeric)) |&gt;\n  scale()\n\n\n\n\nNext run prcomp() on this modified dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nblue_jays |&gt;\n  select(where(is.numeric)) |&gt;\n  scale() |&gt;\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nblue_jays |&gt;\n  select(where(is.numeric)) |&gt;\n  scale() |&gt;\n  prcomp()\n\n\n\n\nIn practice, we store the output from prcomp() in a variable for subsequent downstream manipulations:\n\n\n\n\n\n\n\n\nThen we can extract useful data from this model fit object by running various functions from the broom package on it. For example, the tidy() function extracts model parameters in a tidy format. It takes an argument matrix that can take the values \"scores\", \"rotation\", and \"eigenvalues\". See what these different options do.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npca_fit |&gt;\n  tidy(matrix = \"scores\")\n\npca_fit |&gt;\n  tidy(matrix = \"rotation\")\n\npca_fit |&gt;\n  tidy(matrix = \"eigenvalues\")\n\n\n\n\nWe can also add the original dataset back into the PCA coordinates via the augment() function. This is helpful for example when we want to plot values from the original dataset (such as some of the categorical variables removed at the first step of the analysis) in the transformed coordinate system. Try out how augment() works.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npca_fit |&gt;\n  augment(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npca_fit |&gt;\n  augment(blue_jays)"
  },
  {
    "objectID": "worksheets/dimension-reduction-1.html#making-a-pca-plot",
    "href": "worksheets/dimension-reduction-1.html#making-a-pca-plot",
    "title": "Dimension reduction 1",
    "section": "Making a PCA plot",
    "text": "Making a PCA plot\nWhen plotting the results from a PCA, we usually make three separate plots: (i) we plot the individual data points in PC coordinates, (ii) we plot the rotation matrix, and (iii) we plot the variance explained by each components. Let’s discuss each of these in turn.\n\nPlotting individual data points in PC coordinates\nIn the previous subsection, we used augment() to add the original dataset back into the PCA coordinates. The result from this computation can be used directly in ggplot. Try this out by plotting PC 2 versus PC 1 and coloring by the sex of the birds. Remember: The columns containing PC coordinates are called .fittedPC1, .fittedPC2, etc.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npca_fit |&gt;\n  augment(blue_jays) |&gt;\n  ggplot(aes(.fittedPC1, .fittedPC2, color = sex)) +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npca_fit |&gt;\n  augment(blue_jays) |&gt;\n  ggplot(aes(.fittedPC1, .fittedPC2, color = sex)) +\n  geom_point() +\n  coord_fixed()\n\n\n\n\nTry also plotting other PC coordinates, e.g. PC 3 vs PC 2 or PC 3 vs PC 1.\n\n\nPlotting the rotation matrix\nTo plot the rotation matrix we require a bit of boiler-plate code. It is always the same, so it’s fine to copy-and-paste when needed. This is the baseline for a rotation-matrix plot:\n# define an arrow style\narrow_style &lt;- arrow(\n  angle = 20, length = grid::unit(8, \"pt\"),\n  ends = \"first\", type = \"closed\"\n)\n\npca_fit |&gt;\n  tidy(matrix = \"rotation\") |&gt;  # extract rotation matrix\n  pivot_wider(\n    names_from = \"PC\", values_from = \"value\",\n    names_prefix = \"PC\"\n  ) |&gt;\n  ggplot(aes(PC1, PC2)) +\n  geom_segment(\n    xend = 0, yend = 0,\n    arrow = arrow_style\n  ) +\n  geom_text(aes(label = column)) +\n  coord_fixed(\n    # you will generally have to set the limits appropriately\n    xlim = ___,\n    ylim = ___\n  )\nUse the above code to plot the rotation matrix for the blue jays PCA analysis. Make two customizations: 1. Change the x and y limits to appropriate values. Use hjust and/or vjust in geom_text() to aligne the text labels appropriately.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# define an arrow style\narrow_style &lt;- arrow(\n  angle = 20, length = grid::unit(8, \"pt\"),\n  ends = \"first\", type = \"closed\"\n)\n\npca_fit |&gt;\n  tidy(matrix = \"rotation\") |&gt;  # extract rotation matrix\n  pivot_wider(\n    names_from = \"PC\", values_from = \"value\",\n    names_prefix = \"PC\"\n  ) |&gt;\n  ggplot(aes(PC1, PC2)) +\n  geom_segment(\n    xend = 0, yend = 0,\n    arrow = arrow_style\n  ) +\n  geom_text(aes(label = column), hjust = 1) +\n  coord_fixed(\n    xlim = c(-1.7, .5),\n    ylim = c(-1, 1)\n  )\n\n\n\n\nNow do the same for PC 2 versus PC 3. (Hint: This means putting PC 3 on the x axis.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# define an arrow style\narrow_style &lt;- arrow(\n  angle = 20, length = grid::unit(8, \"pt\"),\n  ends = \"first\", type = \"closed\"\n)\n\npca_fit |&gt;\n  tidy(matrix = \"rotation\") |&gt;  # extract rotation matrix\n  pivot_wider(\n    names_from = \"PC\", values_from = \"value\",\n    names_prefix = \"PC\"\n  ) |&gt;\n  ggplot(aes(PC3, PC2)) +\n  geom_segment(\n    xend = 0, yend = 0,\n    arrow = arrow_style\n  ) +\n  geom_text(aes(label = column), hjust = c(1, 0, 1, 1, 1, 1)) +\n  coord_fixed(\n    xlim = c(-1.3, 1.8),\n    ylim = c(-1, .8)\n  )\n\n\n\n\n\n\nPlotting the eigenvalues (variance explained)\nTo plot the variance explained, we extract the eigenvalues with the function tidy(), as discussed above. As a reminder, do this one more time and inspect the structure of the output.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npca_fit |&gt;\n  tidy(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npca_fit |&gt;\n  tidy(matrix = \"eigenvalues\")\n\n\n\n\nNow make a bar plot of the percent variance explained (column percent) by each PC.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npca_fit |&gt;\n  tidy(matrix = \"eigenvalues\") |&gt;\n  ggplot(___) + \n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npca_fit |&gt;\n  tidy(matrix = \"eigenvalues\") |&gt;\n  ggplot(aes(PC, percent)) +\n  geom_col() +\n  scale_x_continuous(breaks = 1:6) +\n  scale_y_continuous(labels = scales::label_percent())"
  },
  {
    "objectID": "worksheets/data-wrangling-1.html",
    "href": "worksheets/data-wrangling-1.html",
    "title": "Data wrangling 1",
    "section": "",
    "text": "In this worksheet, we will discuss how to perform basic data manipulations, such as filtering data rows that meet certain conditions, choosing data columns, and arranging data in ascending or descending order.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data. We will be working with data on individual penguins in Antarctica.\npenguins"
  },
  {
    "objectID": "worksheets/data-wrangling-1.html#introduction",
    "href": "worksheets/data-wrangling-1.html#introduction",
    "title": "Data wrangling 1",
    "section": "",
    "text": "In this worksheet, we will discuss how to perform basic data manipulations, such as filtering data rows that meet certain conditions, choosing data columns, and arranging data in ascending or descending order.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data. We will be working with data on individual penguins in Antarctica.\npenguins"
  },
  {
    "objectID": "worksheets/data-wrangling-1.html#the-pipe-symbol-read-and-then",
    "href": "worksheets/data-wrangling-1.html#the-pipe-symbol-read-and-then",
    "title": "Data wrangling 1",
    "section": "The pipe (symbol |>, read “and then”)",
    "text": "The pipe (symbol |&gt;, read “and then”)\nWhen writing complex data analysis pipelines, we frequently use the pipe operator |&gt; to move data from one analysis step to the next. The pipe is pronounced “and then”, and it takes the data on its left and uses it as the first argument for the function on its right.\nFor example, to see the first few lines of a dataset, we often write head(data). Instead, we can write data |&gt; head().\nTry this yourself. Write code that displays the first few lines of the penguins dataset, using |&gt; and head():\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins ___ head()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt; head()\n\n\n\n\nIn older R code, you may also see %&gt;% (called the “magrittr” pipe) instead of |&gt; (the “native” pipe). While these two operators have subtle differences, for all intents and purposes you can treat them interchangeably. Try the previous exercise with the magrittr pipe instead of the native pipe.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins ___ head()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins %&gt;% head()"
  },
  {
    "objectID": "worksheets/data-wrangling-1.html#choosing-data-rows",
    "href": "worksheets/data-wrangling-1.html#choosing-data-rows",
    "title": "Data wrangling 1",
    "section": "Choosing data rows",
    "text": "Choosing data rows\nThe function filter() allows you to find rows in a dataset that meet one or more specific conditions. The syntax is data |&gt; filter(condition), where condition is a logical condition. For example, filter(x &gt; 5) would pick all rows for which the value in column x is greater than 5.\nAs an example, the following code picks all penguins from the island Biscoe:\n\n\n\n\n\n\n\n\nNow it’s your turn. Pick all penguins from the island Dream:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  filter(island == \"Dream\")\n\n\n\n\nYou can also state multiple conditions, separated by a comma. For example, filter(x &gt; 5, y &lt; 2) would pick all rows for which the value in the column x is greater than 5 and the value in the column y is less than 2. Note that the conditions are combined via logical AND, both need to be satisfied for the row to be picked.\nTo try this out, pick all penguins of species Chinstrap from the island Dream:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  filter(species == ___, island == ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  filter(species == \"Chinstrap\", island == \"Dream\")"
  },
  {
    "objectID": "worksheets/data-wrangling-1.html#choosing-data-columns",
    "href": "worksheets/data-wrangling-1.html#choosing-data-columns",
    "title": "Data wrangling 1",
    "section": "Choosing data columns",
    "text": "Choosing data columns\nThe function select() allows you to pick specific data columns by name. This is frequently useful when a dataset has many more columns than we are interested in at the time. For example, if we are only interested in the penguins’ species, island, and sex, we could select these three columns:\n\n\n\n\n\n\n\n\nTry this yourself, picking the columns representing the penguin species (species), the bill length (bill_length_mm), and then flipper length (flipper_length_mm).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  select(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  select(species, bill_length_mm, flipper_length_mm)\n\n\n\n\nAnother situation that arises frequently is one where we want to remove specific columns. We can also do this with select(), but now write select(-column) to remove one or more columns.\nTry this. Remove the column species.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  select(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  select(-species)\n\n\n\n\nAnd now remove both species and island.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  select(-___, -___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  select(-species, -island)"
  },
  {
    "objectID": "worksheets/data-wrangling-1.html#sorting-data",
    "href": "worksheets/data-wrangling-1.html#sorting-data",
    "title": "Data wrangling 1",
    "section": "Sorting data",
    "text": "Sorting data\nThe function arrange() allows you to sort data by one or more columns. For example, data |&gt; arrange(x) would sort the data by increasing values of x, and data |&gt; arrange(x, y) would sort the data first by x and then, for ties in x, by y.\nAs an example, the following code sorts penguins by their flipper length:\n\n\n\n\n\n\n\n\nNow it’s your turn. Sort the penguins by bill length:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  arrange(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  arrange(bill_length_mm)\n\n\n\n\nTo arrange data in descending order, enclose the data column in desc(). For example, data |&gt; arrange(desc(x)) would sort the data by decreasing values of x. (desc stands for “descending”.)\nTry this out. Sort the penguins by bill length, from largest to smallest:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  arrange(___(bill_length_mm))\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  arrange(desc(bill_length_mm))"
  },
  {
    "objectID": "worksheets/data-wrangling-1.html#counting",
    "href": "worksheets/data-wrangling-1.html#counting",
    "title": "Data wrangling 1",
    "section": "Counting",
    "text": "Counting\nWe frequently want to count how many times a particular value or combination of values occurs in a dataset. We do this using the count() function. For example, the following code counts how many penguins of the different species there are in the penguins dataset.\n\n\n\n\n\n\n\n\nNow try this yourself. Count how many male and female penguins there are.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  count(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  count(sex)\n\n\n\n\nWe can also perform more fine-grained counts, by providing the count() function with more than one column name. See if you can count how many male and female penguins the dataset contains for each species.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  count(___, sex)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  count(species, sex)\n\n\n\n\nNow count how many penguins of each species the dataset contains for each island.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  count(___, species)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  count(island, species)"
  },
  {
    "objectID": "worksheets/data-wrangling-1.html#chaining-analysis-steps-into-pipelines",
    "href": "worksheets/data-wrangling-1.html#chaining-analysis-steps-into-pipelines",
    "title": "Data wrangling 1",
    "section": "Chaining analysis steps into pipelines",
    "text": "Chaining analysis steps into pipelines\nWe can chain multiple analysis steps into a pipeline by continuing to add “and then” statements. For example, data |&gt; count(...) |&gt; arrange(...) would first count and then sort the data.\nTry this out by counting the number of penguins of each species and then sorting by the number of penguins.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  count(___) |&gt;\n  arrange(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  count(species) |&gt;\n  arrange(n)\n\n\n\n\nYou may remember from before that the default sorting is from the smallest to the largest value. Repeat the previous exercise but now arrange the penguin species from the most frequent to the least frequent:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  count(species) |&gt;\n  arrange(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  count(species) |&gt;\n  arrange(desc(n))"
  },
  {
    "objectID": "worksheets/data-wrangling-1.html#creating-new-data-columns",
    "href": "worksheets/data-wrangling-1.html#creating-new-data-columns",
    "title": "Data wrangling 1",
    "section": "Creating new data columns",
    "text": "Creating new data columns\nThe function mutate() allows you to add new columns to a data table. For example, data |&gt; mutate(sum = x + y) would create a new column sum that is the sum of the columns x and y:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that the part to the left of the equals sign (here, sum) is the name of the new column, and the part to the right of the equals sign (here, x + y) is an R expression that evaluates to the values in the new column.\nNow apply this concept to the penguins dataset. Add a new column bill_ratio that is the ratio of bill length and bill depth:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  select(species, bill_length_mm, bill_depth_mm) |&gt;\n  mutate(\n    bill_ratio = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  select(species, bill_length_mm, bill_depth_mm) |&gt;\n  mutate(\n    bill_ratio = bill_length_mm / bill_depth_mm\n  )"
  },
  {
    "objectID": "worksheets/data-wrangling-1.html#counting-with-custom-conditions",
    "href": "worksheets/data-wrangling-1.html#counting-with-custom-conditions",
    "title": "Data wrangling 1",
    "section": "Counting with custom conditions",
    "text": "Counting with custom conditions\nIt is quite common that we want to count items that meet a specific condition. For example, let’s say we want to count how many penguins of different species have flippers longer than 200mm. To do this efficiently, we first create a new column that indicates whether the condition is met or not, and we then use count with that indicator column.\nThe easiest way to create indicator columns is via the function if_else(), which takes three arguments: a condition, a result if the condition is met, and a result if the condition is not met. The following example shows how to create an indicator column showing whether a variable is positive or negative:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow try this yourself. Count how many penguins of different species have flippers longer than 200mm. Then sort your results from most frequent to least frequent.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  mutate(\n    flipper_length = if_else(___, \"greater than 200mm\", \"less than 200mm\")\n  ) |&gt;\n  count(___, flipper_length) |&gt;\n  arrange(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  mutate(\n    flipper_length = if_else(flipper_length_mm &gt; 200, \"greater than 200mm\", \"less than 200mm\")\n  ) |&gt;\n  count(species, flipper_length) |&gt;\n  arrange(desc(n))"
  },
  {
    "objectID": "worksheets/compound-figures.html",
    "href": "worksheets/compound-figures.html",
    "title": "Compound figures",
    "section": "",
    "text": "In this worksheet, we will discuss how to combine several ggplot2 plots into one compound figure.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nWe will be working with the R builtin dataset mtcars, which contains fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models)."
  },
  {
    "objectID": "worksheets/compound-figures.html#introduction",
    "href": "worksheets/compound-figures.html#introduction",
    "title": "Compound figures",
    "section": "",
    "text": "In this worksheet, we will discuss how to combine several ggplot2 plots into one compound figure.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nWe will be working with the R builtin dataset mtcars, which contains fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models)."
  },
  {
    "objectID": "worksheets/compound-figures.html#combining-plots",
    "href": "worksheets/compound-figures.html#combining-plots",
    "title": "Compound figures",
    "section": "Combining plots",
    "text": "Combining plots\nFirst we set up four different plots that we will subsequently combine. The plots are stored in variables p1, p2, p3, p4.\n\n\n\n\n\n\n\n\nTo show plots side-by-side, the patchwork package provides the operator |, as in p1 | p2. Try this by making a compound plot of plots p1, p2, p3 side-by-side.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\np1 | p2 | p3\n\n\n\n\nTo show plots on top of one-another, we use the operator /, as in p1 / p2. Try this by making a compound plot of plots p1, p2, p3 on top of each other.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\np1 / p2 / p3\n\n\n\n\nWe can also use parentheses to group plots with respect to the operators | and /. For example, we can place several plots side-by-side and then place this entire row of plots on top of another plot. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n(___) / p4\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n(p1 | p2 | p3 ) / p4"
  },
  {
    "objectID": "worksheets/compound-figures.html#plot-annotations",
    "href": "worksheets/compound-figures.html#plot-annotations",
    "title": "Compound figures",
    "section": "Plot annotations",
    "text": "Plot annotations\nThe patchwork package provides a powerful annotation system via the plot_annotation() function that can be added to a plot assembly. For example, we can add plot tags (the labels in the upper left corner identifying the plots) via the plot annotation tag_levels. You can set tag_levels = \"A\" to generate tags A, B, C, etc. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n(p1 | p2 | p3 ) / p4 +\n  plot_annotation(\n    ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n(p1 | p2 | p3 ) / p4 +\n  plot_annotation(\n    tag_levels = \"A\"\n  )\n\n\n\n\nTry also tag levels such as \"a\", \"i\", or \"1\".\nYou can also add elements such as titles, subtitles, and captions, by setting the title, subtitle, or caption argument in plot_annotation(). Try this out by adding an overall title to the figure from the previous exercise.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n(p1 | p2 | p3 ) / p4 +\n  plot_annotation(\n    tag_levels = \"A\",\n    ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n(p1 | p2 | p3 ) / p4 +\n  plot_annotation(\n    tag_levels = \"A\",\n    title = \"Various observations about old cars\"\n  )\n\n\n\n\nAlso set a subtitle and a caption.\nFinally, you can change the theme of all plots in the plot assembly via the & operator, as in (p1 | p2) & theme_bw(). Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n(p1 | p2) & theme_bw()\n\n\n\n\nWhat happens if you write this expression without parentheses? Do you understand why?"
  },
  {
    "objectID": "worksheets/color-scales.html",
    "href": "worksheets/color-scales.html",
    "title": "Color scales",
    "section": "",
    "text": "In this worksheet, we will discuss how to change and customize color scales.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the dataset temperatures that we have used in previous worksheets. This dataset contains the average temperature for each day of the year for four different locations.\n\n\n\n\n\n\n\n\nWe will also be working with an aggregated version of this dataset called temps_months, which contains the mean temperature for each month for the same locations."
  },
  {
    "objectID": "worksheets/color-scales.html#introduction",
    "href": "worksheets/color-scales.html#introduction",
    "title": "Color scales",
    "section": "",
    "text": "In this worksheet, we will discuss how to change and customize color scales.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the dataset temperatures that we have used in previous worksheets. This dataset contains the average temperature for each day of the year for four different locations.\n\n\n\n\n\n\n\n\nWe will also be working with an aggregated version of this dataset called temps_months, which contains the mean temperature for each month for the same locations."
  },
  {
    "objectID": "worksheets/color-scales.html#built-in-ggplot2-color-scales",
    "href": "worksheets/color-scales.html#built-in-ggplot2-color-scales",
    "title": "Color scales",
    "section": "Built in ggplot2 color scales",
    "text": "Built in ggplot2 color scales\nWe will start with built-in ggplot2 color scales, which require no additional packages. The scale functions are always named scale_color_*() or scale_fill_*(), depending on whether they apply to the color or fill aesthetic. The * indicates some other words specifying the type of the scale, for example scale_color_brewer() or scale_color_distiller() for discrete or continuous scales from the ColorBrewer project, respectively. You can find all available built-in scales here.\nNow consider the following plot:\n\n\n\n\n\n\n\n\nIf you wanted to change the color scale to one from the ColorBrewer project, which scale function would you have to add? Think about this and then try it out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_distiller()\n\n\n\n\nMost color scale functions have additional customizations. How to use them depends on the specific scale function. For the ColorBrewer scales you can set direction = 1 or direction = -1 to set the direction of the scale (light to dark or dark to light). You can also set the palette via a numeric argument, e.g. palette = 1, palette = 2, palette = 3 etc.\nTry this out by setting the direction of the scale from light to dark and using palette #4.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_distiller(direction = ___, palette = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_distiller(direction = 1, palette = 4)\n\n\n\n\nA popular set of scales are the viridis scales, which are provided by scale_*_viridis_c() for continuous data and scale_*_viridis_d() for discrete data. Change the above plot to use a viridis scale.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_c()\n\n\n\n\nThe viridis scales can be customized with direction (as before), option (which can be \"A\", \"B\", \"C\", \"D\", or \"E\"), and begin and end which are numerical values between 0 and 1 indicating where in the color scale the data should begin or end. For example, begin = 0.2 means that the lowest data value is mapped to the 20th percentile in the scale.\nTry different choices for option, begin, and end to see how they change the plot.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_c(option = \"B\", begin = 0.15)"
  },
  {
    "objectID": "worksheets/color-scales.html#customizing-scale-title-and-labels",
    "href": "worksheets/color-scales.html#customizing-scale-title-and-labels",
    "title": "Color scales",
    "section": "Customizing scale title and labels",
    "text": "Customizing scale title and labels\nIn a previous worksheet, we used arguments such as name, breaks, labels, and limits to customize the axis. For color scales, instead of an axis we have a legend, and we can use the same arguments inside the scale function to customize how the legend looks.\nTry this out. Set the scale limits from 10 to 110 and set the name of the scale and the breaks as you wish.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_c(\n    name = ___,\n    breaks = ___,\n    limits = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_c(\n    name = \"temperature (F)\",\n    breaks = c(25, 50, 75, 100),\n    limits = c(10, 110)\n  )\n\n\n\n\nNote: Color scales ignore the expand argument, so you cannot use it to expand the scale beyond the data values as you can for position scales."
  },
  {
    "objectID": "worksheets/color-scales.html#binned-scales",
    "href": "worksheets/color-scales.html#binned-scales",
    "title": "Color scales",
    "section": "Binned scales",
    "text": "Binned scales\nResearch into human perception has shown that continuous coloring can be difficult to interpret. Therefore, it is often preferable to use a small number of discrete colors to indicate ranges of data values. You can do this in ggplot with binned scales. For example, scale_fill_viridis_b() provides a binned version of the viridis scale. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_b()\n\n\n\n\nYou can provide bin breaks directly with the breaks argument. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_b(\n    breaks = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_viridis_b(\n    breaks = c(40, 60, 80, 100)\n  )"
  },
  {
    "objectID": "worksheets/color-scales.html#scales-from-the-colorspace-package",
    "href": "worksheets/color-scales.html#scales-from-the-colorspace-package",
    "title": "Color scales",
    "section": "Scales from the colorspace package",
    "text": "Scales from the colorspace package\nThe color scales provided by the colorspace package follow a simple naming scheme of the form scale_&lt;aesthetic&gt;_&lt;datatype&gt;_&lt;colorscale&gt;(), where &lt;aesthetic&gt; is the name of the aesthetic (fill, color, colour), &lt;datatype&gt; indicates the type of variable plotted (discrete, continuous, binned), and colorscale stands for the type of the color scale (qualitative, sequential, diverging, divergingx).\nFor the mean temperature plot we have been using throughout this worksheet, which color scale(s) from the colorspace package is/are appropriate? Think about this and then try it out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTwo alternative options are appropriate. Can you think of both?\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# Option 1: Continuous scale\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_continuous_sequential()\n\n# Option 2: Binned scale\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_binned_sequential()\n\n\n\n\nYou can customize the colorspace scales with the palette argument, which takes the name of a palette (e.g., \"Inferno\", \"BluYl\", \"Lajolla\"). Try this out. Also try reversing the scale direction with rev = TRUE or rev = FALSE. (The colorspace scales use rev instead of direction.) You can find the names of all supported scales here (consider specifically single-hue and multi-hue sequential palettes).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_continuous_sequential(\n    palette = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_continuous_sequential(\n    palette = \"Lajolla\"\n  )\n\n\n\n\nYou can also use begin and end just like in the viridis scales."
  },
  {
    "objectID": "worksheets/color-scales.html#manual-scales",
    "href": "worksheets/color-scales.html#manual-scales",
    "title": "Color scales",
    "section": "Manual scales",
    "text": "Manual scales\nFor discrete data with a small number of categories, it’s usually best to set colors manually. This can be done with the scale functions scale_*_manual(). These functions take an argument values that specifies the color values to use.\nTo see how this works, let’s go back to this plot of temperatures over time for four locations:\n\n\n\n\n\n\n\n\nLet’s use the following four colors: \"gold2\", \"firebrick\", \"blue3\", \"springgreen4\". We can visualize this palette using the function swatchplot() from the colorspace package.\n\n\n\n\n\n\n\n\nNow apply this color palette to the temperatures plot, by using the manual color scale.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temperatures, aes(day_of_year, temperature, color = location)) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(\n    values = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temperatures, aes(day_of_year, temperature, color = location)) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(\n    values = c(\"gold2\", \"firebrick\", \"blue3\", \"springgreen4\")\n  )\n\n\n\n\nOne problem with this approach is that we can’t easily control which data value gets assigned to which color. What if we wanted San Diego to be shown in green and Chicago in blue? The simplest way to resolve this issue is to use a named vector. A named vector in R is a vector where each value has a name. Named vectors are created by writing c(name1 = value1, name2 = value2, ...). See the following example.\n\n\n\n\n\n\n\n\nThe names in the second example are A, B, and C. Notice that the names are not in quotes. However, if you need a name containing a space (such as Death Valley), you need to enclose the name in backticks. Thus, our named vector of colors could be written like so:\n\n\n\n\n\n\n\n\nNow try to use this color vector in the figure showing temperatures over time.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ncolorvector &lt;- c(___)\n\nggplot(temperatures, aes(day_of_year, temperature, color = location)) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(\n    values = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncolorvector &lt;- c(\n  `Death Valley` = \"gold2\",\n  Houston = \"firebrick\",\n  Chicago = \"blue3\",\n  `San Diego` = \"springgreen4\"\n)\n\nggplot(temperatures, aes(day_of_year, temperature, color = location)) +\n  geom_line(linewidth = 1) +\n  scale_color_manual(\n    values = colorvector\n  )\n\n\n\n\nTry some other colors also. For example, you could use the Okabe-Ito colors:\n\n\n\n\n\n\n\n\nAlternatively, you can find a list of all named colors here. You can also run the command colors() in your R console to get a list of all available color names.\nHint: It’s a good idea to never use the colors \"red\", \"green\", \"blue\", \"cyan\", \"magenta\", \"yellow\". They are extreme points in the RGB color space and tend to look unnatural and cheap. Try this by making a swatch plot of these colors, and compare for example to the color scale containing the colors \"firebrick\", \"springgreen4\", \"blue3\", \"turquoise3\", \"darkorchid2\", \"gold2\". Do you see the difference?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncolorspace::swatchplot(c(\"red\", \"green\", \"blue\", \"cyan\", \"magenta\", \"yellow\"))\ncolorspace::swatchplot(c(\"firebrick\", \"springgreen4\", \"blue3\", \"turquoise3\", \"darkorchid2\", \"gold2\"))"
  },
  {
    "objectID": "worksheets/aesthetic-mappings.html",
    "href": "worksheets/aesthetic-mappings.html",
    "title": "Aesthetic mappings",
    "section": "",
    "text": "In this worksheet, we will discuss a core concept of ggplot, the mapping of data values onto aesthetics.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will first work with the dataset temps_houston which contains the average temperature for each day of the year for Houston, TX."
  },
  {
    "objectID": "worksheets/aesthetic-mappings.html#introduction",
    "href": "worksheets/aesthetic-mappings.html#introduction",
    "title": "Aesthetic mappings",
    "section": "",
    "text": "In this worksheet, we will discuss a core concept of ggplot, the mapping of data values onto aesthetics.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will first work with the dataset temps_houston which contains the average temperature for each day of the year for Houston, TX."
  },
  {
    "objectID": "worksheets/aesthetic-mappings.html#basic-use-of-ggplot",
    "href": "worksheets/aesthetic-mappings.html#basic-use-of-ggplot",
    "title": "Aesthetic mappings",
    "section": "Basic use of ggplot",
    "text": "Basic use of ggplot\nIn the most basic use of ggplot, we call the ggplot() function with a dataset and an aesthetic mapping (created with aes()), and then we add a geom, such as geom_line() to draw lines or geom_point() to draw points.\nTry this for yourself. Map the column day_of_year onto the x axis and the column temperature onto the y axis, and use geom_line() to display the data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_houston, aes(x = day_of_year, y = temperature)) +\n  geom_line()\n\n\n\n\nTry again. Now use geom_point() instead of geom_line().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_houston, aes(x = day_of_year, y = temperature)) +\n  geom_point()\n\n\n\n\nAnd now swap which column you map to x and which to y.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_houston, aes(x = temperature, y = day_of_year)) +\n  geom_point()"
  },
  {
    "objectID": "worksheets/aesthetic-mappings.html#more-complex-geoms",
    "href": "worksheets/aesthetic-mappings.html#more-complex-geoms",
    "title": "Aesthetic mappings",
    "section": "More complex geoms",
    "text": "More complex geoms\nYou can use other geoms to make different types of plots. For example, geom_boxplot() will make boxplots. For boxplots, we frequently want categorical data on the x or y axis. For example, we might want a separate boxplot for each month. Try this out. Puth month on the x axis, temperature on the y axis, and use geom_boxplot().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temps_houston, aes(x = month, y = temperature)) +\n  ___()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_houston, aes(x = month, y = temperature)) +\n  geom_boxplot()\n\n\n\n\nNow put the month on the y axis and the temperature on the x axis.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temps_houston, aes(x = ___, y = ___)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_houston, aes(x = temperature, y = month)) +\n  geom_boxplot()"
  },
  {
    "objectID": "worksheets/aesthetic-mappings.html#adding-color",
    "href": "worksheets/aesthetic-mappings.html#adding-color",
    "title": "Aesthetic mappings",
    "section": "Adding color",
    "text": "Adding color\nNext we will be working with the dataset temperatures, which is similar to temps_houston but contains data for three more locations.\n\n\n\n\n\n\n\n\nMake a line plot of temperature against day_of_year, using the color aesthetic to color the lines by location.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temperatures, aes(x = day_of_year, y = temperature, color = ___)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temperatures, aes(x = day_of_year, y = temperature, color = location)) +\n  geom_line()\n\n\n\n\nTry again, this time using location as the location along the y axis and temperature for the color. This plot looks better with geom_point() than geom_line(). (Try it out to see why. Also, try geom_point(size = 5) to create larger points.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temperatures, aes(x = ___, y = ___, color = ___)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temperatures, aes(x = day_of_year, y = location, color = temperature)) +\n  geom_point()"
  },
  {
    "objectID": "worksheets/aesthetic-mappings.html#using-the-fill-aesthetic",
    "href": "worksheets/aesthetic-mappings.html#using-the-fill-aesthetic",
    "title": "Aesthetic mappings",
    "section": "Using the fill aesthetic",
    "text": "Using the fill aesthetic\nSome geoms use a fill aesthetic, which is similar to color but applies to shaded areas. (color applies to lines and points.) For example, we can use the fill aesthetic with geom_boxplot() to color the interior of the box. Try this yourself. Plot month on x, temperature on y, and color the interior of the box by location.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temperatures, aes(x = month, y = ___, fill = ___)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temperatures, aes(x = month, y = temperature, fill = location)) +\n  geom_boxplot()\n\n\n\n\nCan you color the lines of the boxplot by location and the interior by month? Try it.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temperatures, aes(x = month, y = temperature, color = ___, fill = ___)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temperatures, aes(x = month, y = temperature, color = location, fill = month)) +\n  geom_boxplot()"
  },
  {
    "objectID": "worksheets/aesthetic-mappings.html#using-aesthetics-as-parameters",
    "href": "worksheets/aesthetic-mappings.html#using-aesthetics-as-parameters",
    "title": "Aesthetic mappings",
    "section": "Using aesthetics as parameters",
    "text": "Using aesthetics as parameters\nMany of the aesthetics (such as color, fill, and also size to change line size or point thickness) can be used as parameters inside a geom rather than inside an aes() statement. The difference is that when you use an aesthetic as a parameter, you specify a specific value, such as color = \"blue\", rather than a mapping, such as aes(color = location). Notice the difference: Inside the aes() function, we don’t actually specify the specific color values, ggplot does that for us. We only say that we want the data values of the location column to correspond to different colors. (We will learn later how to tell ggplot to use specific colors in this mapping.)\nTry this with the boxplot example from the previous section. Map location onto the fill aesthetic but set the color of the lines to \"navyblue\".\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temperatures, aes(x = month, y = temperature, fill = ___)) +\n  geom_boxplot(color = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temperatures, aes(x = month, y = temperature, fill = location)) +\n  geom_boxplot(color = \"navyblue\")\n\n\n\n\nNow do the reverse. Map location onto the line colors but fill the box with the color \"navyblue\".\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temperatures, aes(x = month, y = temperature, color = ___)) +\n  geom_boxplot(fill = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temperatures, aes(x = month, y = temperature, color = location)) +\n  geom_boxplot(fill = \"navyblue\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSC 385",
    "section": "",
    "text": "This is the home page for DSC 385, Data Exploration, Visualization, and Foundations of Unsupervised Learning. All course materials will be posted on this site.\nInstructor: Claus O. Wilke\nMeeting times: TTH 5:00pm to 6:30pm\nVenue: FAC 21\nSyllabus: click here\nUpcoming lectures and assignments: click here"
  },
  {
    "objectID": "index.html#computing-requirements",
    "href": "index.html#computing-requirements",
    "title": "DSC 385",
    "section": "Computing requirements",
    "text": "Computing requirements\nFor students enrolled in this course, you only need a working web browser to access the edupod server, located at: https://edupod.cns.utexas.edu/\nIf you are using the edupod server, stop reading here. Everything is pre-installed and no further action is needed.\nTo run any of the materials locally on your own machine, you will need the following:\n\nA recent version of R, download from here.\nA recent version of RStudio, download from here, OR a recent version of Positron, download from here.\nThe following R packages:\nbroom, cluster, colorspace, cowplot, gapminder, GGally, gganimate, ggiraph, ggdendro, ggdist, ggforce, ggplot2movies, ggrepel, ggridges, ggthemes, gifski, glue, knitr, learnr, naniar, margins, MASS, Matrix, nycflights13, palmerpenguins, patchwork, quarto, rmarkdown, rnaturalearth, rnaturalearthhires, Rtsne, scales, sf, sp, tidyverse, transformr, umap\n\nYou can install all required R packages at once by running the following code in the R command line:\n# first run this command:\ninstall.packages(\n  c(\n    \"broom\", \"cluster\", \"colorspace\", \"cowplot\", \"gapminder\", \n    \"GGally\", \"gganimate\", \"ggiraph\", \"ggdendro\", \"ggdist\", \"ggforce\",\n    \"ggplot2movies\", \"ggrepel\", \"ggridges\", \"ggthemes\", \"gifski\", \"glue\",\n    \"knitr\", \"learnr\", \"naniar\", \"margins\", \"MASS\", \"Matrix\",\n    \"nycflights13\", \"palmerpenguins\", \"patchwork\", \"quarto\", \"rmarkdown\",\n    \"rnaturalearth\", \"Rtsne\", \"scales\", \"sf\", \"sp\", \"tidyverse\",\n    \"transformr\", \"umap\"\n  )\n)\n\n# then run this command:\ninstall.packages(\n  \"rnaturalearthhires\", repos = \"https://packages.ropensci.org\", type = \"source\"\n)"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "DSC 385 Schedule",
    "section": "",
    "text": "Materials:\n\n\nSlides\n\nWorksheet 1: Introduction to Quarto\nWorksheet 2: Introduction to R\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides Part I (visualizing amounts)\nWorksheet Part I\nSlides Part II (telling a story)\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides Part I (pipe, sorting, filtering, mutating)\nWorksheet Part I\nSlides Part II (summarizing, pivoting, joining)\nWorksheet Part II\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\nWorksheet Part I (data cleaning)\nWorksheet Part II (missing data)\n\n\n\n\n\nMaterials:\n\n\nSlides\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides: Interactive plots\n\nWorksheet: Interactive plots\nSlides: Animations\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet"
  },
  {
    "objectID": "schedule.html#lectures",
    "href": "schedule.html#lectures",
    "title": "DSC 385 Schedule",
    "section": "",
    "text": "Materials:\n\n\nSlides\n\nWorksheet 1: Introduction to Quarto\nWorksheet 2: Introduction to R\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides Part I (visualizing amounts)\nWorksheet Part I\nSlides Part II (telling a story)\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides Part I (pipe, sorting, filtering, mutating)\nWorksheet Part I\nSlides Part II (summarizing, pivoting, joining)\nWorksheet Part II\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\nWorksheet Part I (data cleaning)\nWorksheet Part II (missing data)\n\n\n\n\n\nMaterials:\n\n\nSlides\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet\n\n\n\n\n\nMaterials:\n\n\nSlides: Interactive plots\n\nWorksheet: Interactive plots\nSlides: Animations\n\n\n\n\n\nMaterials:\n\n\nSlides\n\nWorksheet"
  },
  {
    "objectID": "worksheets/clustering.html",
    "href": "worksheets/clustering.html",
    "title": "Clustering",
    "section": "",
    "text": "In this worksheet, we will discuss how to perform k-means clustering.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with two datasets, spirals and iris. The dataset spirals contains made-up data in two dimensions that forms three intertwined spirals.\n\n\n\n\n\n\n\n\nThe dataset iris contains measurements on the leaves of flowers of three Iris species.\n\n\n\n\n\n\n\n\nHint: Pay attention to the column names in the iris dataset. They are all capitalized (e.g., Species), and the first four use a point as a separator (e.g., Sepal.Length). It is easy to misspell them and then the R code doesn’t work correctly."
  },
  {
    "objectID": "worksheets/clustering.html#introduction",
    "href": "worksheets/clustering.html#introduction",
    "title": "Clustering",
    "section": "",
    "text": "In this worksheet, we will discuss how to perform k-means clustering.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with two datasets, spirals and iris. The dataset spirals contains made-up data in two dimensions that forms three intertwined spirals.\n\n\n\n\n\n\n\n\nThe dataset iris contains measurements on the leaves of flowers of three Iris species.\n\n\n\n\n\n\n\n\nHint: Pay attention to the column names in the iris dataset. They are all capitalized (e.g., Species), and the first four use a point as a separator (e.g., Sepal.Length). It is easy to misspell them and then the R code doesn’t work correctly."
  },
  {
    "objectID": "worksheets/clustering.html#clustering-the-iris-dataset",
    "href": "worksheets/clustering.html#clustering-the-iris-dataset",
    "title": "Clustering",
    "section": "Clustering the iris dataset",
    "text": "Clustering the iris dataset\nWe perform k-means clustering in R with the function kmeans(). It takes two important arguments, the number of clusters we want to generate (centers) and the number of times we want to re-run the clustering algorithm with different random starting points (nstart). Similarly to a PCA, we need to remove all non-numeric data columns before we can run the analysis.\n\n\n\n\n\n\n\n\nThe output from the fitted object (km_fit) gives us various pieces of information in human-readable form, such as the cluster sizes, the cluster means, and the assignment of rows in the original data table to the different clusters (“clustering vector”).\nAt the end of the output, you see a list of “available components.” These are various pieces of information about the clustering result that you can extract from the fitted object. For example, km_fit$cluster gives you information about which row in the original data table belongs to which cluster.\n\n\n\n\n\n\n\n\nSimilarly, centers will give you the positions of the cluster centers and tot.withinss will give you the total within sum-of-squares. Try this out. Also, see if you can figure out what the component size represents.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nkm_fit$cluster\n___\n___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nkm_fit$cluster      # assignment of original data rows to clusters\nkm_fit$tot.withinss # total within sum-of-squares\nkm_fit$size         # cluster sizes (number of observations in each cluster)\n\n\n\n\nNext we move on to plotting the clustering output. The k-means algorithm is a stochastic algorithm that produces slightly different output each time it is run. This is particularly apparent when you set nstart = 1. In this case, you will get possibly quite different results for different random seeds. You can set the random seed via set.seed().\nIn the example below, try various seeds, including 2356, 2357, 2358, 2359, and see what the results are.\n\n\n\n\n\n\n\n\nNow set nstart = 10 and try the same random seeds once more."
  },
  {
    "objectID": "worksheets/clustering.html#finding-the-appropriate-number-of-clusters",
    "href": "worksheets/clustering.html#finding-the-appropriate-number-of-clusters",
    "title": "Clustering",
    "section": "Finding the appropriate number of clusters",
    "text": "Finding the appropriate number of clusters\nTo get a sense of the correct number of clusters for a given dataset, we can plot the total within sum-of-squares as a function of the cluster number and look for a bend (“elbow”) in the curve. Remember, the total within sum-of-squares can be obtained from the fitted object via km_fit$tot.withinss.\nThe following code sets up a function calc_withinss that calculates the total within sum-of-squares for an arbitrary data set and number of clusters, and then applies it to the spirals dataset.\n\n\n\n\n\n\n\n\nNow take this code and use it to make a plot of the total within sum-of-squares against cluster number.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntibble(centers = 1:15) |&gt;\n  mutate(\n    within_sum_squares = map_dbl(\n      centers, ~calc_withinss(spirals, .x)\n    )\n  ) |&gt;\n  ggplot(aes(___)) +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntibble(centers = 1:15) |&gt;\n  mutate(\n    within_sum_squares = map_dbl(\n      centers, ~calc_withinss(spirals, .x)\n    )\n  ) |&gt;\n  ggplot(aes(centers, within_sum_squares)) +\n  geom_point() +\n  geom_line() +\n  theme_bw()\n\n\n\n\nThe plot suggests that the correct number of clusters should be around 3 or 4. Now cluster the spirals dataset with this number of clusters and then plot it colored by cluster id.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nkm_fit &lt;- ___ |&gt; \n  select(where(is.numeric)) |&gt;\n  kmeans(centers = 3, nstart = 10)\n\nkm_fit |&gt;\n  augment(___) |&gt;\n  ___\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nkm_fit &lt;- spirals |&gt; \n  select(where(is.numeric)) |&gt;\n  kmeans(centers = 3, nstart = 10)\n\nkm_fit |&gt;\n  augment(spirals) |&gt;\n  ggplot() +\n  aes(___) +\n  geom_point(aes(color = ___, shape = ___))\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nkm_fit &lt;- spirals |&gt; \n  select(where(is.numeric)) |&gt;\n  kmeans(centers = 3, nstart = 10)\n\nkm_fit |&gt;\n  augment(spirals) |&gt;\n  ggplot() +\n  aes(x, y) +\n  geom_point(aes(color = .cluster, shape = group))\n\n\n\n\nTry a few different cluster numbers to see how the algorithm behaves. Do you think k-means clustering works on this dataset?"
  },
  {
    "objectID": "worksheets/clustering.html#combining-k-means-and-pca",
    "href": "worksheets/clustering.html#combining-k-means-and-pca",
    "title": "Clustering",
    "section": "Combining k-means and PCA",
    "text": "Combining k-means and PCA\nIn practice, we often perform PCA first on a dataset and then cluster the transformed coordinates. Try this out on the iris dataset. Run a PCA, then cluster the PCA coordinates, and then plot the clusters in PCA space.\nAs a reminder, this is how we would do a PCA on this dataset:\n\n\n\n\n\n\n\n\nNow modify this example so you perform a k-means clustering analysis and then color by clusters rather than by species.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npca_fit &lt;- iris |&gt; \n  select(where(is.numeric)) |&gt; # retain only numeric columns\n  scale() |&gt;                   # scale to zero mean and unit variance\n  prcomp()\n\n# combine iris data with PCA data (needed for plot)\niris_pca &lt;- augment(pca_fit, iris)\n\n# perform k-means\nkm_fit &lt;- augment(pca_fit) |&gt;\n  select(-.rownames) |&gt;\n  ___\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npca_fit &lt;- iris |&gt; \n  select(where(is.numeric)) |&gt; # retain only numeric columns\n  scale() |&gt;                   # scale to zero mean and unit variance\n  prcomp()\n\n# combine iris data with PCA data (needed for plot)\niris_pca &lt;- augment(pca_fit, iris)\n\n# perform k-means\nkm_fit &lt;- augment(pca_fit) |&gt;\n  select(-.rownames) |&gt;\n  kmeans(centers = 3, nstart = 10)\n\nkm_fit |&gt;\n  # combine with original data and the PCA coordinates\n  ___ |&gt;\n  # plot\n  ___\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npca_fit &lt;- iris |&gt; \n  select(where(is.numeric)) |&gt; # retain only numeric columns\n  scale() |&gt;                   # scale to zero mean and unit variance\n  prcomp()\n\n# combine iris data with PCA data (needed for plot)\niris_pca &lt;- augment(pca_fit, iris)\n\n# perform k-means\nkm_fit &lt;- augment(pca_fit) |&gt;\n  select(-.rownames) |&gt;\n  kmeans(centers = 3, nstart = 10)\n\nkm_fit |&gt;\n  # combine with original data and the PCA coordinates\n  augment(iris_pca) |&gt;\n  ggplot() +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npca_fit &lt;- iris |&gt; \n  select(where(is.numeric)) |&gt; # retain only numeric columns\n  scale() |&gt;                   # scale to zero mean and unit variance\n  prcomp()\n\n# combine iris data with PCA data (needed for plot)\niris_pca &lt;- augment(pca_fit, iris)\n\n# perform k-means\nkm_fit &lt;- augment(pca_fit) |&gt;\n  select(-.rownames) |&gt;\n  kmeans(centers = 3, nstart = 10)\n\nkm_fit |&gt;\n  # combine with original data and the PCA coordinates\n  augment(iris_pca) |&gt;\n  ggplot() +\n  aes(x = .fittedPC1, .fittedPC2) +\n  geom_point(\n    aes(color = .cluster, shape = Species)\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npca_fit &lt;- iris |&gt; \n  select(where(is.numeric)) |&gt; # retain only numeric columns\n  scale() |&gt;                   # scale to zero mean and unit variance\n  prcomp()\n\n# combine iris data with PCA data (needed for plot)\niris_pca &lt;- augment(pca_fit, iris)\n\n# perform k-means\nkm_fit &lt;- augment(pca_fit) |&gt;\n  select(-.rownames) |&gt;\n  kmeans(centers = 3, nstart = 10)\n\nkm_fit |&gt;\n  # combine with original data and the PCA coordinates\n  augment(iris_pca) |&gt;\n  ggplot() +\n  aes(x = .fittedPC1, .fittedPC2) +\n  geom_point(\n    aes(color = .cluster, shape = Species)\n  ) +\n  geom_point(\n    data = tidy(km_fit),\n    aes(fill = cluster),\n    shape = 21, color = \"black\", size = 4\n  ) +\n  guides(color = \"none\")\n\n\n\n\nChange which components you plot on the x and the y axis to try to get a sense of how the clusters are located in the 4-dimensional PC space."
  },
  {
    "objectID": "worksheets/color-selection.html",
    "href": "worksheets/color-selection.html",
    "title": "Color selection",
    "section": "",
    "text": "In this worksheet, you will practice choosing your own colors.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with two datasets that we have seen previously. First, the penguins dataset:\npenguins\n\n\n\n\n\n\n\n\n\n\nSecond, the temps_months dataset which contains the mean temperature for each month in four different locations.\n\n\n\n\n\n\n\n\nWe will start with a scatter plot of the penguins dataset.\n\n\n\n\n\n\n\n\nUse the color chooser app to manually pick three colors that are appropriate for a qualitative color scale. Then modify the plot to use this scale.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm, color = species)) +\n  geom_point(size = 2, na.rm = TRUE) +\n  scale_color_manual(\n    values = ___ # your colors here \n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm, color = species)) +\n  geom_point(size = 2, na.rm = TRUE) +\n  scale_color_manual(\n    # this is just an example, there are many possible choices here\n    values = c('#BF8A21', '#A74C48', '#17517A')\n  )\n\n\n\n\nNow let’s consider this heat map of temperatures in different locations throughout the year.\n\n\n\n\n\n\n\n\nUse the color chooser app to manually pick four to six colors that are appropriate for a sequential color scale. Then modify the plot to use this scale. (To create a manual color gradient, use scale_fill_gradientn().)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_gradientn(\n    colours = ___ # your colors here \n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_gradientn(\n    # this is just an example, there are many possible choices here\n    colours = c('#475010', '#8B9B38', '#C6D77C', '#F4F9E1')\n  )"
  },
  {
    "objectID": "worksheets/color-selection.html#introduction",
    "href": "worksheets/color-selection.html#introduction",
    "title": "Color selection",
    "section": "",
    "text": "In this worksheet, you will practice choosing your own colors.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with two datasets that we have seen previously. First, the penguins dataset:\npenguins\n\n\n\n\n\n\n\n\n\n\nSecond, the temps_months dataset which contains the mean temperature for each month in four different locations.\n\n\n\n\n\n\n\n\nWe will start with a scatter plot of the penguins dataset.\n\n\n\n\n\n\n\n\nUse the color chooser app to manually pick three colors that are appropriate for a qualitative color scale. Then modify the plot to use this scale.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm, color = species)) +\n  geom_point(size = 2, na.rm = TRUE) +\n  scale_color_manual(\n    values = ___ # your colors here \n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(penguins, aes(body_mass_g, bill_length_mm, color = species)) +\n  geom_point(size = 2, na.rm = TRUE) +\n  scale_color_manual(\n    # this is just an example, there are many possible choices here\n    values = c('#BF8A21', '#A74C48', '#17517A')\n  )\n\n\n\n\nNow let’s consider this heat map of temperatures in different locations throughout the year.\n\n\n\n\n\n\n\n\nUse the color chooser app to manually pick four to six colors that are appropriate for a sequential color scale. Then modify the plot to use this scale. (To create a manual color gradient, use scale_fill_gradientn().)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_gradientn(\n    colours = ___ # your colors here \n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_months, aes(x = month, y = location, fill = mean)) + \n  geom_tile() + \n  coord_fixed(expand = FALSE) +\n  scale_fill_gradientn(\n    # this is just an example, there are many possible choices here\n    colours = c('#475010', '#8B9B38', '#C6D77C', '#F4F9E1')\n  )"
  },
  {
    "objectID": "worksheets/coordinate-systems-axes.html",
    "href": "worksheets/coordinate-systems-axes.html",
    "title": "Coordinate systems and axes",
    "section": "",
    "text": "In this worksheet, we will discuss how to change and customize scales and coordinate systems.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with three different datasets, boxoffice, temperatures, and tx_counties. You have already seen the first two previously.\nThe boxoffice dataset contains box-office gross results for Dec. 22-24, 2017.\n\n\n\n\n\n\n\n\nThe temperatures dataset contains the average temperature for each day of the year for four different locations.\n\n\n\n\n\n\n\n\nThe tx_counties dataset holds information about how many people lived in Texas counties in 2010. The column popratio is the ratio of the number of inhabitants to the median across all counties, and the column index simply counts the counties from most populous to least populous."
  },
  {
    "objectID": "worksheets/coordinate-systems-axes.html#introduction",
    "href": "worksheets/coordinate-systems-axes.html#introduction",
    "title": "Coordinate systems and axes",
    "section": "",
    "text": "In this worksheet, we will discuss how to change and customize scales and coordinate systems.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with three different datasets, boxoffice, temperatures, and tx_counties. You have already seen the first two previously.\nThe boxoffice dataset contains box-office gross results for Dec. 22-24, 2017.\n\n\n\n\n\n\n\n\nThe temperatures dataset contains the average temperature for each day of the year for four different locations.\n\n\n\n\n\n\n\n\nThe tx_counties dataset holds information about how many people lived in Texas counties in 2010. The column popratio is the ratio of the number of inhabitants to the median across all counties, and the column index simply counts the counties from most populous to least populous."
  },
  {
    "objectID": "worksheets/coordinate-systems-axes.html#scale-customizations",
    "href": "worksheets/coordinate-systems-axes.html#scale-customizations",
    "title": "Coordinate systems and axes",
    "section": "Scale customizations",
    "text": "Scale customizations\nWe can modify the appearance of the x and y axis with scale functions. All scale functions have name of the form scale_aesthetic_type(), where aesthetic stands for an aesthetic to which we’re mapping data (e.g., x, y, color, fill, etc), and type stands for the specific type of the scale. What scale types are available depends on both the aesthetic and the data.\nHere, we only consider position scales, which are scales for the x and y aesthetics. The most commonly used scales types for position scales are continuous for continuous data and discrete for discrete data, yielding the scale functions scale_x_continuous(), scale_y_continuous(), scale_x_discrete(), and scale_y_discrete(). But there are others, such as date, time, or binned. You can look them up here: https://ggplot2.tidyverse.org/reference/index.html#section-scales\nPosition scale functions are used to modify both the appearance of the axis (axis title, axis labels, number and location of breaks, etc.) and the mapping from data to position (including the range of data values considered, i.e., axis limits, and whether the data should be transformed, as is the case in log scales).\nLet’s start with this plot of the boxoffice data:\n\n\n\n\n\n\n\n\nWe can use scale functions to modify the axis titles, by setting the name argument. For example, scale_x_continuous(name = \"the x value\") would set the axis title to “the x value” in a continuous scale along the x axis.\nUse the appropriate scale functions to modify both axis titles in the above plot. Think about which axes (if any) are continuous and which are discrete.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(boxoffice) +\n  aes(amount, fct_reorder(title, amount)) +\n  geom_col() +\n  scale_x_continuous(___) +\n  scale_y_discrete(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(boxoffice) +\n  aes(amount, fct_reorder(title, amount)) +\n  geom_col() +\n  scale_x_continuous(name = \"weekend gross (million USD)\") +\n  scale_y_discrete(name = NULL)\n\n\n\n\nWe can also use scale functions to set axis limits, via the limits argument. For continuous scales, the limits argument takes a vector of two numbers representing the lower and upper limit. For example, limits = c(0, 80) would indicate an axis that runs from 0 to 80. For discrete scales, the limits argument takes a vector of all the categories that should be shown, in the order in which they should be shown.\nTry this out by setting a limit from 0 to 80 on the x axis.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(boxoffice) +\n  aes(amount, fct_reorder(title, amount)) +\n  geom_col() +\n  scale_x_continuous(\n    name = \"weekend gross (million USD)\",\n    limits = ___\n  ) +\n  scale_y_discrete(name = NULL)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(boxoffice) +\n  aes(amount, fct_reorder(title, amount)) +\n  geom_col() +\n  scale_x_continuous(\n    name = \"weekend gross (million USD)\",\n    limits = c(0, 80)\n  ) +\n  scale_y_discrete(name = NULL)\n\n\n\n\nWhat happens if you set the axis limits such that not all data points can be shown, for example an upper limit of 65 rather than 80? Do you understand why?\n(Hint: Scale limits are applied before the plot is drawn, and data points outside the scale limits are discarded. If this is not what you want, there’s an alternative way of setting limits. See the very end of this worksheet under “Coords”.)\nNext, we can use the breaks and labels arguments to customize which axis ticks are shown and how they are labeled. In general, you need exactly as many breaks as labels. If you define only breaks but not labels then labels are automatically generated from the breaks.\nBuilding on the code from the previous example, set breaks at 0, 25, 50, and 75, and format the labels such that they can be read as currency. For example, write $25M instead of just 25.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(boxoffice) +\n  aes(amount, fct_reorder(title, amount)) +\n  geom_col() +\n  scale_x_continuous(\n    name = \"weekend gross\",\n    limits = c(0, 80),\n    breaks = ___,\n    labels = ___\n  ) +\n  scale_y_discrete(name = NULL)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(boxoffice) +\n  aes(amount, fct_reorder(title, amount)) +\n  geom_col() +\n  scale_x_continuous(\n    name = \"weekend gross\",\n    limits = c(0, 80),\n    breaks = c(0, 25, 50, 75),\n    labels = c(\"0\", \"$25M\", \"$50M\", \"$75M\")\n  ) +\n  scale_y_discrete(name = NULL)\n\n\n\n\nWhen looking at the resulting plot, you may notice that the x axis extends beyond the limits you have set. This happens because by default ggplot scales expand the axis range by a small amount. You can set the axis expansion via the expand parameter. Setting the expansion can be a bit tricky, because we can set expansion at either end of a scale and we can define both additive and multiplicative expansion. (Additive expansion adds a fixed value, whereas multiplicative expansion adds a multiple of the scale range. ggplot uses additive expansion for discrete scales and multiplicative expansion for continuous scales, but you can use either for either scale.)\nThe simplest way to define expansions is with the expansion() function, which takes arguments mult for multiplicative expansion and add for additive expansion. Either takes a vector of two values, indicating expansion at the lower and upper end, respectively. Thus, expansion(mult = c(0, 0.1)) indicates multiplicative expansion of 0% at the lower end and 10% at the upper end, whereas expansion(add = c(2, 2)) indicates additive expansion of 2 units at either end of the scale.\nTry this yourself. Use the expand argument to remove the gap to the left of 0 on the x axis.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(boxoffice) +\n  aes(amount, fct_reorder(title, amount)) +\n  geom_col() +\n  scale_x_continuous(\n    name = \"weekend gross\",\n    limits = c(0, 80),\n    breaks = c(0, 25, 50, 75),\n    labels = c(\"0\", \"$25M\", \"$50M\", \"$75M\"),\n    expand = expansion(___)\n  ) +\n  scale_y_discrete(name = NULL)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(boxoffice) +\n  aes(amount, fct_reorder(title, amount)) +\n  geom_col() +\n  scale_x_continuous(\n    name = \"weekend gross\",\n    limits = c(0, 80),\n    breaks = c(0, 25, 50, 75),\n    labels = c(\"0\", \"$25M\", \"$50M\", \"$75M\"),\n    expand = expansion(mult = c(0, 0.06))\n  ) +\n  scale_y_discrete(name = NULL)\n\n\n\n\nTry different settings for the expand argument. Try both multiplicative and additive expansions. Apply different expansions to the y axis as well."
  },
  {
    "objectID": "worksheets/coordinate-systems-axes.html#logarithmic-scales",
    "href": "worksheets/coordinate-systems-axes.html#logarithmic-scales",
    "title": "Coordinate systems and axes",
    "section": "Logarithmic scales",
    "text": "Logarithmic scales\nScales can also transform the data before plotting. For example, log scales such as scale_x_log10() and scale_y_log10() log-transform the data. To try this out, we’ll be working with the tx_counties dataset:\n\n\n\n\n\n\n\n\nModify this plot so the y axis uses a log scale.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(tx_counties) +\n  aes(x = index, y = popratio) +\n  geom_point() +\n  scale_y_log10()\n\n\n\n\nNow customize the log scale by setting name, limits, breaks, and labels. These work exactly as they did in scale_x_continuous().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(tx_counties) +\n  aes(x = index, y = popratio) +\n  geom_point() +\n  scale_y_log10(\n    name = ___,\n    limits = ___,\n    breaks = ___,\n    labels = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(tx_counties) +\n  aes(x = index, y = popratio) +\n  geom_point() +\n  scale_y_log10(\n    name = \"population number / median\",\n    limits = c(0.003, 300),\n    breaks = c(0.01, 1, 100),\n    labels = c(\"0.01\", \"1\", \"100\")\n  )"
  },
  {
    "objectID": "worksheets/coordinate-systems-axes.html#coords",
    "href": "worksheets/coordinate-systems-axes.html#coords",
    "title": "Coordinate systems and axes",
    "section": "Coords",
    "text": "Coords\nWhile scales determine how data values are mapped and represented along one dimension, e.g. the x or the y axis, coordinate systems define how these dimensions are projected onto the 2d plot surface. The default coordinate system is the Cartesian coordinate system, which uses orthogonal x and y axes. In the following example, I have added the coord explicitly, but this is not normally necessary.\n\n\n\n\n\n\n\n\nWe can however add a different coord, for example coord_polar() to use a polar coordinate system. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temperatures, aes(day_of_year, temperature, color = location)) +\n  geom_line() +\n  coord_polar()\n\n\n\n\nIn the polar coordinate system, the y axis (here, temperature) is mapped onto the radius, and the x axis (here, day of year) is mapped onto the angle. You can use scale_x_continuous() and scale_y_continuous() to modify the radial and angular axes. For example, you may want to change the temperature limits from 0 to 105 so the temperature curve for Chicago doesn’t hit the exact center of the plot. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temperatures, aes(day_of_year, temperature, color = location)) +\n  geom_line() +\n  coord_polar() +\n  scale_y_continuous(limits = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temperatures, aes(day_of_year, temperature, color = location)) +\n  geom_line() +\n  coord_polar() +\n  scale_y_continuous(limits = c(0, 105))\n\n\n\n\nThere are other useful coords. For example, coord_fixed() is a Cartesian coordinate system with fixed aspect ratio. This is useful when we plot variables along the x and y axes that are measured in the same units. In this case, we want the two axes to be coordinated, such that one step along x has the same meaning as one step along y.\nTo demonstrate this, we reshape the temperatures dataset into wide format, and then plot temperatures in San Diego versus temperatures in Houston.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(A side remark: Do you know why we write `San Diego` and not \"San Diego\" or 'San Diego' inside the aes() function? If you don’t, see if you can find out.)\nThe units along both the x and the y axis are temperatures, but a 10 degree difference in Houston is shown as a shorter distance than a 10 degree difference in San Diego. To address this problem, add coord_fixed() to the above plot.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_wide, aes(`San Diego`, Houston)) +\n  geom_point() +\n  coord_fixed()\n\n\n\n\nThis plot is technically correct but it doesn’t look good, because breaks are spaced differently along the two axes. Also, the plot looks strangely narrow and tall. We can fix both issues by manually setting breaks and limits for both axes. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(temps_wide, aes(`San Diego`, Houston)) +\n  geom_point() +\n  coord_fixed() +\n  scale_x_continuous(\n    limits = ___,\n    breaks = ___\n  ) +\n  scale_y_continuous(\n    limits = ___,\n    breaks = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(temps_wide, aes(`San Diego`, Houston)) +\n  geom_point() +\n  coord_fixed() +\n  scale_x_continuous(\n    limits = c(45, 85),\n    breaks = c(40, 50, 60, 70, 80)\n  ) +\n  scale_y_continuous(\n    limits = c(48, 88),\n    breaks = c(50, 60, 70, 80)\n  )\n\n\n\n\nFinally, as the last example of what can be done with coords, we go back to the problem of setting limits on the box-office bar plot. Instead of setting limits with scale functions, we can also set them via the arguments xlim and ylim inside the coord, for example here coord_cartesian(). (This would be a good reason to explicity add coord_cartesian() to a plot.) When we set limits in the coord ggplot does not discard any data points. Instead it simply zooms in or out according to the limits set. Try this out by setting the x limits from 10 to 65 in the box-office plot.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(boxoffice) +\n  aes(amount, fct_reorder(title, amount)) +\n  geom_col() +\n  coord_cartesian(\n    xlim = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(boxoffice) +\n  aes(amount, fct_reorder(title, amount)) +\n  geom_col() +\n  coord_cartesian(\n    xlim = c(10, 65)\n  )\n\n\n\n\nNote: It is normally not a good idea to start a bar plot at a value other than 0. This exercise was solely meant to demonstrate how limits in coords differ from limits in scales."
  },
  {
    "objectID": "worksheets/data-wrangling-2.html",
    "href": "worksheets/data-wrangling-2.html",
    "title": "Data wrangling 2",
    "section": "",
    "text": "In this worksheet, we will continue with basic data manipulations, now moving on to grouping and summarizing, making data tables wider or longer, and joining data tables.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data. We will be working with data on individual penguins in Antarctica.\npenguins\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe’ll also be working with two datasets containing some information about Texas cities."
  },
  {
    "objectID": "worksheets/data-wrangling-2.html#introduction",
    "href": "worksheets/data-wrangling-2.html#introduction",
    "title": "Data wrangling 2",
    "section": "",
    "text": "In this worksheet, we will continue with basic data manipulations, now moving on to grouping and summarizing, making data tables wider or longer, and joining data tables.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data. We will be working with data on individual penguins in Antarctica.\npenguins\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe’ll also be working with two datasets containing some information about Texas cities."
  },
  {
    "objectID": "worksheets/data-wrangling-2.html#analyzing-subsets",
    "href": "worksheets/data-wrangling-2.html#analyzing-subsets",
    "title": "Data wrangling 2",
    "section": "Analyzing subsets",
    "text": "Analyzing subsets\nIn many data analysis settings, we want to break a dataset into subsets and then perform some summary calculation on each subset. The simplest example is counting, which we have done previously with the count() function.\n\n\n\n\n\n\n\n\nThis function subdivides the penguins dataset into subsets for each species and then calculates the number n for each subset, which is the number of observations in each subset.\nThe function count() here does all the work for us, but what if instead of counting we wanted to calculate the mean weight of the penguins for each species, or calculate the mean weight and count at the same time? We need a general framework that allows us to do these kinds of calculations with maximum flexibility.\nThe tidyverse approach is to first group a dataset with group_by() and then to calculate grouped summaries with summarize().\n\nGrouping\nLet’s first consider just grouping. If we look at the raw R output of just the penguins table or the penguins table after running it through group_by(species), we see that the table is the same, except in the second case there is a line # Groups:   species [3] which indicates that the table is grouped by species and there are three groups. (Here, we need to pipe the tables into the print() function to see the raw R output instead of a formatted table that would hide the grouping information.)\n\n\n\n\n\n\n\n\nWe can also group by multiple data columns at once, and we can undo any grouping with ungroup().\n\n\n\n\n\n\n\n\nNow try this yourself. Group the penguins dataset by sex and island.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  group_by(___) |&gt;\n  print()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  group_by(sex, island) |&gt;\n  print()\n\n\n\n\nNow undo the previous grouping.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  group_by(sex, island) |&gt;\n  ___ |&gt;\n  print()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  group_by(sex, island) |&gt;\n  ungroup() |&gt;\n  print()\n\n\n\n\nAlso verify what the output looks like when you omit the print() function at the end.\n\n\nPerforming summaries\nOnce we have set up a grouping for a data table, we can then calculate summary data with the summarize() function. This function works similarly to mutate(), in that we provide it with statements of the form &lt;new column name&gt; = &lt;computation&gt;, where &lt;new column name&gt; stands for the name of the new column that is being created and &lt;computation&gt; stands for the computation that is used to generate the values in the new column. As an example, if we want to calculate the mean weight (body mass) of penguins, we could write summarize(mean_weight = mean(body_mass_g)), and this would create a new column called mean_weight.\nTry this out. First group by sex and then calculate the mean weight for each sex.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  group_by(sex) |&gt;\n  summarize(\n    ___ = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  group_by(sex) |&gt;\n  summarize(\n    mean_weight = mean(body_mass_g)\n  )\n\n\n\n\nWe see that male penguins on average are heavier than female penguins. We also see that there is a row containing NAs. This happens because there are a few entries in the dataset for which we know neither the penguins’ sex nor their weight.\nNext, see if the pattern changes if we subdivide the dataset by species.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  group_by(species, sex) |&gt;\n  summarize(\n    ___ = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  group_by(species, sex) |&gt;\n  summarize(\n    mean_weight = mean(body_mass_g)\n  )\n\n\n\n\nWhen running this code, you see a message that summarise() (the tidyverse uses British spelling internally) has grouped the output by species. This happens because if you group by multiple variables and then perform a summary it usually makes sense to keep all but the innermost groupings. Verify this is the case by piping the output from summarize() into print().\nWe can perform multiple summaries at once by adding more statements inside the summarize() function. To try this out, calculate the mean bill length in addition to the mean weight.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  group_by(species, sex) |&gt;\n  summarize(\n    mean_weight = ___,\n    mean_bill_length = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  group_by(species, sex) |&gt;\n  summarize(\n    mean_weight = mean(body_mass_g),\n    mean_bill_length = mean(bill_length_mm)\n  )\n\n\n\n\nWhen performing summaries, we often want to know how many observations there are in each group (i.e., we want to count). We can do this with the function n(), which inside summarize() gives us the group size. So, we can count by adding a statement such as count = n() inside summarize(). Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  group_by(species, sex) |&gt;\n  summarize(\n    mean_weight = ___,\n    mean_bill_length = ___,\n    count = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  group_by(species, sex) |&gt;\n  summarize(\n    mean_weight = mean(body_mass_g),\n    mean_bill_length = mean(bill_length_mm),\n    count = n()\n  )\n\n\n\n\n\n\nRemoving missing values\nIf we try the previous calculation but grouping only by species and not by sex, we notice a problem: Most values have been replaced by NA.\n\n\n\n\n\n\n\n\nThis happens because R does not like to calculate the mean of a set of numbers where at least one is missing. Whenever there are missing values, we need to think carefully whether we can just ignore them or need to do something more sophisticated. In the penguins dataset there are only a handful of missing values, and therefore ignoring them is fine.\nWe can ignore missing values by setting na.rm = TRUE inside the mean() function. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  group_by(species) |&gt;\n  summarize(\n    mean_weight = mean(body_mass_g, ___),\n    mean_bill_length = mean(bill_length_mm, ___)\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  group_by(species) |&gt;\n  summarize(\n    mean_weight = mean(body_mass_g, na.rm = TRUE),\n    mean_bill_length = mean(bill_length_mm, na.rm = TRUE)\n  )\n\n\n\n\nAlternatively, we could filter out all rows that contain NAs in the columns of interest. We test whether a column contains NAs with is.na(&lt;column name&gt;), and to keep rows without NAs we use !is.na(&lt;column name&gt;). Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  filter(!is.na(body_mass_g), ___) |&gt;\n  group_by(species) |&gt;\n  summarize(\n    mean_weight = mean(body_mass_g),\n    mean_bill_length = mean(bill_length_mm)\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  filter(!is.na(body_mass_g), !is.na(bill_length_mm)) |&gt;\n  group_by(species) |&gt;\n  summarize(\n    mean_weight = mean(body_mass_g),\n    mean_bill_length = mean(bill_length_mm)\n  )"
  },
  {
    "objectID": "worksheets/data-wrangling-2.html#making-tables-wider-or-longer",
    "href": "worksheets/data-wrangling-2.html#making-tables-wider-or-longer",
    "title": "Data wrangling 2",
    "section": "Making tables wider or longer",
    "text": "Making tables wider or longer\nFor efficient data processing, we usually want tables in long form, where each columns is one variable and each row is one observation. However, in some applications, for example when making a table easier to read for humans, a wide format can be preferred. In a wide format, some variables are displayed as column names, and other variables are distributed over multiple columns.\nConsider the following two versions of a summary table. The first is in long format, where sex is one column and the mean weight is another.\n\n\n\n\n\n\n\n\nThe second is in wide format, where the values of the sex variable (female or male) are used as column headings, and the mean weight values are distributed over these two columns.\n\n\n\n\n\n\n\n\nYou can turn a long table into a wide table using the function pivot_wider(), which takes two arguments: names_from specifies the long column from which the new wide column names should be taken (here e.g., \"sex\"), and values_from specifies the long column from which the new wide values should be taken (here e.g., \"mean_weight\"). Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins_long |&gt;\n  pivot_wider(names_from = ___, values_from = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins_long |&gt;\n  pivot_wider(names_from = \"sex\", values_from = \"mean_weight\")\n\n\n\n\nYou can similarly turn a wide table into a long one using the function pivot_longer(). It has arguments cols, names_to, and values_to. cols specifies the wide columns on which to operate, names_to specifies into which long columns the names of the wide columns should be written, and values_to specfies into which long columns the values of the wide columns should be written. Note that while names_to and values_to are specified as strings (that is, in quotes, such as names_to = \"sex\"), the cols argument does not use quotes (e.g., cols = c(female, male)).\nTry this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins_wide |&gt;\n  pivot_longer(\n    cols = ___,\n    names_to = ___,\n    values_to = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins_wide |&gt;\n  pivot_longer(\n    cols = c(female, male),\n    names_to = \"sex\",\n    values_to = \"mean_weight\"\n  )\n\n\n\n\nNotice how the arguments names_from and values_from in pivot_wider() are exactly equivalent to names_to and values_to in pivot_longer()."
  },
  {
    "objectID": "worksheets/data-wrangling-2.html#combining-datasets-with-joins",
    "href": "worksheets/data-wrangling-2.html#combining-datasets-with-joins",
    "title": "Data wrangling 2",
    "section": "Combining datasets with joins",
    "text": "Combining datasets with joins\nFinally, we sometimes encounter the situation where we have two data sets that contain different pieces of information about the same subjects or objects, and we need to merge these tables for further analysis. In this situation, we need to perform a join, and there are multiple different types of joins available: left_join(), right_join(), inner_join(), full_join(). These joins all differ in how they handle cases where an observation is present in only one of the two tables but missing in the other.\nTwo explore joins, consider the following two datasets, which contain the population number of three Texas cities and the city areas, respectively. The cities in the two tables are not the same, on purpose.\n\n\n\n\n\n\n\n\nTry to merge TX_area into TX_population, using left_join().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nleft_join(___, ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nleft_join(TX_population, TX_area)\n\n\n\n\nWhat happens if you reverse the two arguments?\nNow try the same with full_join().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nfull_join(___, ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nfull_join(TX_population, TX_area)\n\n\n\n\nTry also right_join() and inner_join(). See if you can describe what each join function does and how they differ from one another."
  },
  {
    "objectID": "worksheets/dimension-reduction-2.html",
    "href": "worksheets/dimension-reduction-2.html",
    "title": "Dimension reduction 2",
    "section": "",
    "text": "In this worksheet, we will discuss how to perform t-SNE (t-distributed stochastic neighbor embedding), a type of non-linear dimension reduction.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with two datasets, spirals and blue_jays. The dataset spirals contains made-up data in two dimensions that forms three intertwined spirals.\n\n\n\n\n\n\n\n\nThe dataset blue_jays contains various measurements taken on blue jay birds."
  },
  {
    "objectID": "worksheets/dimension-reduction-2.html#introduction",
    "href": "worksheets/dimension-reduction-2.html#introduction",
    "title": "Dimension reduction 2",
    "section": "",
    "text": "In this worksheet, we will discuss how to perform t-SNE (t-distributed stochastic neighbor embedding), a type of non-linear dimension reduction.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with two datasets, spirals and blue_jays. The dataset spirals contains made-up data in two dimensions that forms three intertwined spirals.\n\n\n\n\n\n\n\n\nThe dataset blue_jays contains various measurements taken on blue jay birds."
  },
  {
    "objectID": "worksheets/dimension-reduction-2.html#performing-t-sne-on-the-spirals-dataset",
    "href": "worksheets/dimension-reduction-2.html#performing-t-sne-on-the-spirals-dataset",
    "title": "Dimension reduction 2",
    "section": "Performing t-SNE on the spirals dataset",
    "text": "Performing t-SNE on the spirals dataset\nWe start by taking a closer look at the spirals dataset. It has three columns, x, y, and group. When we create a scatterplot of y against x and color by group we see three intertwined spirals.\n\n\n\n\n\n\n\n\nWe perform t-SNE on this dataset with the function Rtsne(). Data preparation is similar to PCA: First, we discard all non-numeric columns. Then, we scale the variables to zero mean and unit variance.\n\n\n\n\n\n\n\n\nThe result looks quite similar to the plot of the raw data. That is the case because we have not customized t-SNE. The main parameter that we change when running t-SNE is the perplexity value (perplexity), and its default of 30 is relativley large for the spirals data. We can also change the random seed and the number of iterations until the algorithm is considered converged (max_iter, higher is better).\n\n\n\n\n\n\n\n\nNow, to see how the parameter settings change the t-SNE results, run the above code for a few different values of the three custom config parameters we have set up. Pay attention to how the output changes as you change each of these parameters.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# random seed\nset.seed(1255)\n\n# run t-SNE with different perplexity and total number of iterations\ntsne_fit &lt;- spirals |&gt;\n  select(where(is.numeric)) |&gt;\n  scale() |&gt;\n  Rtsne(perplexity = 8, max_iter = 1000)\n\n# extract coordinates from the `tsne_fit` object and plot\ntsne_fit$Y |&gt;\n  as.data.frame() |&gt;\n  # put non-numeric data columns back in to the dataset\n  cbind(select(spirals, -where(is.numeric))) |&gt;\n  ggplot(aes(V1, V2, color = group)) +\n  geom_point()"
  },
  {
    "objectID": "worksheets/dimension-reduction-2.html#performing-t-sne-on-the-blue_jays-dataset",
    "href": "worksheets/dimension-reduction-2.html#performing-t-sne-on-the-blue_jays-dataset",
    "title": "Dimension reduction 2",
    "section": "Performing t-SNE on the blue_jays dataset",
    "text": "Performing t-SNE on the blue_jays dataset\nNext we will perform t-SNE on the blue_jays dataset. See if you can adapt the code from the spirals data to work with the blue_jays dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n# random seed\nset.seed(1255)\n\n# run t-SNE with different perplexity and total number of iterations\ntsne_fit &lt;- ___ |&gt;\n  select(where(is.numeric)) |&gt;\n  scale() |&gt;\n  Rtsne(perplexity = 8, max_iter = 1000)\n\n# extract coordinates from the `tsne_fit` object and plot\ntsne_fit$Y |&gt;\n  as.data.frame() |&gt;\n  # put non-numeric data columns back in to the dataset\n  cbind(select(___, -where(is.numeric))) |&gt;\n  ggplot(aes(V1, V2, color = ___)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# random seed\nset.seed(1255)\n\n# run t-SNE with different perplexity and total number of iterations\ntsne_fit &lt;- blue_jays |&gt;\n  select(where(is.numeric)) |&gt;\n  scale() |&gt;\n  Rtsne(perplexity = 8, max_iter = 1000)\n\n# extract coordinates from the `tsne_fit` object and plot\ntsne_fit$Y |&gt;\n  as.data.frame() |&gt;\n  # put non-numeric data columns back in to the dataset\n  cbind(select(blue_jays, -where(is.numeric))) |&gt;\n  ggplot(aes(V1, V2, color = sex)) +\n  geom_point()\n\n\n\n\nAs before, change the t-SNE configuration parameters and see what effect different choices have on the results you obtain.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n# random seed\nset.seed(___)\n\n# run t-SNE with different perplexity and total number of iterations\ntsne_fit &lt;- blue_jays |&gt;\n  select(where(is.numeric)) |&gt;\n  scale() |&gt;\n  Rtsne(\n    perplexity = ___,\n    max_iter = ___\n  )\n\n# extract coordinates from the `tsne_fit` object and plot\ntsne_fit$Y |&gt;\n  as.data.frame() |&gt;\n  # put non-numeric data columns back in to the dataset\n  cbind(select(blue_jays, -where(is.numeric))) |&gt;\n  ggplot(aes(V1, V2, color = sex)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# random seed\nset.seed(9327)\n\n# run t-SNE with different perplexity and total number of iterations\ntsne_fit &lt;- blue_jays |&gt;\n  select(where(is.numeric)) |&gt;\n  scale() |&gt;\n  Rtsne(\n    perplexity = 6,\n    max_iter = 2000\n  )\n\n# extract coordinates from the `tsne_fit` object and plot\ntsne_fit$Y |&gt;\n  as.data.frame() |&gt;\n  # put non-numeric data columns back in to the dataset\n  cbind(select(blue_jays, -where(is.numeric))) |&gt;\n  ggplot(aes(V1, V2, color = sex)) +\n  geom_point()"
  },
  {
    "objectID": "worksheets/functional-programming.html",
    "href": "worksheets/functional-programming.html",
    "title": "Functional programming",
    "section": "",
    "text": "In this worksheet, we will discuss elements of functional programming in R.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data. We will be working with data on individual penguins in Antarctica."
  },
  {
    "objectID": "worksheets/functional-programming.html#introduction",
    "href": "worksheets/functional-programming.html#introduction",
    "title": "Functional programming",
    "section": "",
    "text": "In this worksheet, we will discuss elements of functional programming in R.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data. We will be working with data on individual penguins in Antarctica."
  },
  {
    "objectID": "worksheets/functional-programming.html#calling-functions-repeatedly",
    "href": "worksheets/functional-programming.html#calling-functions-repeatedly",
    "title": "Functional programming",
    "section": "Calling functions repeatedly",
    "text": "Calling functions repeatedly\nThe core concept in functional programming is a function, which is a way of running the same code multiple times on different input data. In R, functions are defined with the function keyword, followed by a list of arguments in parentheses and the body of the function in curly braces. For example, the following code defines a function that squares a numeric value.\n\n\n\n\n\n\n\n\nThe variable x is the argument of the function, and it can then be used in the body of the function for computations. The result of the last expression in the function body is used as the return value of the function, so this simple function returns the square of its argument. Note that functions are first-class objects in R, and we can assign a function to a variable using &lt;-, just like any other assignment in R.\nTo call a function, we write the name of the function followed by parentheses enclosing the argument(s). For example, the following code calculates the squares of 3, 4, and 5:\n\n\n\n\n\n\n\n\nWe often want to run a function on a set of given input values. In procedural programming, we would typically do this with a for loop. The equivalent concept in functional programming is the map. Specifically, the map() function takes as input a vector of values (e.g., the numbers from 3 to 5, 3:5) and a function name (e.g. square, note no parentheses) and applies the function to each value in the input vector.\n\n\n\n\n\n\n\n\nThe return result is a list, hence the weird double brackets ([[1]], [[2]], etc.). If instead we want a regular vector of numbers, we can use map_dbl(). Here, “dbl” stands for “double”, which is shorthand for “double precision floating point numbers”, the default numeric datatype of R.\n\n\n\n\n\n\n\n\nWhen using any of the map functions, instead of providing a function by name, we can also define a function in place, as a formula. We do so by writing an R expression with a tilde (~) in front. The parameter supplied by the map function is always called .x. So ~.x^2 is equivalent to function(.x) { .x^2 }.\n\n\n\n\n\n\n\n\nNow try these concepts yourself. First write a function that calculates the cube of its argument.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ncube &lt;- function(___) {\n  ___\n}\n\ncube(2)\ncube(3)\ncube(4)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncube &lt;- function(x) {\n  x^3\n}\n\ncube(2)\ncube(3)\ncube(4)\n\n\n\n\nNow use this function in conjunction with either map() or map_dbl() to calculate the first 5 cubes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ncube &lt;- function(x) {\n  x^3\n}\n\nmap(1:5, ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncube &lt;- function(x) {\n  x^3\n}\n\nmap(1:5, cube)\nmap_dbl(1:5, cube)\n\n\n\n\nNow calculate the first 5 cubes using the in-place function definition via a formula.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nmap(1:5, ~___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nmap(1:5, ~.x^3)\nmap_dbl(1:5, ~.x^3)\n\n\n\n\nThe map() function applies a function taking a single argument to a single vector of values. But what if we have a function with two arguments, say, a function that takes values x and y and returns their product? In this case, we can use map2(), which requires two input vectors and a function of two arguments.\n\n\n\n\n\n\n\n\nTo try this out, use a single map2() expression to calculate the square of 3, the cube of 4, and the fourth power of 5.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nmap2(3:5, 2:4, ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nmap2(3:5, 2:4, function(x, y) x^y)\n\n\n\n\nFinally, sometimes we want to call a function repeatedly but not to collect the return values but rather for side effects, such as printing output. In this case, we use walk() instead of map().\n\n\n\n\n\n\n\n\nTry this out by calling the following function print_value() on the input values 1, 2, and 3.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nprint_value &lt;- function(x) {\n  cat(\"The value is\", x, \"\\n\")\n}\n\nwalk(1:3, ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nprint_value &lt;- function(x) {\n  cat(\"The value is\", x, \"\\n\")\n}\n\nwalk(1:3, print_value)"
  },
  {
    "objectID": "worksheets/functional-programming.html#nesting-and-unnesting",
    "href": "worksheets/functional-programming.html#nesting-and-unnesting",
    "title": "Functional programming",
    "section": "Nesting and unnesting",
    "text": "Nesting and unnesting\nFunctional programming becomes a very powerful concept in data analysis when combined with nested data frames, so we will be discussing nesting and unnesting next.\nWe use the function nest() to take rectangular regions in a data table and compress them into a single cell in a higher-level table. This process is useful when we want to store all the information for one category of data in a single cell.\nFor example, we can store all the penguin data in a nested table with three rows and two columns, where one column contains the penguins species and the other column contains all the data for that species. We generate such a table as follows.\n\n\n\n\n\n\n\n\nThe specification data = -species means “create a new column called data and move everything into this column except the contents of the species column”. The nest() function will automatically generate exactly one row for each unique combination of data values that are not being nested. Therefore, we end up with three rows, one for each species.\nThe data column is a list column, and we can access individual values in it via list indexing, i.e., double square brackets. So, data[[1]] is the first nested table, data[[2]] is the second nested table, and so on. For example, the following code extracts all the data for Gentoo penguins.\n\n\n\n\n\n\n\n\nNow try this out. First, make a nested table but nest by island.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  nest(data = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  nest(data = -island)\n\n\n\n\nNow extract the data table for the third island.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins_nested &lt;- penguins |&gt;\n  nest(data = -island)\n\npenguins_nested$data[[___]]\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins_nested &lt;- penguins |&gt;\n  nest(data = -island)\n\npenguins_nested$data[[3]]\n\n\n\n\nNow nest by species and island at the same time. You can nest by multiple columns by excluding both from the newly created data column, via data = -c(species, island).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  nest(data = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  nest(data = -c(species, island))\n\n\n\n\nTo unnest, we use the function unnest(). Its argument cols takes the name of the column to be unnested. For example, if we nest into the data column, as we have done in all examples so far, then cols = data unnests this column.\n\n\n\n\n\n\n\n\nTry this for yourself in the following example. Note that the data column has a different name here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins_nested &lt;- penguins |&gt;\n  nest(species_data = -species)\n\npenguins_nested |&gt;\n  unnest(cols = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins_nested &lt;- penguins |&gt;\n  nest(species_data = -species)\n\npenguins_nested |&gt;\n  unnest(cols = species_data)"
  },
  {
    "objectID": "worksheets/functional-programming.html#plotting-subsets-of-data",
    "href": "worksheets/functional-programming.html#plotting-subsets-of-data",
    "title": "Functional programming",
    "section": "Plotting subsets of data",
    "text": "Plotting subsets of data\nNow we will use the concepts of mapping and nesting to automatically create plots of subsets of data. Specifically, we will make pie charts of the species composition of penguin species on the different islands. The pie charts will be generated by the following function, which takes as arguments the data for the island and the name of the island.\n\n\n\n\n\n\n\n\nWe can use this function for a single island like so.\n\n\n\n\n\n\n\n\nHowever, here we want to automate the process of calling this function for all islands separately. See if you can make this happen, using the functions nest(), mutate(), map2(), pull(), and walk(). Note: The individual stages of the calculation are provided as hints, so you can click through them one-by-one if you get stuck or something is not clear.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nFirst create a nested table so it has three rows, one for each island. The table should have a column data whose entries contain all the data for each island.\npenguins |&gt;\n  nest(___)\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nNext use mutate() and map2() to run the make_pie() function on each subset of data and store the resulting plots.\npenguins |&gt;\n  # move all data for each island into a single\n  # entry in a column called `data`\n  nest(data = -island) |&gt;\n  ___ # continue here with mutate\n\n\n\n\n\n\n\n\n\n\n\nHint 3\n\n\n\n\n\nNext extract the plots column.\npenguins |&gt;\n  # move all data for each island into a single\n  # entry in a column called `data`\n  nest(data = -island) |&gt;\n  # run the `make_pie()` function on each dataset separately,\n  # store result in a column `plots`\n  mutate(\n    plots = map2(data, island, make_pie)\n  ) |&gt;\n  ___ # extract the plots column\n\n\n\n\n\n\n\n\n\n\n\nHint 4\n\n\n\n\n\nNext use walk() to print all the plots.\npenguins |&gt;\n  # move all data for each island into a single\n  # entry in a column called `data`\n  nest(data = -island) |&gt;\n  # run the `make_pie()` function on each dataset separately,\n  # store result in a column `plots`\n  mutate(\n    plots = map2(data, island, make_pie)\n  ) |&gt;\n  pull(plots) |&gt;  # extract the column holding the plots\n  ___ # use `walk()` to print all the plots\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  # move all data for each island into a single\n  # entry in a column called `data`\n  nest(data = -island) |&gt;\n  # run the `make_pie()` function on each dataset separately,\n  # store result in a column `plots`\n  mutate(\n    plots = map2(data, island, make_pie)\n  ) |&gt;\n  pull(plots) |&gt; # extract the column holding the plots\n  walk(print)    # print all plots one by one"
  },
  {
    "objectID": "worksheets/getting-things-in-order.html",
    "href": "worksheets/getting-things-in-order.html",
    "title": "Getting things into the right order",
    "section": "",
    "text": "In this worksheet, we will discuss how to manipulate factor levels such that plots show visual elements in the correct order.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nWe will be working with the dataset penguins, which contains data on individual penguins on Antarctica.\npenguins\n\n\n\n\n\n\n\n\n\n\nWe will also be working with the dataset gapminder, which contains information about life expectancy, population number, and GDP for 142 different countries.\n\n\n\n\n\n\n\n\nFinally, we will be working with the dataset Aus_athletes, which contains various physiological measurements made on athletes competing in different sports."
  },
  {
    "objectID": "worksheets/getting-things-in-order.html#introduction",
    "href": "worksheets/getting-things-in-order.html#introduction",
    "title": "Getting things into the right order",
    "section": "",
    "text": "In this worksheet, we will discuss how to manipulate factor levels such that plots show visual elements in the correct order.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nWe will be working with the dataset penguins, which contains data on individual penguins on Antarctica.\npenguins\n\n\n\n\n\n\n\n\n\n\nWe will also be working with the dataset gapminder, which contains information about life expectancy, population number, and GDP for 142 different countries.\n\n\n\n\n\n\n\n\nFinally, we will be working with the dataset Aus_athletes, which contains various physiological measurements made on athletes competing in different sports."
  },
  {
    "objectID": "worksheets/getting-things-in-order.html#manual-reordering",
    "href": "worksheets/getting-things-in-order.html#manual-reordering",
    "title": "Getting things into the right order",
    "section": "Manual reordering",
    "text": "Manual reordering\nThe simplest form of reordering is manual, where we state explicitly in which order we want some graphical element to appear. We reorder manually with the function fct_relevel(), which takes as arguments the variable to reorder and the levels we want to reorder, in the order in which we want them to appear.\nHere is a simple example. We create a factor x with levels \"A\", \"B\", \"C\", in that order, and then we reorder the levels to \"B\", \"C\", \"A\".\n\n\n\n\n\n\n\n\nTry this out for yourself. Place the levels into a few different orderings. Also try listing only some of the levels to reorder.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nx &lt;- factor(c(\"A\", \"B\", \"A\", \"C\", \"B\"))\nx\n\nfct_relevel(x, \"C\", \"A\", \"B\")\n\n\n\n\nNow we apply this concept to a ggplot graph. We will work with the following boxplot visualization of the distribution of bill length versus penguin species.\n\n\n\n\n\n\n\n\nUse the function fct_relevel() to place the three species into the order Chinstrap, Gentoo, Adelie. (Hint: You will have to use a mutate() statement to modify the species column.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  mutate(\n    species = fct_relevel(___)\n  ) |&gt;\n  ggplot(aes(species, bill_length_mm)) +\n  geom_boxplot(na.rm = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  mutate(\n    species = fct_relevel(species, \"Chinstrap\", \"Gentoo\", \"Adelie\")\n  ) |&gt;\n  ggplot(aes(species, bill_length_mm)) +\n  geom_boxplot(na.rm = TRUE)\n\n\n\n\nNow flip the x and y axes, making sure that the order remains Chinstrap, Gentoo, Adelie from top to bottom.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npenguins |&gt;\n  mutate(\n    species = fct_relevel(species, ___)\n  ) |&gt;\n  ggplot(aes(bill_length_mm, species)) +\n  geom_boxplot(na.rm = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\npenguins |&gt;\n  mutate(\n    species = fct_relevel(species, \"Adelie\", \"Gentoo\", \"Chinstrap\")\n  ) |&gt;\n  ggplot(aes(bill_length_mm, species)) +\n  geom_boxplot(na.rm = TRUE)"
  },
  {
    "objectID": "worksheets/getting-things-in-order.html#reordering-based-on-frequency",
    "href": "worksheets/getting-things-in-order.html#reordering-based-on-frequency",
    "title": "Getting things into the right order",
    "section": "Reordering based on frequency",
    "text": "Reordering based on frequency\nManual reordering is cumbersome if there are many levels that need to be reorderd. Therefore, we often use functions that can reorder automatically based on some quantitative criterion. For example, we can use fct_infreq() to order a factor based on the number of occurrences of each level in the dataset. And we can reverse the order of a factor using the function fct_rev(). These two functions are particularly useful for making bar plots.\nConsider the following plot of the number of athletes competing in various sports in the Aus_athletes dataset. This plot is problematic because the sports are arranged in an arbitrary (here: alphabetic) order that is not meaningful for the data shown.\n\n\n\n\n\n\n\n\nReorder the sport column so that the sport with the most athletes appears on top and the sport with the least athletes at the bottom.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nAus_athletes |&gt;\n  mutate(\n    sport = ___\n  ) |&gt;\n  ggplot(aes(y = sport)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAus_athletes |&gt;\n  mutate(\n    sport = fct_rev(fct_infreq(sport))\n  ) |&gt;\n  ggplot(aes(y = sport)) +\n  geom_bar()"
  },
  {
    "objectID": "worksheets/getting-things-in-order.html#reordering-based-on-numerical-values",
    "href": "worksheets/getting-things-in-order.html#reordering-based-on-numerical-values",
    "title": "Getting things into the right order",
    "section": "Reordering based on numerical values",
    "text": "Reordering based on numerical values\nAnother common problem we encounter is that we want to order a factor based on some other numerical variable, possibly after we have calculated some summary statistic such as the median, minimum, or maximum.\nAs an example for this problem, we consider a plot of the life expectancy in various countries in the Americas over time, shown as colored tiles.\n\n\n\n\n\n\n\n\nThe default alphabetic ordering creates a meaningless color pattern that is difficult to read. It would make more sense to order the countries by some function of the life expectancy values, such as the minimum, median, or maximum value. We can do this with the function fct_reorder(), which takes three arguments: The factor to reorder, the numerical variable on which to base the ordering, and the name of a function (such as min, median, max) to be applied to calculate the ordering statistic.\nModify the above plot so the countries are ordered by their median life expectancy over the observed time period.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ngapminder |&gt;\n  filter(continent == \"Americas\") |&gt;\n  mutate(\n    country = fct_reorder(___, ___, ___)\n  ) |&gt;\n  ggplot(aes(year, country, fill = lifeExp)) + \n  geom_tile() +\n  scale_fill_viridis_c(option = \"A\")\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ngapminder |&gt;\n  filter(continent == \"Americas\") |&gt;\n  mutate(\n    country = fct_reorder(country, lifeExp, median)\n  ) |&gt;\n  ggplot(aes(year, country, fill = lifeExp)) + \n  geom_tile() +\n  scale_fill_viridis_c(option = \"A\")\n\n\n\n\nTry other orderings, such as min, max, or mean.\nNext, instead of plotting this data as colored tiles, plot it as lines, using facets to make separate panels for each country.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ngapminder |&gt;\n  filter(continent == \"Americas\") |&gt;\n  mutate(country = fct_reorder(country, lifeExp, median)) |&gt;\n  ggplot(___) + \n  geom____() +\n  facet_wrap(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ngapminder |&gt;\n  filter(continent == \"Americas\") |&gt;\n  mutate(country = fct_reorder(country, lifeExp, median)) |&gt;\n  ggplot(aes(year, lifeExp)) + \n  geom_line() +\n  facet_wrap(vars(country))\n\n\n\n\nAgain, try various orderings, including min, max, or mean."
  },
  {
    "objectID": "worksheets/getting-things-in-order.html#lumping-of-factor-levels",
    "href": "worksheets/getting-things-in-order.html#lumping-of-factor-levels",
    "title": "Getting things into the right order",
    "section": "Lumping of factor levels",
    "text": "Lumping of factor levels\nFinally, we sometimes have factors with too many levels and we want to combine some into a catch-all level such as “Other”. We illustrate this concept with the following plot, which shows BMI (body-mass index) versus height for male athletes, broken down by sport.\n\n\n\n\n\n\n\n\nWe want to modify this plot so that all sports other than basketball and water polo are shown as “Other”. To achieve this goal, you will have to create a new column called sport_lump that contains a lumped version of the sport factor.\nThe function that does the lumping is called fct_other(), and it takes as argument the variable to lump and an argument keep listing the values to keep or alternatively an argument drop listing the values to drop. Since you want to keep only basketball and water polo, use the variant with the keep argument.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nAus_athletes |&gt;\n  filter(sex == \"m\") |&gt;\n  mutate(\n    sport_lump = fct_other(sport, keep = ___)\n  ) |&gt;\n  ggplot(aes(height, bmi, color = sport_lump)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAus_athletes |&gt;\n  filter(sex == \"m\") |&gt;\n  mutate(\n    sport_lump = fct_other(sport, keep = c(\"basketball\", \"water polo\"))\n  ) |&gt;\n  ggplot(aes(height, bmi, color = sport_lump)) +\n  geom_point()\n\n\n\n\nNow use the variant of the fct_other() function with the drop argument. Drop field, rowing, and tennis from the sports considered individually.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nAus_athletes |&gt;\n  filter(sex == \"m\") |&gt;\n  mutate(\n    sport_lump = fct_other(sport, drop = ___)\n  ) |&gt;\n  ggplot(aes(height, bmi, color = sport_lump)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAus_athletes |&gt;\n  filter(sex == \"m\") |&gt;\n  mutate(\n    sport_lump = fct_other(sport, drop = c(\"field\", \"rowing\", \"tennis\"))\n  ) |&gt;\n  ggplot(aes(height, bmi, color = sport_lump)) +\n  geom_point()\n\n\n\n\nFinally, try other lumping functions also. For example, the function fct_lump_n() retains the n most frequent levels and lump all others into \"Other\". See if you can create a meaningful example with the Aus_athletes dataset that uses the fct_lump_n() function. Hint: Try to make a bar plot, similar to the one we made in the section on reordering based on frequency."
  },
  {
    "objectID": "worksheets/interactive-plots.html",
    "href": "worksheets/interactive-plots.html",
    "title": "Interactive plots",
    "section": "",
    "text": "In this worksheet, we will discuss how to combine several ggplot2 plots into one compound figure.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the dataset texas_counties. This dataset contains various pieces of information about each county in Texas, such as the number of people living in the county in 2010 (pop2010), the size of each county (column area), and the median income (median_income). The column popratio is the ratio of the number of inhabitants to the median across all counties. The dataset also contains the shape information about each county (stored in the geometry column). The column FIPS contains a five-digit id code that uniquely represents each county."
  },
  {
    "objectID": "worksheets/interactive-plots.html#introduction",
    "href": "worksheets/interactive-plots.html#introduction",
    "title": "Interactive plots",
    "section": "",
    "text": "In this worksheet, we will discuss how to combine several ggplot2 plots into one compound figure.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the dataset texas_counties. This dataset contains various pieces of information about each county in Texas, such as the number of people living in the county in 2010 (pop2010), the size of each county (column area), and the median income (median_income). The column popratio is the ratio of the number of inhabitants to the median across all counties. The dataset also contains the shape information about each county (stored in the geometry column). The column FIPS contains a five-digit id code that uniquely represents each county."
  },
  {
    "objectID": "worksheets/interactive-plots.html#interactice-scatterplots",
    "href": "worksheets/interactive-plots.html#interactice-scatterplots",
    "title": "Interactive plots",
    "section": "Interactice scatterplots",
    "text": "Interactice scatterplots\nThe ggiraph package provides the simplest means towards adding a moderate amount of interactivity into ggplot2 plots. It makes it quite straightforward to produce interactive tooltips, interactive highlighting, and the ability to execute actions in the browser (such as opening a new page) when the user clicks on specific elements in the plot.\nAs a first example, we will create an interactive version of the following plot, which shows median income in Texas counties versus the number of inhabitants of that county.\n\n\n\n\n\n\n\n\nTo turn this plot interactive, we need to make at least the following three modifications:\n\nReplace the geom with the appropriate interactive version. For example, geom_point() is replaced by geom_point_interactive().\nAdd an interactive aesthetic. For example, the tooltip aesthetic sets the contents of tooltips that show when hovering over the data points.\nDisplay the interactive plot object by calling the girafe() function with the argument ggobj. For example, if your ggplot2 plot is stored in a variable p, you would call girafe(ggobj = p).\n\nMake these modifications to the above plot to create an interactive version.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntexas_scatter &lt;- texas_counties |&gt;\n  ggplot(aes(pop2010, median_income)) +\n  geom_point_interactive(\n    aes(tooltip = ___),\n    na.rm = TRUE, size = 2\n  ) +\n  scale_x_log10()\n\ngirafe(\n  ggobj = ___\n)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntexas_scatter &lt;- texas_counties |&gt;\n  ggplot(aes(pop2010, median_income)) +\n  geom_point_interactive(\n    aes(tooltip = county),\n    na.rm = TRUE, size = 2\n  ) +\n  scale_x_log10()\n\ngirafe(\n  ggobj = texas_scatter\n)\n\n\n\n\nIn addition to the tooltip aesthetic, there is also the data_id aesthetic, which enables highlighting of the selected point(s). If each element has its own data_id then elements get highlighted individually. Alternatively, if elements share their data_id value then they get highlighted jointly.\nFirst, try individual highlighting, by using county as the data_id.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntexas_scatter &lt;- texas_counties |&gt;\n  ggplot(aes(pop2010, median_income)) +\n  geom_point_interactive(\n    aes(\n      tooltip = county,\n      data_id = ___\n    ),\n    na.rm = TRUE, size = 2\n  ) +\n  scale_x_log10()\n\ngirafe(\n  ggobj = texas_scatter\n)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntexas_scatter &lt;- texas_counties |&gt;\n  ggplot(aes(pop2010, median_income)) +\n  geom_point_interactive(\n    aes(\n      tooltip = county,\n      data_id = county\n    ),\n    na.rm = TRUE, size = 2\n  ) +\n  scale_x_log10()\n\ngirafe(\n  ggobj = texas_scatter\n)\n\n\n\n\nNext, try joint highlighting, by creating two groups: one for counties with a median income above $60,000 and one for all other counties.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntexas_scatter &lt;- texas_counties |&gt;\n  mutate(\n    income = ifelse(___)\n  ) |&gt;\n  ggplot(aes(pop2010, median_income, color = ___)) +\n  geom_point_interactive(\n    aes(\n      tooltip = county,\n      data_id = ___\n    ),\n    na.rm = TRUE, size = 2\n  ) +\n  scale_x_log10()\n\ngirafe(\n  ggobj = texas_scatter\n)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntexas_scatter &lt;- texas_counties |&gt;\n  mutate(\n    income = ifelse(median_income &gt; 60000, \"high\", \"low\")\n  ) |&gt;\n  ggplot(aes(pop2010, median_income, color = income)) +\n  geom_point_interactive(\n    aes(\n      tooltip = county,\n      data_id = income\n    ),\n    na.rm = TRUE, size = 2\n  ) +\n  scale_x_log10()\n\ngirafe(\n  ggobj = texas_scatter\n)\n\n\n\n\nYou can customize how tooltips and highlighted data points appear by providing the argument options in the girafe() function. Options are separated out by tooltip options, hover options, etc. which are provided inside a list(). Tooltip options are set via opts_tooltip(), and hover options are set via opts_hover(). Both functions take an argument css which takes CSS declarations such as background: #F5F5F5; or fill: blue;. Thus, customization code could look as follows:\ngirafe(\n  ggobj = texas_scatter,\n  options = list(\n    opts_tooltip(\n      css = \"background: #F5F5F5; color: black;\"\n    ),\n    opts_hover(\n      css = \"fill: orange;\"\n    )\n  )\n)\nTry this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntexas_scatter &lt;- texas_counties |&gt;\n  ggplot(aes(pop2010, median_income)) +\n  geom_point_interactive(\n    aes(\n      tooltip = county,\n      data_id = county\n    ),\n    na.rm = TRUE, size = 2\n  ) +\n  scale_x_log10()\n\ngirafe(\n  ggobj = texas_scatter,\n  options = list(\n    opts_tooltip(\n      css = ___\n    ),\n    opts_hover(\n      css = ___\n    )\n  )\n)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntexas_scatter &lt;- texas_counties |&gt;\n  ggplot(aes(pop2010, median_income)) +\n  geom_point_interactive(\n    aes(\n      tooltip = county,\n      data_id = county\n    ),\n    na.rm = TRUE, size = 2\n  ) +\n  scale_x_log10()\n\ngirafe(\n  ggobj = texas_scatter,\n  options = list(\n    opts_tooltip(\n      css = \"background: #F5F5F5; color: #191970;\"\n    ),\n    opts_hover(\n      css = \"fill: #D83832;\"\n    )\n  )\n)\n\n\n\n\nAlso try different CSS properties to see which effect they have. For example, for the tooltip CSS, try padding (docs). For the hove CSS, try stroke (docs) or stroke-width (docs)."
  },
  {
    "objectID": "worksheets/interactive-plots.html#interactive-maps",
    "href": "worksheets/interactive-plots.html#interactive-maps",
    "title": "Interactive plots",
    "section": "Interactive maps",
    "text": "Interactive maps\nWe can also make interactive maps. This requires using geom_sf_interactive() instead of geom_sf(), and again using aesthetics such as tooltip or data_id.\nAs an example, consider this non-interactive plot of median income in Texas counties.\n\n\n\n\n\n\n\n\nMake it interactive, such that by hovering over the map counties get highlighted and a tooltip shows the county name.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntexas_county_map &lt;- texas_counties %&gt;%\n  ggplot(aes(fill = median_income)) +\n  geom_sf_interactive(\n    aes(\n      tooltip = county,\n      data_id = county\n    ),\n    size = 0.2, color = \"black\"\n  ) +\n  scale_fill_viridis_c(option = \"E\") +\n  theme_minimal()\n\ngirafe(\n  ggobj = texas_county_map\n)\n\n\n\n\nWe can also make the counties in the map clickable, by providing an onclick aesthetic. The aesthetic needs to be provided with strings holding JavaScript code that should be executed when the user clicks on the element. For example, to open the Wikipedia page for Travis County we would need to provide the following code snippet:\nwindow.open(\"https://en.wikipedia.org/wiki/Travis County, Texas\")\nIntegrate this into the previous map by writing code that generates the JavaScript snippets for each county and maps them onto the onclick aesthetic. Hint: The glue() function will be very helpful here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ntexas_county_map &lt;- texas_counties %&gt;%\n  mutate(\n    onclick = glue(___)\n  ) %&gt;%\n  ggplot(aes(fill = median_income)) +\n  geom_sf_interactive(\n    aes(\n      tooltip = county,\n      data_id = county,\n      onclick = ___\n    ),\n    size = 0.2, color = \"black\"\n  ) +\n  scale_fill_viridis_c(option = \"E\") +\n  theme_minimal()\n\ngirafe(\n  ggobj = texas_county_map\n)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ntexas_county_map &lt;- texas_counties %&gt;%\n  mutate(\n    onclick = glue('window.open(\"https://en.wikipedia.org/wiki/{county} County, Texas\")')\n  ) %&gt;%\n  ggplot(aes(fill = median_income)) +\n  geom_sf_interactive(\n    aes(\n      tooltip = county,\n      data_id = county,\n      onclick = onclick\n    ),\n    size = 0.2, color = \"black\"\n  ) +\n  scale_fill_viridis_c(option = \"E\") +\n  theme_minimal()\n\ngirafe(\n  ggobj = texas_county_map\n)\n\n\n\n\nInteractive maps become particularly useful if you combine them with one or more additional plots that show further information, e.g. a scatterplot. Then, we can highlight a county in the map and the corresponding data point in the scatterplot or vice versa. We will do this by combining the scatter plot from the previous section with the Texas map from this section. You can combine two plots with the function plot_grid(), which takes as argument the two plots to combine, e.g. plot_grid(texas_scatter, texas_county_map). This can be used as the ggobj in girafe().\nHint: Set width_svg = 8 and height_svg = 4 in the girafe() function to obtain an appropriate plot layout.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n# first make the scatter plot\ntexas_scatter &lt;- texas_counties %&gt;%\n  ggplot(aes(pop2010, median_income)) +\n  geom_point_interactive(\n    aes(\n      tooltip = county,\n      data_id = county\n    ),\n    na.rm = TRUE, size = 3\n  ) +\n  scale_x_log10() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n# first make the scatter plot\ntexas_scatter &lt;- texas_counties %&gt;%\n  ggplot(aes(pop2010, median_income)) +\n  geom_point_interactive(\n    aes(\n      tooltip = county,\n      data_id = county\n    ),\n    na.rm = TRUE, size = 3\n  ) +\n  scale_x_log10() +\n  theme_bw()\n\n# then make the map\ntexas_county_map &lt;- texas_counties %&gt;%\n  ggplot() +\n  geom_sf_interactive(\n    aes(\n      tooltip = county,\n      data_id = county\n    ),\n    size = 0.2, color = \"black\"\n  ) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n# first make the scatter plot\ntexas_scatter &lt;- texas_counties %&gt;%\n  ggplot(aes(pop2010, median_income)) +\n  geom_point_interactive(\n    aes(\n      tooltip = county,\n      data_id = county\n    ),\n    na.rm = TRUE, size = 3\n  ) +\n  scale_x_log10() +\n  theme_bw()\n\n# then make the map\ntexas_county_map &lt;- texas_counties %&gt;%\n  ggplot() +\n  geom_sf_interactive(\n    aes(\n      tooltip = county,\n      data_id = county\n    ),\n    size = 0.2, color = \"black\"\n  ) +\n  theme_void()\n\n# then combine\ngirafe(\n  ggobj = (___ | ___),\n  width_svg = 8,\n  height_svg = 4\n)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# first make the scatter plot\ntexas_scatter &lt;- texas_counties %&gt;%\n  ggplot(aes(pop2010, median_income)) +\n  geom_point_interactive(\n    aes(\n      tooltip = county,\n      data_id = county\n    ),\n    na.rm = TRUE, size = 3\n  ) +\n  scale_x_log10() +\n  theme_bw()\n\n# then make the map\ntexas_county_map &lt;- texas_counties %&gt;%\n  ggplot() +\n  geom_sf_interactive(\n    aes(\n      tooltip = county,\n      data_id = county\n    ),\n    size = 0.2, color = \"black\"\n  ) +\n  theme_void()\n\n# then combine\ngirafe(\n  ggobj = (texas_scatter | texas_county_map),\n  width_svg = 8,\n  height_svg = 4\n)"
  },
  {
    "objectID": "worksheets/intro-to-R.html#introduction",
    "href": "worksheets/intro-to-R.html#introduction",
    "title": "Introduction to R",
    "section": "Introduction",
    "text": "Introduction\nIn this worksheet, we will cover some of the basic concepts of the R programming language. The worksheet is not an exhaustive introduction to the language, but it will cover the most important concepts and in particular the concepts where R differs from other languages you may be familiar with. If you have prior R experience you can skip this worksheet.\nR is a language designed for interactive data analysis, and some of its features may seem strange when approached from the perspective of a general purpose programming language. Keep in mind that language features that simplify interactive work may get in the way of writing complex programs and vice versa.\nPlease wait a moment until the live R session is fully set up and all packages are loaded."
  },
  {
    "objectID": "worksheets/intro-to-R.html#basic-data-types",
    "href": "worksheets/intro-to-R.html#basic-data-types",
    "title": "Introduction to R",
    "section": "Basic data types",
    "text": "Basic data types\nR implements all the standard mathematical operations you would expect, such as addition, subtraction, etc., as well as special functions. This will generally work just like you would expect from other languages.\n\n\n\n\n\n\n\n\nTry this out. Can you calculate 2 to the power of 5? Or the sin of pi/4? Or the square-root of 2?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n2^5\nsin(pi/4)\nsqrt(2)\n\n\n\n\nOne way in which R differs from most programming languages is that it is inherently vectorized. In R, you always work with vectors of numbers rather than with individual values. (A vector is an ordered set of values of the same data type.) Vectors are created with c(...), as in c(1, 2, 3). You can also create vectors of consecutive integers using the colon notation, as in 1:3 or 3:1. The latter places the integers into the reverse order.\n\n\n\n\n\n\n\n\nTry this out. Make a vector of the integers from 1 to 10. Make a vector of the values 0.25, 0.5, 0.75. Make a vector of the words “orange”, “banana”, “grapefruit”.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n1:10\nc(0.25, 0.5, 0.75)\nc(\"orange\", \"banana\", \"grapefruit\")\n\n\n\n\nMathematical operations are also vectorized, so you can for example multiply all values in a vector by the same number or calculate multiple square roots at once. You can also do mathematical operations combining two (or more) vectors and the operation will be element-wise. If the numbers of elements don’t match you will get a warning but R will still give you a result. However, it’s generally best to avoid combining vectors with mismatched lengths, as the results can be non-intuitive.\n\n\n\n\n\n\n\n\nTry this out. Make a vector of all the squares of the numbers from 1 to 5. Also make a vector of the values 0.25, 0.5, 0.75, by using a vectorized mathematical expression.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n(1:5)^2\n(1:3)/4\n\n\n\n\nR also has logical values TRUE and FALSE (written in all capitals). Logical values also are vectorized, and they can be created by vectorized comparisons. This is very important for data analysis tasks.\n\n\n\n\n\n\n\n\nTry this out. Manually create a vector of logical values. Then create a vector of logical values via comparison.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nc(TRUE, TRUE, TRUE, FALSE)\n(1:10) &lt;= 5\n\n\n\n\nYou can combine vectors of logical values with & (logical AND) and | (logical OR). You can negate logical values with ! (logical NOT).\n\n\n\n\n\n\n\n\nTry this out. Combine some logical vectors with & and |. Also negate a logical vector.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n!c(FALSE, TRUE) & c(TRUE, FALSE)\nc(FALSE, TRUE) | c(TRUE, FALSE)"
  },
  {
    "objectID": "worksheets/intro-to-R.html#missing-values",
    "href": "worksheets/intro-to-R.html#missing-values",
    "title": "Introduction to R",
    "section": "Missing values",
    "text": "Missing values\nR supports the concept of missing values. Missing values are data values that don’t exist. This is a common issue in real-world data. For example, consider a scenario where people are asked to fill out a questionaire about various aspects of who they are and where they live, and one question asks about where they were born, and some people simply don’t answer that question. The result is a missing value, and we need the ability to express this concept.\nIn R, missing values are denoted by NA. You can use NA as a value for any vector.\n\n\n\n\n\n\n\n\nNote that the NA indicating a missing value is not enclosed in quotes, even for vectors of words (i.e, character strings).\nIn computations, missing values remain missing. You can check for missingness via is.na().\n\n\n\n\n\n\n\n\nTry this out. Make both a numerical and a character vector with some missing values. Also test for the missing positions in one of the vectors you made.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nc(NA, 1, NA, 1)\nc(\"banana\", NA, \"orange\", NA)\nis.na(c(\"banana\", NA, \"orange\", NA))"
  },
  {
    "objectID": "worksheets/intro-to-R.html#variables-and-functions",
    "href": "worksheets/intro-to-R.html#variables-and-functions",
    "title": "Introduction to R",
    "section": "Variables and functions",
    "text": "Variables and functions\nAny data values or objects that you are working with in R can be assigned to variables to be reused later. Assignment in R is expressed with the &lt;- operator. (You can also assign with = but this is generally discouraged.) If you subsequently just write the variable name by itself R prints out the value corresponding to that variable.\n\n\n\n\n\n\n\n\nTry this out. Assign the number 5 to a variable called foo and then print the value of foo. Then calculate the cosine of this number.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nfoo &lt;- 5\nfoo\ncos(foo)\n\n\n\n\nIn addition to working with variables, we commonly use and interact with functions in R. Functions are a way to store code and reuse it at a later stage. To call a function (which means to execute the code the function stores), you write the name of the variable storing the function followed by parentheses, as in sin() for the sine function. Inside the parentheses we can place values that are called “arguments,” as in sin(0.5). These arguments turn into variables that are used inside the function body.\nIn R, function arguments are always named, which means you can write the name of the argument when you provide the argument value, as in sin(x = 0.5). This is helpful for functions with many arguments, as without providing the argument names it can be confusing which value gets assigned to which argument. If you don’t name the function arguments, then values are assigned to arguments in order (positional matching), similarly to how most other programming languages work.\nIn the following example, the function example_fun() takes three arguments, a, b, and c, and each argument has a default value that will be used in case the argument is not provided when the function is called. The function then simply prints the values of the arguments. This allows us to explore how argument matching works in R.\n\n\n\n\n\n\n\n\nNow try this out yourself. Using the function example_fun() defined above, see what happens when you provide different arguments, positional or named. Do you understand what example_fun(2, a = 1) does?"
  },
  {
    "objectID": "worksheets/intro-to-R.html#packages",
    "href": "worksheets/intro-to-R.html#packages",
    "title": "Introduction to R",
    "section": "Packages",
    "text": "Packages\nMany R features are provided by extension packages. You need to load those packages with library() before you can use them. For example, throughout this class, we make extensive use of the tidyverse package and therefore you will see library(tidyverse) at the beginning of most worksheets and homework templates. One of the most common problem students encounter in assignments is that they want to use a function from a package but have not properly loaded the package.\nNote that we don’t normally put the package name in quotes inside the library() statement.\nUpon loading, some packages write out all sorts of messages. In particular, the tidyverse package lists a number of “conflicts”. This frequently confuses students as they think something has gone wrong. You can just ignore these conflicts. They are expected and they will not interfere with your work in this class.\n\n\n\n\n\n\n\n\nTry out loading a package. Load the package ggridges. Then load the package cowplot.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nlibrary(ggridges)\nlibrary(cowplot)"
  },
  {
    "objectID": "worksheets/intro-to-R.html#numerical-and-logical-indexing",
    "href": "worksheets/intro-to-R.html#numerical-and-logical-indexing",
    "title": "Introduction to R",
    "section": "Numerical and logical indexing",
    "text": "Numerical and logical indexing\nR has a variety of ways to extract specific values or subsets of a vector. First, you can extract an individual element by indexing with square brackets. For example, if x is a vector, x[1] is the first element, x[2] is the second element, and so on. Note that in R, the first element of a vector is number 1, not number 0 as it is in most other languages (Python, C, Rust, etc.). You can also extract multiple elements by placing a vector of numeric values inside the square brackets.\n\n\n\n\n\n\n\n\nNegative indices remove the respective elements.\n\n\n\n\n\n\n\n\nTry this out. Extract the first element from the names vector, then extract the last two, then extract all but the first.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nnames[1]\nnames[c(3, 4)]\nnames[-1]\n\n\n\n\nIn addition to numerical indexing, a frequently used indexing approach in R is logical indexing. In logical indexing, you provide inside the square brackets a logical vector that indicates for each element whether you want to keep it (TRUE) or not (FALSE). The benefit of this indexing approach is that you can combine it with logical statements to extract all elements that meet a specific condition.\n\n\n\n\n\n\n\n\nTry this out, by extracting all the even numbers from the numerical vector 1:10. To test whether a number x is even, you can use x %% 2 == 0.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nnumbers &lt;- 1:10\nnumbers[numbers %% 2 == 0]"
  },
  {
    "objectID": "worksheets/intro-to-R.html#data-frames",
    "href": "worksheets/intro-to-R.html#data-frames",
    "title": "Introduction to R",
    "section": "Data frames",
    "text": "Data frames\nA core concept of R is the data frame, which holds data in tabular form. A data frame is made up of multiple columns that all have the same number of elements. Different columns can be of different types.\nThere are a variety of ways to create a data frame. We will usually use the tibble() function from the tidyverse package.\n\n\n\n\n\n\n\n\nNote how we can assign names to the columns via named arguments in the tibble() function.\nTry this out. Create a tibble of your own."
  },
  {
    "objectID": "worksheets/intro-to-R.html#flow-control",
    "href": "worksheets/intro-to-R.html#flow-control",
    "title": "Introduction to R",
    "section": "Flow control",
    "text": "Flow control\nR has standard flow-control features such as for loops and if/else statements. These are almost never needed in data analysis and therefore I will not cover them here. If you find yourself wanting to use those constructs chances are you are replicating procedural programming patterns you have learned in other languages but that are not the most elegant way to solving a data analysis problem. I would encourage you to think about how to solve your problem using vectorized or functional programming patterns instead. (Functional programming patterns such as map() go beyond this basic tutorial but will be covered later in this class.)\nA concept closely related to flow control is the if_else() function from the tidyverse package. With if_else(), you can run a comparison at each position in a vector and then create a new vector whose elements depend on the outcome of each comparison.\nFor example, we can replace each occurrence of the word “orange” by “citrus” like so:\n\n\n\n\n\n\n\n\nThe first argument to if_else() is the logical condition you want to execute, the second argument is the resulting value if the condition is true, and the third argument is the resulting value if the condition is false.\nTry this out. In the following example, replace all numbers greater than 5 with the number 5 in the vector numbers.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nnumbers &lt;- c(10, 2, 4, 7, 6, -1, -8)\nif_else(numbers &gt; 5, ___, ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nnumbers &lt;- c(10, 2, 4, 7, 6, -1, -8)\nif_else(numbers &gt; 5, 5, numbers)"
  },
  {
    "objectID": "worksheets/know-your-data-2.html",
    "href": "worksheets/know-your-data-2.html",
    "title": "Getting to know your data 2",
    "section": "",
    "text": "In this worksheet, we will discuss how to work with missing values in R.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nWe will be working with the R built-in dataset airquality, which contains daily air quality measurements in New York, May to September 1973. The data columns are mean ozone in parts per billion, solar radiation in Langleys, average wind speed in miles per hour, maximum temperature in Fahrenheit, and numeric month and day of the month."
  },
  {
    "objectID": "worksheets/know-your-data-2.html#introduction",
    "href": "worksheets/know-your-data-2.html#introduction",
    "title": "Getting to know your data 2",
    "section": "",
    "text": "In this worksheet, we will discuss how to work with missing values in R.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nWe will be working with the R built-in dataset airquality, which contains daily air quality measurements in New York, May to September 1973. The data columns are mean ozone in parts per billion, solar radiation in Langleys, average wind speed in miles per hour, maximum temperature in Fahrenheit, and numeric month and day of the month."
  },
  {
    "objectID": "worksheets/know-your-data-2.html#reading-csv-files-with-missing-values",
    "href": "worksheets/know-your-data-2.html#reading-csv-files-with-missing-values",
    "title": "Getting to know your data 2",
    "section": "Reading csv files with missing values",
    "text": "Reading csv files with missing values\nWe will first talk about how to replace specific values with NA when reading in data files. We prepare a simple comma-separated values (CSV) file with four columns, a, b, c, and d, which all use different ways to indicate a missing value.\n\n\n\n\n\n\n\n\nIn column a, second row, a field is completely empty, the line starts with a comma. In column b, first row, a missing value is indicated with #N/A. In column c, second row, a missing value is indicated with NA. In column d, fourth row, a missing value is indicated with -99.\nIf we read this input with read_csv(), we can see that the missing values in columns a and c are treated correctly but the others are not.\n\n\n\n\n\n\n\n\nThis outcome is determined by the na argument of read_csv(). By default, it is set to na = c(\"\", \"NA\"), which handles empty cells and cells containing NA correctly. Modify this argument so that the entire table is read correctly.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nread_csv(simple_csv, na = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nread_csv(simple_csv, na = c(\"\", \"NA\", \"#N/A\", \"-99\"))\n\n\n\n\nAlso try other options to see what happens. For example, how does the result change if you remove the empty string from the na argument?\nAs an alternative to defining a global set of character strings that should be interpreted as missing values, you can make the substitution on a column-by-column basis, via the function replace_with_na_at() from the naniar package. This function allows you to specify one or more columns to work on and the specific data values that should be replaced with NA. The first argument to the function is the name of the data column on which you want to operate, given as a string, and the second argument is a logical expression determining whether replacement should be made or not, given as a formula. For example, the following code replaces -99 with NA in column d:\n\n\n\n\n\n\n\n\nNow use this same construct to replace the string #N/A with NA in column b.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nread_csv(simple_csv) |&gt;\n  replace_with_na_at(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nread_csv(simple_csv) |&gt;\n  replace_with_na_at(\"b\", ~.x == \"#N/A\")\n\n\n\n\nDo you see any remaining issues with this result?"
  },
  {
    "objectID": "worksheets/know-your-data-2.html#computing-with-missing-values",
    "href": "worksheets/know-your-data-2.html#computing-with-missing-values",
    "title": "Getting to know your data 2",
    "section": "Computing with missing values",
    "text": "Computing with missing values\nWhen performing common summary calculations, such as calculating the mean of a numerical column, any missing values will cause the final result to be NA. For example, if you wanted to calculate the mean ozone value in the airquality dataset, you might see the following:\n\n\n\n\n\n\n\n\nIf you are certain that it is Ok to ignore missing values in your summary calculation, you can set the argument na.rm = TRUE inside the mean() function. Try this.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nmean(airquality$Ozone) # not ignoring NA values\nmean(airquality$Ozone, na.rm = ___) # ignoring NA values\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nmean(airquality$Ozone) # not ignoring NA values\nmean(airquality$Ozone, na.rm = TRUE) # ignoring NA values\n\n\n\n\nNow try the same with the median, the maximum, and the sum of the Ozone column.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nmedian(airquality$Ozone)\nmedian(airquality$Ozone, na.rm = TRUE)\nmax(airquality$Ozone)\nmax(airquality$Ozone, na.rm = TRUE)\nsum(airquality$Ozone)\nsum(airquality$Ozone, na.rm = TRUE)\n\n\n\n\nTo test whether a specific value is missing, you cannot use the standard comparison operator ==. Instead, you have to use the function is.na(). Try this out by retaining only the rows in airquality for which the Ozone column contains a missing value.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nairquality |&gt;\n  filter(is.na(___))\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nairquality |&gt;\n  filter(is.na(Ozone))\n\n\n\n\nNow do the opposite. Retain only the rows for which the Ozone column does not contain a missing value.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nairquality |&gt;\n  filter(!is.na(Ozone))"
  },
  {
    "objectID": "worksheets/know-your-data-2.html#visualizing-missing-values",
    "href": "worksheets/know-your-data-2.html#visualizing-missing-values",
    "title": "Getting to know your data 2",
    "section": "Visualizing missing values",
    "text": "Visualizing missing values\nIt is also useful to be able to visualize missing values easily. By default, when we make for example a scatter plot, missing values are simply not shown, and instead ggplot gives us a warning about missing values.\n\n\n\n\n\n\n\n\nThis is not very helpful, because we don’t know where the values are missing. In this specific example, are they missing in the Ozone column or in the Solar.R column? And also, we may want to know whether missing values in one column coincide with particular values in the other column.\nThis can be addressed by using geom_miss_point() from the naniar package. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(airquality, aes(x = Solar.R, y = Ozone)) +\n geom_miss_point()\n\n\n\n\nThe naniar package has various other methods to visualize missing values. For example, gg_miss_var() will provide an overall summary of how many missing values there are in each column in the data frame. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ngg_miss_var(airquality)"
  },
  {
    "objectID": "worksheets/redundant-coding.html",
    "href": "worksheets/redundant-coding.html",
    "title": "Redundant coding, text annotations",
    "section": "",
    "text": "In this worksheet, we will discuss how to encode data using multiple visual channels (such as color and point shape), and we will also discuss text annotations.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nWe will be working with two datasets, iris and cars93. The iris dataset contains measurements on the flowers of three Iris species.\n\n\n\n\n\n\n\n\nHint: Pay attention to the column names in the iris dataset. They are all capitalized (e.g., Species), and the first four use a point as a separator (e.g., Sepal.Length). It is easy to misspell them and then the R code doesn’t work correctly.\nThe cars93 dataset contains information about various passenger cars that were on the market in 1993."
  },
  {
    "objectID": "worksheets/redundant-coding.html#introduction",
    "href": "worksheets/redundant-coding.html#introduction",
    "title": "Redundant coding, text annotations",
    "section": "",
    "text": "In this worksheet, we will discuss how to encode data using multiple visual channels (such as color and point shape), and we will also discuss text annotations.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nWe will be working with two datasets, iris and cars93. The iris dataset contains measurements on the flowers of three Iris species.\n\n\n\n\n\n\n\n\nHint: Pay attention to the column names in the iris dataset. They are all capitalized (e.g., Species), and the first four use a point as a separator (e.g., Sepal.Length). It is easy to misspell them and then the R code doesn’t work correctly.\nThe cars93 dataset contains information about various passenger cars that were on the market in 1993."
  },
  {
    "objectID": "worksheets/redundant-coding.html#mapping-variables-to-color-and-shape",
    "href": "worksheets/redundant-coding.html#mapping-variables-to-color-and-shape",
    "title": "Redundant coding, text annotations",
    "section": "Mapping variables to color and shape",
    "text": "Mapping variables to color and shape\nFirst, we will do an exercise to practice using multiple visual channels (color and shape) to represent the same qualitative variable. We will do this exercise with the iris dataset.\nMake a plot of Sepal.Width versus Sepal.Length for the three species in the iris dataset. Map Species to both color and shape.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(iris, aes(Sepal.Length, Sepal.Width, ___)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(iris, aes(Sepal.Length, Sepal.Width, color = Species, shape = Species)) +\n  geom_point()\n\n\n\n\nYou can set the shapes with scale_shape_manual(), just like you do with colors. There are five special shapes, 21 through 25, that have a line color and a fill color. Modify the plot from the previous exercise so it uses these shapes. Hint: This means you should use the fill aesthetic rather than the color aesthetic.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(iris, aes(Sepal.Length, Sepal.Width, ___)) +\n  geom_point() +\n  scale_shape_manual(values = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(iris, aes(Sepal.Length, Sepal.Width, fill = Species, shape = Species)) +\n  geom_point() +\n  scale_shape_manual(values = c(21, 23, 25))"
  },
  {
    "objectID": "worksheets/redundant-coding.html#manually-applying-text-labels",
    "href": "worksheets/redundant-coding.html#manually-applying-text-labels",
    "title": "Redundant coding, text annotations",
    "section": "Manually applying text labels",
    "text": "Manually applying text labels\nWe can place text labels with geom_text(). Oftentimes it makes sense to manually fine-tune exactly where the text labels will be located. To practice this, we will work with a simple dataset that contains three points:\n\n\n\n\n\n\n\n\nPlot these three points with geom_point(), and use geom_text() to add the label text to the right side of each point. Remember that hjust = 0 plots text left-justified. Hints: Add xlim(1, 4) to ensure the text labels don’t run beyond the edge of the plot panel.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(data, aes(x, y)) +\n  geom_point() +\n  geom_text(___) +\n  xlim(1, 4)\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(data, aes(x, y)) +\n  geom_point() +\n  geom_text(aes(label = ___), hjust = ___) +\n  xlim(1, 4)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(data, aes(x, y)) +\n  geom_point() +\n  geom_text(aes(label = label), hjust = 0) +\n  xlim(1, 4)\n\n\n\n\nNow place the text labels centered below the points. Remember: hjust = 0.5 means horizontally centered, and vjust = 1 means vertically below the reference point. You may also have to adjust x and y limits to make sure all labels are within the plot area.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(data, aes(x, y)) +\n  geom_point() +\n  geom_text(\n    aes(label = label),\n    ___\n  ) +\n  xlim(0.5, 3.5) +\n  ylim(0.5, 3)\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(data, aes(x, y)) +\n  geom_point() +\n  geom_text(\n    aes(label = label),\n    hjust = ___,\n    vjust = ___\n  ) +\n  xlim(0.5, 3.5) +\n  ylim(0.5, 3)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(data, aes(x, y)) +\n  geom_point() +\n  geom_text(\n    aes(label = label),\n    hjust = 0.5,\n    vjust = 1\n  ) +\n  xlim(0.5, 3.5) +\n  ylim(0.5, 3)\n\n\n\n\nFinally, place each label in a different relative orientation to the point. Place “alpha” horizontally centered underneath the point, “beta” vertically centered left of the point, and “gamma” horizontally centered above the point. This will require adding justification data columns to the data table and then mapping them to hjust and vjust in geom_text().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ndata &lt;- tibble(\n  x = c(1, 2, 3),\n  y = c(1, 3, 2),\n  label = c(\"alpha\", \"beta\", \"gamma\"),\n  hjust = ___,\n  vjust = ___\n)\n\nggplot(data, aes(x, y)) +\n  geom_point() +\n  geom_text(\n    aes(label = ___, ___)\n  ) +\n  xlim(0.5, 3.5) +\n  ylim(0.5, 3)\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ndata &lt;- tibble(\n  x = c(1, 2, 3),\n  y = c(1, 3, 2),\n  label = c(\"alpha\", \"beta\", \"gamma\"),\n  hjust = c(0.5, 1, 0.5),\n  vjust = c(1, 0.5, 0)\n)\n\nggplot(data, aes(x, y)) +\n  geom_point() +\n  geom_text(\n    aes(label = ___, ___)\n  ) +\n  xlim(0.5, 3.5) +\n  ylim(0.5, 3)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ndata &lt;- tibble(\n  x = c(1, 2, 3),\n  y = c(1, 3, 2),\n  label = c(\"alpha\", \"beta\", \"gamma\"),\n  hjust = c(0.5, 1, 0.5),\n  vjust = c(1, 0.5, 0)\n)\n\nggplot(data, aes(x, y)) +\n  geom_point() +\n  geom_text(\n    aes(label = label, hjust = hjust, vjust = vjust)\n  ) +\n  xlim(0.5, 3.5) +\n  ylim(0.5, 3)"
  },
  {
    "objectID": "worksheets/redundant-coding.html#non-overlapping-text-labels",
    "href": "worksheets/redundant-coding.html#non-overlapping-text-labels",
    "title": "Redundant coding, text annotations",
    "section": "Non-overlapping text labels",
    "text": "Non-overlapping text labels\nWhen there are many points to be labeled, we frequently run into the issue that labels overlap and become unreadable. This problem can be resolved with geom_text_repel() from the ggrepel package. This geom ensures that none of the text labels overlap. It is also highly customizable, and nearly any labeling problem can be solved with it.\nConsider the following plot of fuel-tank capacity versus price, for cars costing more than $30k.\n\n\n\n\n\n\n\n\nUse geom_text_repel() to add a text label to each point that shows the make of the car (column Make). Hint: Set max.overlaps = Inf to avoid a warning about unlabeled data points.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ncars93 |&gt;\n  filter(Price &gt; 30) |&gt;\n  ggplot(aes(Price, Fuel.tank.capacity)) +\n  geom_point() +\n  geom_text_repel(\n    aes(label = ___),\n    max.overlaps = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncars93 |&gt;\n  filter(Price &gt; 30) |&gt;\n  ggplot(aes(Price, Fuel.tank.capacity)) +\n  geom_point() +\n  geom_text_repel(\n    aes(label = Make),\n    max.overlaps = Inf\n  )\n\n\n\n\nThe value of the argument box.padding determines how far the labels are drawn from the data points. The default is box.padding = 0.25. Try out what larger values do. E.g., use 0.8 or 1.2.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ncars93 |&gt;\n  filter(Price &gt; 30) |&gt;\n  ggplot(aes(Price, Fuel.tank.capacity)) +\n  geom_point() +\n  geom_text_repel(\n    aes(label = Make),\n    max.overlaps = Inf,\n    ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncars93 |&gt;\n  filter(Price &gt; 30) |&gt;\n  ggplot(aes(Price, Fuel.tank.capacity)) +\n  geom_point() +\n  geom_text_repel(\n    aes(label = Make),\n    max.overlaps = Inf,\n    box.padding = 0.8\n  )\n\ncars93 |&gt;\n  filter(Price &gt; 30) |&gt;\n  ggplot(aes(Price, Fuel.tank.capacity)) +\n  geom_point() +\n  geom_text_repel(\n    aes(label = Make),\n    max.overlaps = Inf,\n    box.padding = 1.2\n  )\n\n\n\n\nSee if you can pull the text labels towards the left edge of the plot. This will require using the arguments force_pull, hjust, nudge_x, and direction. It will also require manual setting of the x limits. For additional hints, see the ggrepel documentation here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ncars93 |&gt;\n  filter(Price &gt; 30) |&gt;\n  ggplot(aes(Price, Fuel.tank.capacity)) +\n  geom_point() +\n  geom_text_repel(\n    aes(label = Make),\n    max.overlaps = Inf,\n    ___\n  ) +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ncars93 |&gt;\n  filter(Price &gt; 30) |&gt;\n  ggplot(aes(Price, Fuel.tank.capacity)) +\n  geom_point() +\n  geom_text_repel(\n    aes(label = Make),\n    max.overlaps = Inf,\n    force_pull = ___,\n    hjust = ___,\n    nudge_x = ___,\n    direction = ___\n  ) +\n  xlim(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\ncars93 |&gt;\n  filter(Price &gt; 30) |&gt;\n  ggplot(aes(Price, Fuel.tank.capacity)) +\n  geom_point() +\n  geom_text_repel(\n    aes(label = Make),\n    max.overlaps = Inf,\n    force_pull = 0,\n    hjust = 1,\n    nudge_x = -10,\n    direction = \"y\"\n  ) +\n  xlim(20, 65)\n\n\n\n\nExperiment with the various options for force_pull, hjust/vjust, nudge_x/nudge_y, and direction to get a sense of how they work."
  },
  {
    "objectID": "worksheets/visualizing-distributions-1.html",
    "href": "worksheets/visualizing-distributions-1.html",
    "title": "Visualizing distributions 1",
    "section": "",
    "text": "In this worksheet, we will discuss how to display distributions of data values using histograms and density plots.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the titanic dataset which contains information about passengers on the Titanic, including their age, sex, the class in which they traveled on the ship, and whether they survived or not:"
  },
  {
    "objectID": "worksheets/visualizing-distributions-1.html#introduction",
    "href": "worksheets/visualizing-distributions-1.html#introduction",
    "title": "Visualizing distributions 1",
    "section": "",
    "text": "In this worksheet, we will discuss how to display distributions of data values using histograms and density plots.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the titanic dataset which contains information about passengers on the Titanic, including their age, sex, the class in which they traveled on the ship, and whether they survived or not:"
  },
  {
    "objectID": "worksheets/visualizing-distributions-1.html#histograms",
    "href": "worksheets/visualizing-distributions-1.html#histograms",
    "title": "Visualizing distributions 1",
    "section": "Histograms",
    "text": "Histograms\nWe start by drawing a histogram of the passenger ages (column age in the dataset titanic). We can do this in ggplot with the geom geom_histogram(). Try this for yourself.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(titanic, aes(age)) +\n  geom_histogram()\n\n\n\n\nIf you don’t specify how many bins you want or how wide you want them to be, geom_histogram() will make an automatic choice, but it will also give you a warning that the automatic choice is probably not good. Make a better choice by setting the binwidth and center parameters. Try the values 5 and 2.5, respectively.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(titanic, aes(age)) +\n  geom_histogram(binwidth = ___, center = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(titanic, aes(age)) +\n  geom_histogram(binwidth = 5, center = 2.5)\n\n\n\n\nTry a few more different binwidths, e.g. 1 or 10. What are good values for center that go with these choices?"
  },
  {
    "objectID": "worksheets/visualizing-distributions-1.html#density-plots",
    "href": "worksheets/visualizing-distributions-1.html#density-plots",
    "title": "Visualizing distributions 1",
    "section": "Density plots",
    "text": "Density plots\nDensity plots are a good alternative to histograms. We can create them with geom_density(). Try this out by drawing a density plot of the passenger ages (column age in the dataset titanic). Also, by default geom_density() does not draw a filled area under the density line. We can change this by setting an explicit fill color, e.g. “cornsilk”.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(titanic, aes(age)) +\n  geom_density(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(titanic, aes(age)) +\n  geom_density(fill = \"cornsilk\")\n\n\n\n\nJust like for histograms, there are options to modify how much detail a density plot shows. A small binwidth in a histogram corresponds to a low bandwidth (bw) in a density plot and similarly a large binwidth corresponds to a high bandwidth. In addition, you can change the kernel, e.g. kernel = \"rectangular\" or kernel = \"triangular\". Try this out by using a bandwidth of 1 and a triangular kernel.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(titanic, aes(age)) +\n  geom_density(fill = \"cornsilk\", bw = ___, kernel = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(titanic, aes(age)) +\n  geom_density(fill = \"cornsilk\", bw = 1, kernel = \"triangular\")\n\n\n\n\nTry a few more different bandwidth and kernel choices, e.g. 0.1 or 10, or rectangular or gaussian kernels. How does the density plot depend on these choices?"
  },
  {
    "objectID": "worksheets/visualizing-distributions-1.html#small-multiples-facets",
    "href": "worksheets/visualizing-distributions-1.html#small-multiples-facets",
    "title": "Visualizing distributions 1",
    "section": "Small multiples (facets)",
    "text": "Small multiples (facets)\nWe can also draw separate histograms for passengers meeting different criteria, for example for passengers traveling in the different classes. Whenever we draw multiple plot panels containing the same type of plot but for different subsets of the data, we speak of “small multiples”. In ggplot, we generate small multiples with the function facet_wrap(). The function facet_wrap() takes as its argument a list of data columns to subdivide the data by. This list is provided as an R formula. It’s Ok if you don’t know what an R formula is. Simply think of it as the name of the column with a tilde (~) in front. For example, ~class means draw a separate panel for each class, ~survived means draw a separate panel for each survival status, and ~class + survived means draw a separate panel for each combination of class and survival status.\nAs an example, the following code generates small multiple histograms by class:\n\n\n\n\n\n\n\n\nNow use the same principle to draw small multiple histograms by survival status.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(titanic, aes(age)) +\n  geom_histogram(binwidth = 5, center = 2.5) +\n  facet_wrap(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(titanic, aes(age)) +\n  geom_histogram(binwidth = 5, center = 2.5) +\n  facet_wrap(~survived)\n\n\n\n\nNow make a plot that breaks down the data by both survival status and class.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(titanic, aes(age)) +\n  geom_histogram(binwidth = 5, center = 2.5) +\n  facet_wrap(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(titanic, aes(age)) +\n  geom_histogram(binwidth = 5, center = 2.5) +\n  facet_wrap(~survived + class)\n\n\n\n\nFinally, do the same but drawing density plots rather than histograms.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(titanic, aes(age)) +\n  ___ +\n  facet_wrap(~survived + class)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(titanic, aes(age)) +\n  geom_density(fill = \"cornsilk\", bw = 2) +\n  facet_wrap(~survived + class)\n\n\n\n\notice the difference between this plot and the corresponding histogram plot. Histograms show absolute counts whereas the density plots are normalized so that the area under the curve is 1. As a consequence, the density plot does not provide an accurate representation of the number of passengers in each grouping. This can be changed. See next section."
  },
  {
    "objectID": "worksheets/visualizing-distributions-1.html#manipulating-stats",
    "href": "worksheets/visualizing-distributions-1.html#manipulating-stats",
    "title": "Visualizing distributions 1",
    "section": "Manipulating stats",
    "text": "Manipulating stats\nYou may have noticed that neither geom_histogram() nor geom_density() require you to define an aesthetic mapping for the y variable. This is because under the hood, a statistical transformation (called a “stat”) calculates the histogram or density from the raw data and then sets the appropriate y mapping.\nSometimes it can be useful to access or modify this mapping directly. We tell ggplot that we want to map a value calculated by a stat, rather than one that is in the original data, by writing after_stat(...) inside the aes() function. So, for example, the default y mapping for geom_density() is y = after_stat(density). An alternative mapping, y = after_stat(count) scales densities by the number of points in each grouping, thus producing something more similar to a histogram. You can see the difference between these two choices in the following two examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe same options of after_stat(count) and after_stat(density) exist for geom_histogram() as well. Try this by making histograms that use the calculated density for the y value.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(titanic, aes(age, y = ___)) + \n  geom_histogram(binwidth = 5, center = 2.5) +\n  facet_wrap(~survived + class)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(titanic, aes(age, y = after_stat(density))) + \n  geom_histogram(binwidth = 5, center = 2.5) +\n  facet_wrap(~survived + class)\n\n\n\n\nNow, instead, try mapping the calculated counts onto the fill aesthetic.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(titanic, aes(age, fill = ___)) + \n  geom_histogram(binwidth = 5, center = 2.5) +\n  facet_wrap(~survived + class)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(titanic, aes(age, fill = after_stat(count))) + \n  geom_histogram(binwidth = 5, center = 2.5) +\n  facet_wrap(~survived + class)\n\n\n\n\nFinally, we can make our own combination of geoms and stats, by setting the stat argument of a geom, e.g. stat = \"density\" to use the density stat. To try this out, draw a density plot using geom_point(), and also map the calculated density values onto the point color.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(titanic, aes(age, color = ___)) +\n  geom_point(stat = \"density\") +\n  facet_wrap(~survived + class)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(titanic, aes(age, color = after_stat(density))) +\n  geom_point(stat = \"density\") +\n  facet_wrap(~survived + class)"
  },
  {
    "objectID": "worksheets/visualizing-proportions.html",
    "href": "worksheets/visualizing-proportions.html",
    "title": "Visualizing proportions",
    "section": "",
    "text": "In this worksheet, we will discuss how to visualize proportions using stacked or dodged bar plots and pie charts.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the dataset bundestag, which contains the composition of the German parliament (Bundestag) from 1976 to 1980.\n\n\n\n\n\n\n\n\nWe will also be working with the dataset marketshare, which contains made-up information about the market share of five hypothetical companies, A, B, C, D, and E, over a time period of three years."
  },
  {
    "objectID": "worksheets/visualizing-proportions.html#introduction",
    "href": "worksheets/visualizing-proportions.html#introduction",
    "title": "Visualizing proportions",
    "section": "",
    "text": "In this worksheet, we will discuss how to visualize proportions using stacked or dodged bar plots and pie charts.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nNext we set up the data.\n\n\n\n\n\n\n\n\nWe will be working with the dataset bundestag, which contains the composition of the German parliament (Bundestag) from 1976 to 1980.\n\n\n\n\n\n\n\n\nWe will also be working with the dataset marketshare, which contains made-up information about the market share of five hypothetical companies, A, B, C, D, and E, over a time period of three years."
  },
  {
    "objectID": "worksheets/visualizing-proportions.html#bars-in-cartesian-and-polar-coordinates",
    "href": "worksheets/visualizing-proportions.html#bars-in-cartesian-and-polar-coordinates",
    "title": "Visualizing proportions",
    "section": "Bars in Cartesian and polar coordinates",
    "text": "Bars in Cartesian and polar coordinates\nThere are three main approaches to visualizing proportions: Stacked bars, grouped (dodged) bars, and pie charts. From the perspective of ggplot, these are all bar charts with only minor tweaks, and we can make them all using geom_bar() or geom_col() (depending on whether the data source contains individual observations or summary counts). The first two types are created by setting position adjustments to \"fill\" and \"dodge\", respectively, and the third type is created by setting the position adjustment to \"fill\" and adding coord_polar() to the plot.\nLet’s try this on the bundestag dataset. We want to lay out the bars horizontally, so let’s map the number of seats (seats) to x and map party to fill. We have nothing to map to y, but ggplot needs something there to generate the plot, so we can write for example y = \"abc\". (Instead of \"abc\", you can use any string you want.) First, make a stacked bar plot using these ideas. Remember that the correct geom in this context is geom_col(), as the dataset contains summary counts. Also, the position adjustment should be \"fill\", to show the numbers as relative proportions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(bundestag, aes(x = seats, y = \"abc\", fill = party)) +\n  geom_col(position = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(bundestag, aes(x = seats, y = \"abc\", fill = party)) +\n  geom_col(position = \"fill\")\n\n\n\n\nNext, modify this plot so the bars a side-by-side rather than stacked.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(bundestag, aes(x = seats, y = \"abc\", fill = party)) +\n  geom_col(position = ___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(bundestag, aes(x = seats, y = \"abc\", fill = party)) +\n  geom_col(position = \"dodge\")\n\n\n\n\nCan you order the arrangement of the bars such that the party with the most seats is on top and the one with the least seats at the bottom?\nNext, use coord_polar() to turn this plot into a pie chart. Which position adjustment do you need to use?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(bundestag, aes(x = seats, y = \"abc\", fill = party)) +\n  geom_col(position = ___) +\n  coord_polar()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(bundestag, aes(x = seats, y = \"abc\", fill = party)) +\n  geom_col(position = \"fill\") +\n  coord_polar()\n\n\n\n\nThe previous plots showed only a single set of propotions, a snapshot of the parliamentary composition at one point in time. Frequently, however, we want to show multiple proportions, for example from different time points.\nWe can try this out with the marketshare dataset. Remember that this dataset has the columns company, year, and percent. Make a stacked bar plot showing percent along the x axis, year along the y axis, and filled by company name.\nHint: Turn year into a factor to ensure ggplot interprets it as a categorical variable.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(marketshare, aes(percent, factor(year), fill = ___)) +\n  geom_col(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(marketshare, aes(percent, factor(year), fill = company)) +\n  geom_col(position = \"fill\")\n\n\n\n\nNow convert this plot into side-by-side bars.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(marketshare, aes(percent, factor(year), fill = company)) +\n  geom_col(___)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(marketshare, aes(percent, factor(year), fill = company)) +\n  geom_col(position = \"dodge\")\n\n\n\n\nAnd now convert this plot into a set of three pie charts.\nHint: You will have to use faceting and plot one pie per facet.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(marketshare, aes(percent, ___, fill = company)) +\n  geom_col(position = ___) +\n  facet_wrap(___) +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(marketshare, aes(percent, \"abc\", fill = company)) +\n  geom_col(position = \"fill\") +\n  facet_wrap(~year) +\n  coord_polar()"
  },
  {
    "objectID": "worksheets/visualizing-proportions.html#pie-charts-in-cartesian-coordinates",
    "href": "worksheets/visualizing-proportions.html#pie-charts-in-cartesian-coordinates",
    "title": "Visualizing proportions",
    "section": "Pie charts in Cartesian coordinates",
    "text": "Pie charts in Cartesian coordinates\nThe idea that a pie chart is a stacked bar plot in polar coordinates tends to be very appealing to proponents of the Grammar of Graphics (which forms the mathematical underpinnings of ggplot), but it oftentimes is not that useful in practice. Instead, we have much more ability to customize our pie charts if we draw them in Cartesian coordinates, using geom_arc_bar() from the package ggforce. It allows us to specify the exact location of the pie center in the x-y plane, and it also allows us to specify the inner and outer pie radius. As an example, consider this code.\n\n\n\n\n\n\n\n\nNow modify this code to reproduce the marketshare pies from the previous section. Reminder: The columns are company, year, and percent.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(marketshare) +\n  aes(\n    ___\n  ) +\n  geom_arc_bar(stat = \"pie\") +\n  facet_wrap(___) +\n  coord_fixed()\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(marketshare) +\n  aes(\n    x0 = 0, y0 = 0,\n    r0 = 0, r = 1,\n    amount = percent,\n    fill = company\n  ) +\n  geom_arc_bar(stat = \"pie\") +\n  facet_wrap(~year) +\n  coord_fixed()\n\n\n\n\nYou can turn the pies into donuts by modifying r0. You can also adjust the plot limits to create some space between the pies and the plot boundaries. Try this out.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nggplot(marketshare) +\n  aes(\n    x0 = 0, y0 = 0,\n    r0 = ___, r = 1,\n    amount = percent,\n    fill = company\n  ) +\n  geom_arc_bar(stat = \"pie\") +\n  facet_wrap(~year) +\n  coord_fixed(\n    xlim = ___,\n    ylim = ___\n  ) \n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nggplot(marketshare) +\n  aes(\n    x0 = 0, y0 = 0,\n    r0 = 0.4, r = 1,\n    amount = percent,\n    fill = company\n  ) +\n  geom_arc_bar(stat = \"pie\") +\n  facet_wrap(~year) +\n  coord_fixed(\n    xlim = c(-1.1, 1.1),\n    ylim = c(-1.4, 1.4)\n  )\n\n\n\n\nCan you plot the year into the center of the donuts? This is an advanced exercise and it’s Ok if you can’t figure this out.\nHints:\n\nYou can draw text with geom_text().\nYou will need to create a new data table just for geom_text().\nBoth geoms will need their own aesthetic mappings.\n\nThe final plot could look like this:\n\n\n\n\n\n\n\n\nHow close to this can you get with your own code?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\n# data table for geom text\nyears &lt;- tibble(year = c(2015, 2016, 2017))\n\nggplot(marketshare) +\n  geom_arc_bar(\n    aes(\n      ___\n    ),\n    stat = \"pie\"\n  ) +\n  geom_text(\n    data = years,\n    aes(___)\n  ) +\n  ____\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n# data table for geom text\nyears &lt;- tibble(year = c(2015, 2016, 2017))\n\nggplot(marketshare) +\n  geom_arc_bar(\n    aes(\n      x0 = 0, y0 = 0,\n      r0 = 0.4, r = 1,\n      amount = percent,\n      fill = company\n    ),\n    stat = \"pie\"\n  ) +\n  geom_text(\n    data = years,\n    aes(x = 0, y = 0, label = year)\n  ) +\n  facet_wrap(~year) +\n  coord_fixed(\n    xlim = c(-1.0, 1.0),\n    ylim = c(-1.1, 1.4)\n  ) +\n  theme_void() +\n  theme(\n    strip.text = element_blank(),\n    strip.background = element_blank()\n  )"
  },
  {
    "objectID": "worksheets/visualizing-uncertainty.html",
    "href": "worksheets/visualizing-uncertainty.html",
    "title": "Visualizing uncertainty",
    "section": "",
    "text": "In this worksheet, we will discuss how to visualize uncertainty estimates obtained from a model fit.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nWe will be working with the dataset gapminder containing data on data on life expectancy, GDP per capita, and population by country and year."
  },
  {
    "objectID": "worksheets/visualizing-uncertainty.html#introduction",
    "href": "worksheets/visualizing-uncertainty.html#introduction",
    "title": "Visualizing uncertainty",
    "section": "",
    "text": "In this worksheet, we will discuss how to visualize uncertainty estimates obtained from a model fit.\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n\n\n\n\nWe will be working with the dataset gapminder containing data on data on life expectancy, GDP per capita, and population by country and year."
  },
  {
    "objectID": "worksheets/visualizing-uncertainty.html#plotting-model-estimates-as-error-bars",
    "href": "worksheets/visualizing-uncertainty.html#plotting-model-estimates-as-error-bars",
    "title": "Visualizing uncertainty",
    "section": "Plotting model estimates as error bars",
    "text": "Plotting model estimates as error bars\nWhenever we are working with linear models applied to a complex dataset, we typically end up with a summary table that holds various parameter estimates with associated standard errors. For example, for the gapminder dataset, we can fit life expectancy against log-transformed GDP per capita separately for each continent and year. We end up with a set of estimates of the slope of the regression line for each subset of data.\nThe pipeline to perform these model fits and extract the estimates and standard errors has been discussed in the preceding worksheet, and we take it as a given here.\n\n\n\n\n\n\n\n\nNext, we can visualize these estimates. Let’s focus just on the Americas. We could make a scatter plot of the estimate (which is the slope of the regression line) against year.\n\n\n\n\n\n\n\n\nHowever, this does not show the uncertainty of each estimate. The simplest way to show uncertainty is via error bars, which we can plot in ggplot with geom_pointrange(). This geom takes in addition to the x and y aesthetics an additional set of aesthetics ymin and ymax (or alternatively xmin and xmax, depending on whether error bars should be shown vertically or horizontally), which represent the end points of the error bars. Importantly, you need to calculate these endpoints yourself, the geom cannot calculate them from the estimate and standard error.\nFor sufficiently large data sets, we can make a normal approximation and assume that the 95% confidence interval corresponds to the mean +/- 1.96 times the error. Thus, we calculate lower and upper bounds in this way and then plot.\n\n\n\n\n\n\n\n\nTo see if you understand these concepts, repeat this plot but with two modifications:\n\nCalculate a 99% confidence interval instead of a 95% confidence interval. The multiplier for a 99% confidence interval is 2.58.\nPlot year along the y axis and the estimate along the x axis. This requires the error bars to be laid out horizontally.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nlm_data |&gt;\n  filter(continent == \"Americas\") |&gt;\n  mutate(\n    lower = estimate - 2.58*std.error,\n    upper = estimate + 2.58*std.error\n  ) |&gt;\n  ggplot(___) +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nlm_data |&gt;\n  filter(continent == \"Americas\") |&gt;\n  mutate(\n    lower = estimate - 2.58*std.error,\n    upper = estimate + 2.58*std.error\n  ) |&gt;\n  ggplot(aes(estimate, year)) +\n  geom_pointrange(aes(xmin = lower, xmax = upper))\n\n\n\n\nThere are two related geoms, geom_linerange() and geom_errorbar(), that differ in minor ways from geom_pointrange(). First, both omit the point in the middle, so you have to plot it manually. Second, geom_errorbar() shows error bars with a little cap at the end. Repeat the previous plot using both of these geoms.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nlm_data |&gt;\n  filter(continent == \"Americas\") |&gt;\n  mutate(\n    lower = estimate - 2.58*std.error,\n    upper = estimate + 2.58*std.error\n  ) |&gt;\n  ggplot(___) +\n  ___\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nlm_data |&gt;\n  filter(continent == \"Americas\") |&gt;\n  mutate(\n    lower = estimate - 2.58*std.error,\n    upper = estimate + 2.58*std.error\n  ) |&gt;\n  ggplot(aes(estimate, year)) +\n  geom_linerange(aes(xmin = lower, xmax = upper)) +\n  geom_point(color = \"navyblue\")\n\nlm_data |&gt;\n  filter(continent == \"Americas\") |&gt;\n  mutate(\n    lower = estimate - 2.58*std.error,\n    upper = estimate + 2.58*std.error\n  ) |&gt;\n  ggplot(aes(estimate, year)) +\n  geom_errorbar(aes(xmin = lower, xmax = upper)) +\n  geom_point(color = \"navyblue\")"
  },
  {
    "objectID": "worksheets/visualizing-uncertainty.html#half-eyes-gradient-intervals-etc.",
    "href": "worksheets/visualizing-uncertainty.html#half-eyes-gradient-intervals-etc.",
    "title": "Visualizing uncertainty",
    "section": "Half-eyes, gradient intervals, etc.",
    "text": "Half-eyes, gradient intervals, etc.\nIf we want to go beyond simple error bars, the ggdist package provides many more sophisticated approaches to visualizing uncertainty distributions. These include stat_dist_halfeye(), stat_dist_gradientinterval(), and stat_dist_dotsinterval() to draw half-eyes, gradient intervals, and quantile dotplots, respectively. All these functions take an unusual aes() argument of the form aes(dist = &lt;distribution function&gt;). Here, &lt;distribution function&gt; is a distribution function from the distributional package converting the parameter estimate and standard error (and possibly other values, such as the residual degrees of freedom) into an error distribution. For example, the following mapping would use the estimate and std.error columns in the data to create a normal error distribution.\naes(dist = dist_normal(mu = estimate, sigma = std.error))\nTo demonstrate how this works, we’ll make a half-eye plot for the gapminder regression models, focusing on the year 1952 but keeping all continents.\n\n\n\n\n\n\n\n\nTry this for yourself. To change things up, pick a different year, e.g. 2002, and a different fill color.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nlm_data |&gt;\n  filter(year == 2002) |&gt;\n  mutate(continent = fct_reorder(continent, estimate)) |&gt;\n  ggplot(aes(x = estimate, y = continent)) +\n  stat_dist_halfeye(\n    aes(dist = dist_normal(mu = estimate, sigma = std.error)),\n    fill = \"olivedrab\"\n  )\n\n\n\n\nNow use stat_dist_gradientinterval() instead of stat_dist_halfeye().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nlm_data |&gt;\n  filter(year == 2002) |&gt;\n  mutate(continent = fct_reorder(continent, estimate)) |&gt;\n  ggplot(aes(x = estimate, y = continent)) +\n  stat_dist_gradientinterval(\n    aes(dist = dist_normal(mu = estimate, sigma = std.error))\n  )\n\n\n\n\nAnd finally use stat_dist_dotsinterval(). This stat takes an additional parameter quantiles that determines the number of quantile dots to draw. Try quantiles = 20.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nlm_data |&gt;\n  filter(year == 2002) |&gt;\n  mutate(continent = fct_reorder(continent, estimate)) |&gt;\n  ggplot(aes(x = estimate, y = continent)) +\n  stat_dist_dotsinterval(\n    aes(dist = dist_normal(mu = estimate, sigma = std.error)),\n    fill = \"olivedrab\",\n    quantiles = ___\n  )\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nlm_data |&gt;\n  filter(year == 2002) |&gt;\n  mutate(continent = fct_reorder(continent, estimate)) |&gt;\n  ggplot(aes(x = estimate, y = continent)) +\n  stat_dist_dotsinterval(\n    aes(dist = dist_normal(mu = estimate, sigma = std.error)),\n    fill = \"olivedrab\",\n    quantiles = 20\n  )\n\n\n\n\nChange both the year and the number of quantiles to see how quantile dotplots look in a variety of different scenarios. The possible year values range from 1952 to 2007 in five-year increments."
  }
]